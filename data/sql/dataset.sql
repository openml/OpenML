INSERT INTO `dataset` (`did`, `uploader`, `source`, `name`, `version`, `version_label`, `description`, `format`, `creator`, `contributor`, `collection_date`, `upload_date`, `language`, `licence`, `citation`, `collection`, `url`, `isOriginal`, `file_id`, `default_target_attribute`, `row_id_attribute`, `ignore_attribute`, `paper_url`, `visibility`, `original_data_id`, `original_data_url`, `update_comment`, `last_update`) VALUES
(1, 1, 0, 'anneal', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title of Database: Annealing Data\n \n 2. Source Information: donated by David Sterling and Wray Buntine.\n \n 3. Past Usage: unknown\n \n 4. Relevant Information:\n    -- Explanation: I suspect this was left by Ross Quinlan in 1987 at the\n       4th Machine Learning Workshop.  I\'d have to check with Jeff Schlimmer\n       to double check this.\n \n 5. Number of Instances: 798\n \n 6. Number of Attributes: 38\n    -- 6 continuously-valued\n    -- 3 integer-valued\n    -- 29 nominal-valued\n \n 7. Attribute Information:\n     1. family:          --,GB,GK,GS,TN,ZA,ZF,ZH,ZM,ZS\n     2. product-type:    C, H, G\n     3. steel:           -,R,A,U,K,M,S,W,V\n     4. carbon:          continuous\n     5. hardness:        continuous\n     6. temper_rolling:  -,T\n     7. condition:       -,S,A,X\n     8. formability:     -,1,2,3,4,5\n     9. strength:        continuous\n    10. non-ageing:      -,N\n    11. surface-finish:  P,M,-\n    12. surface-quality: -,D,E,F,G\n    13. enamelability:   -,1,2,3,4,5\n    14. bc:              Y,-\n    15. bf:              Y,-\n    16. bt:              Y,-\n    17. bw/me:           B,M,-\n    18. bl:              Y,-\n    19. m:               Y,-\n    20. chrom:           C,-\n    21. phos:            P,-\n    22. cbond:           Y,-\n    23. marvi:           Y,-\n    24. exptl:           Y,-\n    25. ferro:           Y,-\n    26. corr:            Y,-\n    27. blue/bright/varn/clean:          B,R,V,C,-\n    28. lustre:          Y,-\n    29. jurofm:          Y,-\n    30. s:               Y,-\n    31. p:               Y,-\n    32. shape:           COIL, SHEET\n    33. thick:           continuous\n    34. width:           continuous\n    35. len:             continuous\n    36. oil:             -,Y,N\n    37. bore:            0000,0500,0600,0760\n    38. packing: -,1,2,3\n    classes:        1,2,3,4,5,U\n  \n    -- The \'-\' values are actually \'not_applicable\' values rather than\n       \'missing_values\' (and so can be treated as legal discrete\n       values rather than as showing the absence of a discrete value).\n \n 8. Missing Attribute Values: Signified with \"?\"\n    Attribute:  Number of instances missing its value:\n    1           0\n    2           0\n    3           70\n    4           0\n    5           0\n    6           675\n    7           271\n    8           283\n    9           0\n   10           703\n   11           790\n   12           217\n   13           785\n   14           797\n   15           680\n   16           736\n   17           609\n   18           662\n   19           798\n   20           775\n   21           791\n   22           730\n   23           798\n   24           796\n   25           772\n   26           798\n   27           793\n   28           753\n   29           798\n   30           798\n   31           798\n   32           0\n   33           0\n   34           0\n   35           0\n   36           740\n   37           0\n   38           789\n   39           0\n \n 9. Distribution of Classes\n      Class Name:   Number of Instances:\n      1               8\n      2              88\n      3             608\n      4               0\n      5              60\n      U              34\n                    ---\n                    798', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:19:24', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1666876/phpFsFYVN', 'true', 1, 'class', NULL, NULL, NULL, 'public', NULL, NULL, 'Restoring dataset file', '2015-09-02 00:49:04'),
(2, 1, 0, 'kr-vs-kp', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Chess End-Game -- King+Rook versus King+Pawn on a7\n    (usually abbreviated KRKPA7).  The pawn on a7 means it is one square\n    away from queening.  It is the King+Rook\'s side (white) to move.\n \n 2. Sources:\n     (a) Database originally generated and described by Alen Shapiro.\n     (b) Donor/Coder: Rob Holte (holte@uottawa.bitnet).  The database\n         was supplied to Holte by Peter Clark of the Turing Institute\n         in Glasgow (pete@turing.ac.uk).\n     (c) Date: 1 August 1989\n \n 3. Past Usage:\n      - Alen D. Shapiro (1983,1987), \"Structured Induction in Expert Systems\",\n        Addison-Wesley.  This book is based on Shapiro\'s Ph.D. thesis (1983)\n        at the University of Edinburgh entitled \"The Role of Structured\n        Induction in Expert Systems\".\n      - Stephen Muggleton (1987), \"Structuring Knowledge by Asking Questions\",\n        pp.218-229 in \"Progress in Machine Learning\", edited by I. Bratko\n        and Nada Lavrac, Sigma Press, Wilmslow, England  SK9 5BB.\n      - Robert C. Holte, Liane Acker, and Bruce W. Porter (1989),\n        \"Concept Learning and the Problem of Small Disjuncts\",\n        Proceedings of IJCAI.  Also available as technical report AI89-106,\n        Computer Sciences Department, University of Texas at Austin,\n        Austin, Texas 78712.\n \n 4. Relevant Information:\n       The dataset format is described below.  Note: the format of this\n     database was modified on 2/26/90 to conform with the format of all\n     the other databases in the UCI repository of machine learning databases.\n \n 5. Number of Instances: 3196 total\n \n 6. Number of Attributes: 36\n \n 7. Attribute Summaries:\n     Classes (2):  -- White-can-win (\"won\") and White-cannot-win (\"nowin\").\n           I believe that White is deemed to be unable to win if the Black pawn\n           can safely advance.\n     Attributes: see Shapiro\'s book.\n \n 8. Missing Attributes: --  none\n \n 9. Class Distribution:\n     In 1669 of the positions (52%), White can win.\n     In 1527 of the positions (48%), White cannot win.\n \n The format for instances in this database is a sequence of 37 attribute values.\n Each instance is a board-descriptions for this chess endgame.  The first\n 36 attributes describe the board.  The last (37th) attribute is the\n classification: \"win\" or \"nowin\".  There are 0 missing values.\n A typical board-description is\n \n f,f,f,f,f,f,f,f,f,f,f,f,l,f,n,f,f,t,f,f,f,f,f,f,f,t,f,f,f,f,f,f,f,t,t,n,won\n \n The names of the features do not appear in the board-descriptions.\n Instead, each feature correponds to a particular position in the\n feature-value list.  For example, the head of this list is the value\n for the feature \"bkblk\".  The following is the list of features, in\n the order in which their values appear in the feature-value list:\n \n [bkblk,bknwy,bkon8,bkona,bkspr,bkxbq,bkxcr,bkxwp,blxwp,bxqsq,cntxt,dsopp,dwipd,\n  hdchk,katri,mulch,qxmsq,r2ar8,reskd,reskr,rimmx,rkxwp,rxmsq,simpl,skach,skewr,\n  skrxp,spcop,stlmt,thrsk,wkcti,wkna8,wknck,wkovl,wkpos,wtoeg]\n \n In the file, there is one instance (board position) per line.\n \n \n Num Instances:     3196\n Num Attributes:    37\n Num Continuous:    0 (Int 0 / Real 0)\n Num Discrete:      37\n Missing values:    0 /  0.0%\n\n     name                      type enum ints real     missing    distinct  (1)\n   1 \'bkblk\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   2 \'bknwy\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   3 \'bkon8\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   4 \'bkona\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   5 \'bkspr\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   6 \'bkxbq\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   7 \'bkxcr\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   8 \'bkxwp\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   9 \'blxwp\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  10 \'bxqsq\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  11 \'cntxt\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  12 \'dsopp\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  13 \'dwipd\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  14 \'hdchk\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  15 \'katri\'                   Enum 100%   0%   0%     0 /  0%     3 /  0%   0% \n  16 \'mulch\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  17 \'qxmsq\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  18 \'r2ar8\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  19 \'reskd\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  20 \'reskr\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  21 \'rimmx\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  22 \'rkxwp\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  23 \'rxmsq\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  24 \'simpl\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  25 \'skach\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  26 \'skewr\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  27 \'skrxp\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  28 \'spcop\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  29 \'stlmt\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  30 \'thrsk\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  31 \'wkcti\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  32 \'wkna8\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  33 \'wknck\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  34 \'wkovl\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  35 \'wkpos\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  36 \'wtoeg\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  37 \'class\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0%', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:19:28', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3/dataset_3_kr-vs-kp.arff', 'true', 2, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:19:28'),
(3, 1, 0, 'letter', '1', '1', '**Author**: David J. Slate  \r\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Letter+Recognition) - 01-01-1991  \r\n**Please cite**: P. W. Frey and D. J. Slate. \"Letter Recognition Using Holland-style Adaptive Classifiers\". Machine Learning 6(2), 1991  \r\n\r\n1. TITLE: \r\n  Letter Image Recognition Data \r\n \r\n    The objective is to identify each of a large number of black-and-white\r\n    rectangular pixel displays as one of the 26 capital letters in the English\r\n    alphabet.  The character images were based on 20 different fonts and each\r\n    letter within these 20 fonts was randomly distorted to produce a file of\r\n    20,000 unique stimuli.  Each stimulus was converted into 16 primitive\r\n    numerical attributes (statistical moments and edge counts) which were then\r\n    scaled to fit into a range of integer values from 0 through 15.  We\r\n    typically train on the first 16000 items and then use the resulting model\r\n    to predict the letter category for the remaining 4000.  See the article\r\n    cited above for more details.', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:19:41', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/6/dataset_6_letter.arff', 'true', 3, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:19:41'),
(4, 1, 0, 'balance-scale', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Balance Scale Weight & Distance Database\n\n2. Source Information: \n    (a) Source: Generated to model psychological experiments reported\n		by Siegler, R. S. (1976).  Three Aspects of Cognitive\n		Development.  Cognitive Psychology, 8, 481-520.\n    (b) Donor: Tim Hume (hume@ics.uci.edu)\n    (c) Date: 22 April 1994\n\n3. Past Usage: (possibly different formats of this data)\n   - Publications\n	1. Klahr, D., & Siegler, R.S. (1978).  The Representation of\n	   Children\'s Knowledge.  In H. W. Reese & L. P. Lipsitt (Eds.),\n	   Advances in Child Development and Behavior, pp. 61-116.  New\n	   York: Academic Press \n	2. Langley,P. (1987).  A General Theory of Discrimination\n	   Learning.  In D. Klahr, P. Langley, & R. Neches (Eds.),\n	   Production System Models of Learning and Development, pp.\n	   99-161. Cambridge, MA: MIT Press\n	3. Newell, A. (1990).  Unified Theories of Cognition.\n	   Cambridge, MA: Harvard University Press\n	4. McClelland, J.L. (1988).  Parallel Distibuted Processing:\n	   Implications for Cognition and Development.  Technical\n	   Report AIP-47, Department of Psychology, Carnegie-Mellon\n	   University \n	5. Shultz, T., Mareschal, D., & Schmidt, W. (1994).  Modeling\n	   Cognitive Development on Balance Scale Phenomena. Machine\n	   Learning, Vol. 16, pp. 59-88.\n\n4. Relevant Information: \n	This data set was generated to model psychological\n	experimental results.  Each example is classified as having the\n	balance scale tip to the right, tip to the left, or be\n	balanced.  The attributes are the left weight, the left\n	distance, the right weight, and the right distance.  The\n	correct way to find the class is the greater of \n	(left-distance * left-weight) and (right-distance *\n	right-weight).  If they are equal, it is balanced.\n\n5. Number of Instances: 625 (49 balanced, 288 left, 288 right)\n\n6. Number of Attributes: 4 (numeric) + class name = 5\n\n7. Attribute Information:\n	1. Class Name: 3 (L, B, R)\n	2. Left-Weight: 5 (1, 2, 3, 4, 5)\n	3. Left-Distance: 5 (1, 2, 3, 4, 5)\n	4. Right-Weight: 5 (1, 2, 3, 4, 5)\n	5. Right-Distance: 5 (1, 2, 3, 4, 5)\n\n8. Missing Attribute Values: \n	none\n\n9. Class Distribution: \n   1. 46.08 percent are L\n   2. 07.84 percent are B\n   3. 46.08 percent are R', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:19:55', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/11/dataset_11_balance-scale.arff', 'true', 4, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:19:55'),
(5, 1, 0, 'mfeat-factors', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThe multi-feature digit dataset\n -------------------------------\n \n Oowned and donated by:\n ----------------------\n \n Robert P.W. Duin\n Department of Applied Physics \n Delft University of Technology \n P.O. Box 5046, 2600 GA Delft\n The Netherlands\n \n email: duin@ph.tn.tudelft.nl\n http : //www.ph.tn.tudelft.nl/~duin\n tel +31 15 2786143\n \n Usage\n -----\n A slightly different version of the database is used in\n \n M. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten\n      digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4,\n      1998, 381-386.\n \n M. van Breukelen and R.P.W. Duin, Neural Network Initialization by Combined\n      Classifiers, in: A.K. Jain, S. Venkatesh, B.C. Lovell (eds.), ICPR\'98,\n      Proc. 14th Int. Conference on Pattern Recognition (Brisbane, Aug. 16-20),\n \n The database as it is is used in:\n \n A.K. Jain, R.P.W. Duin, J. Mao, Statisitcal Pattern Recognition: A Review,\n      in preparation\n \n Description\n -----------\n \n This dataset consists of features of handwritten numerals (`0\'--`9\')\n extracted from a collection of Dutch utility maps. 200 patterns per\n class (for a total of 2,000 patterns) have been digitized in  binary\n images. These digits are represented in terms of the following six\n feature sets (files): \n \n 1. mfeat-fou: 76 Fourier coefficients of the character shapes; \n 2. mfeat-fac: 216 profile correlations; \n 3. mfeat-kar: 64 Karhunen-Love coefficients; \n 4. mfeat-pix: 240 pixel averages in 2 x 3 windows; \n 5. mfeat-zer: 47 Zernike moments; \n 6. mfeat-mor: 6 morphological features. \n \n In each file the 2000 patterns are stored in ASCI on 2000 lines. The\n first 200 patterns are of class `0\', followed by sets of 200 patterns\n for each of the classes `1\' - `9\'. Corresponding patterns in different\n feature sets (files) correspond to the same original character.\n \n The source image dataset is lost. Using the pixel-dataset (mfeat-pix)\n sampled versions of the original images may be obtained (15 x 16 pixels).\n \n Total number of instances:\n --------------------------\n 2000 (200 instances per class)\n \n Total number of attributes:\n ---------------------------\n 649 (distributed over 6 datasets,see above)\n \n no missing attributes\n \n Total number of classes:\n ------------------------\n 10\n \n Format:\n ------\n 6 files, see above.\n Each file contains 2000 lines, one for each instance.\n Attributes are SPACE separated and can be loaded by Matlab as\n > load filename\n No missing attributes. Some are integer, others are real.\n \n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:20:04', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/12/dataset_12_mfeat-factors.arff', 'true', 5, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:20:04'),
(6, 1, 0, 'mfeat-fourier', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThe multi-feature digit dataset\n -------------------------------\n \n Oowned and donated by:\n ----------------------\n \n Robert P.W. Duin\n Department of Applied Physics \n Delft University of Technology \n P.O. Box 5046, 2600 GA Delft\n The Netherlands\n \n email: duin@ph.tn.tudelft.nl\n http : //www.ph.tn.tudelft.nl/~duin\n tel +31 15 2786143\n \n Usage\n -----\n A slightly different version of the database is used in\n \n M. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten\n      digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4,\n      1998, 381-386.\n \n M. van Breukelen and R.P.W. Duin, Neural Network Initialization by Combined\n      Classifiers, in: A.K. Jain, S. Venkatesh, B.C. Lovell (eds.), ICPR\'98,\n      Proc. 14th Int. Conference on Pattern Recognition (Brisbane, Aug. 16-20),\n \n The database as it is is used in:\n \n A.K. Jain, R.P.W. Duin, J. Mao, Statisitcal Pattern Recognition: A Review,\n      in preparation\n \n Description\n -----------\n \n This dataset consists of features of handwritten numerals (`0\'--`9\')\n extracted from a collection of Dutch utility maps. 200 patterns per\n class (for a total of 2,000 patterns) have been digitized in  binary\n images. These digits are represented in terms of the following six\n feature sets (files): \n \n 1. mfeat-fou: 76 Fourier coefficients of the character shapes; \n 2. mfeat-fac: 216 profile correlations; \n 3. mfeat-kar: 64 Karhunen-Love coefficients; \n 4. mfeat-pix: 240 pixel averages in 2 x 3 windows; \n 5. mfeat-zer: 47 Zernike moments; \n 6. mfeat-mor: 6 morphological features. \n \n In each file the 2000 patterns are stored in ASCI on 2000 lines. The\n first 200 patterns are of class `0\', followed by sets of 200 patterns\n for each of the classes `1\' - `9\'. Corresponding patterns in different\n feature sets (files) correspond to the same original character.\n \n The source image dataset is lost. Using the pixel-dataset (mfeat-pix)\n sampled versions of the original images may be obtained (15 x 16 pixels).\n \n Total number of instances:\n --------------------------\n 2000 (200 instances per class)\n \n Total number of attributes:\n ---------------------------\n 649 (distributed over 6 datasets,see above)\n \n no missing attributes\n \n Total number of classes:\n ------------------------\n 10\n \n Format:\n ------\n 6 files, see above.\n Each file contains 2000 lines, one for each instance.\n Attributes are SPACE separated and can be loaded by Matlab as\n > load filename\n No missing attributes. Some are integer, others are real.\n \n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:20:17', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/14/dataset_14_mfeat-fourier.arff', 'true', 6, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:20:17'),
(7, 1, 0, 'breast-w', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:20:20', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/52350/openml_phpJNxH0q', 'true', 7, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, 'added special attributes', '2014-09-21 23:04:47'),
(8, 1, 0, 'mfeat-karhunen', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThe multi-feature digit dataset\n -------------------------------\n \n Oowned and donated by:\n ----------------------\n \n Robert P.W. Duin\n Department of Applied Physics \n Delft University of Technology \n P.O. Box 5046, 2600 GA Delft\n The Netherlands\n \n email: duin@ph.tn.tudelft.nl\n http : //www.ph.tn.tudelft.nl/~duin\n tel +31 15 2786143\n \n Usage\n -----\n A slightly different version of the database is used in\n \n M. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten\n      digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4,\n      1998, 381-386.\n \n M. van Breukelen and R.P.W. Duin, Neural Network Initialization by Combined\n      Classifiers, in: A.K. Jain, S. Venkatesh, B.C. Lovell (eds.), ICPR\'98,\n      Proc. 14th Int. Conference on Pattern Recognition (Brisbane, Aug. 16-20),\n \n The database as it is is used in:\n \n A.K. Jain, R.P.W. Duin, J. Mao, Statisitcal Pattern Recognition: A Review,\n      in preparation\n \n Description\n -----------\n \n This dataset consists of features of handwritten numerals (`0\'--`9\')\n extracted from a collection of Dutch utility maps. 200 patterns per\n class (for a total of 2,000 patterns) have been digitized in  binary\n images. These digits are represented in terms of the following six\n feature sets (files): \n \n 1. mfeat-fou: 76 Fourier coefficients of the character shapes; \n 2. mfeat-fac: 216 profile correlations; \n 3. mfeat-kar: 64 Karhunen-Love coefficients; \n 4. mfeat-pix: 240 pixel averages in 2 x 3 windows; \n 5. mfeat-zer: 47 Zernike moments; \n 6. mfeat-mor: 6 morphological features. \n \n In each file the 2000 patterns are stored in ASCI on 2000 lines. The\n first 200 patterns are of class `0\', followed by sets of 200 patterns\n for each of the classes `1\' - `9\'. Corresponding patterns in different\n feature sets (files) correspond to the same original character.\n \n The source image dataset is lost. Using the pixel-dataset (mfeat-pix)\n sampled versions of the original images may be obtained (15 x 16 pixels).\n \n Total number of instances:\n --------------------------\n 2000 (200 instances per class)\n \n Total number of attributes:\n ---------------------------\n 649 (distributed over 6 datasets,see above)\n \n no missing attributes\n \n Total number of classes:\n ------------------------\n 10\n \n Format:\n ------\n 6 files, see above.\n Each file contains 2000 lines, one for each instance.\n Attributes are SPACE separated and can be loaded by Matlab as\n > load filename\n No missing attributes. Some are integer, others are real.\n \n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:20:30', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/16/dataset_16_mfeat-karhunen.arff', 'true', 8, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:20:30'),
(9, 1, 0, 'mfeat-morphological', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThe multi-feature digit dataset\n -------------------------------\n \n Oowned and donated by:\n ----------------------\n \n Robert P.W. Duin\n Department of Applied Physics \n Delft University of Technology \n P.O. Box 5046, 2600 GA Delft\n The Netherlands\n \n email: duin@ph.tn.tudelft.nl\n http : //www.ph.tn.tudelft.nl/~duin\n tel +31 15 2786143\n \n Usage\n -----\n A slightly different version of the database is used in\n \n M. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten\n      digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4,\n      1998, 381-386.\n \n M. van Breukelen and R.P.W. Duin, Neural Network Initialization by Combined\n      Classifiers, in: A.K. Jain, S. Venkatesh, B.C. Lovell (eds.), ICPR\'98,\n      Proc. 14th Int. Conference on Pattern Recognition (Brisbane, Aug. 16-20),\n \n The database as it is is used in:\n \n A.K. Jain, R.P.W. Duin, J. Mao, Statisitcal Pattern Recognition: A Review,\n      in preparation\n \n Description\n -----------\n \n This dataset consists of features of handwritten numerals (0 - 9)\n extracted from a collection of Dutch utility maps. 200 patterns per\n class (for a total of 2,000 patterns) have been digitized in  binary\n images. These digits are represented in terms of the following six\n feature sets (files): \n \n 1. mfeat-fou: 76 Fourier coefficients of the character shapes; \n 2. mfeat-fac: 216 profile correlations; \n 3. mfeat-kar: 64 Karhunen-Love coefficients; \n 4. mfeat-pix: 240 pixel averages in 2 x 3 windows; \n 5. mfeat-zer: 47 Zernike moments; \n 6. mfeat-mor: 6 morphological features. \n \n In each file the 2000 patterns are stored in ASCI on 2000 lines. The\n first 200 patterns are of class \'0\', followed by sets of 200 patterns\n for each of the classes \'1\' - \'9\'. Corresponding patterns in different\n feature sets (files) correspond to the same original character.\n \n The source image dataset is lost. Using the pixel-dataset (mfeat-pix)\n sampled versions of the original images may be obtained (15 x 16 pixels).\n \n Total number of instances:\n --------------------------\n 2000 (200 instances per class)\n \n Total number of attributes:\n ---------------------------\n 649 (distributed over 6 datasets,see above)\n \n no missing attributes\n \n Total number of classes:\n ------------------------\n 10\n \n Format:\n ------\n 6 files, see above.\n Each file contains 2000 lines, one for each instance.\n Attributes are SPACE separated and can be loaded by Matlab as\n > load filename\n No missing attributes. Some are integer, others are real.\n \n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:20:37', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/18/dataset_18_mfeat-morphological.arff', 'true', 9, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:20:37'),
(10, 1, 0, 'mfeat-pixel', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThe multi-feature digit dataset\n -------------------------------\n \n Oowned and donated by:\n ----------------------\n \n Robert P.W. Duin\n Department of Applied Physics \n Delft University of Technology \n P.O. Box 5046, 2600 GA Delft\n The Netherlands\n \n email: duin@ph.tn.tudelft.nl\n http : //www.ph.tn.tudelft.nl/~duin\n tel +31 15 2786143\n \n Usage\n -----\n A slightly different version of the database is used in\n \n M. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten\n      digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4,\n      1998, 381-386.\n \n M. van Breukelen and R.P.W. Duin, Neural Network Initialization by Combined\n      Classifiers, in: A.K. Jain, S. Venkatesh, B.C. Lovell (eds.), ICPR\'98,\n      Proc. 14th Int. Conference on Pattern Recognition (Brisbane, Aug. 16-20),\n \n The database as it is is used in:\n \n A.K. Jain, R.P.W. Duin, J. Mao, Statisitcal Pattern Recognition: A Review,\n      in preparation\n \n Description\n -----------\n \n This dataset consists of features of handwritten numerals (`0\'--`9\')\n extracted from a collection of Dutch utility maps. 200 patterns per\n class (for a total of 2,000 patterns) have been digitized in  binary\n images. These digits are represented in terms of the following six\n feature sets (files): \n \n 1. mfeat-fou: 76 Fourier coefficients of the character shapes; \n 2. mfeat-fac: 216 profile correlations; \n 3. mfeat-kar: 64 Karhunen-Love coefficients; \n 4. mfeat-pix: 240 pixel averages in 2 x 3 windows; \n 5. mfeat-zer: 47 Zernike moments; \n 6. mfeat-mor: 6 morphological features. \n \n In each file the 2000 patterns are stored in ASCI on 2000 lines. The\n first 200 patterns are of class `0\', followed by sets of 200 patterns\n for each of the classes `1\' - `9\'. Corresponding patterns in different\n feature sets (files) correspond to the same original character.\n \n The source image dataset is lost. Using the pixel-dataset (mfeat-pix)\n sampled versions of the original images may be obtained (15 x 16 pixels).\n \n Total number of instances:\n --------------------------\n 2000 (200 instances per class)\n \n Total number of attributes:\n ---------------------------\n 649 (distributed over 6 datasets,see above)\n \n no missing attributes\n \n Total number of classes:\n ------------------------\n 10\n \n Format:\n ------\n 6 files, see above.\n Each file contains 2000 lines, one for each instance.\n Attributes are SPACE separated and can be loaded by Matlab as\n > load filename\n No missing attributes. Some are integer, others are real.\n \n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:20:48', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/20/dataset_20_mfeat-pixel.arff', 'true', 10, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:20:48'),
(11, 1, 0, 'car', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Car Evaluation Database\n \n 2. Sources:\n    (a) Creator: Marko Bohanec\n    (b) Donors: Marko Bohanec   (marko.bohanec@ijs.si)\n                Blaz Zupan      (blaz.zupan@ijs.si)\n    (c) Date: June, 1997\n \n 3. Past Usage:\n \n    The hierarchical decision model, from which this dataset is\n    derived, was first presented in \n \n    M. Bohanec and V. Rajkovic: Knowledge acquisition and explanation for\n    multi-attribute decision making. In 8th Intl Workshop on Expert\n    Systems and their Applications, Avignon, France. pages 59-78, 1988.\n \n    Within machine-learning, this dataset was used for the evaluation\n    of HINT (Hierarchy INduction Tool), which was proved to be able to\n    completely reconstruct the original hierarchical model. This,\n    together with a comparison with C4.5, is presented in\n \n    B. Zupan, M. Bohanec, I. Bratko, J. Demsar: Machine learning by\n    function decomposition. ICML-97, Nashville, TN. 1997 (to appear)\n \n 4. Relevant Information Paragraph:\n \n    Car Evaluation Database was derived from a simple hierarchical\n    decision model originally developed for the demonstration of DEX\n    (M. Bohanec, V. Rajkovic: Expert system for decision\n    making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates\n    cars according to the following concept structure:\n \n    CAR                      car acceptability\n    . PRICE                  overall price\n    . . buying               buying price\n    . . maint                price of the maintenance\n    . TECH                   technical characteristics\n    . . COMFORT              comfort\n    . . . doors              number of doors\n    . . . persons            capacity in terms of persons to carry\n    . . . lug_boot           the size of luggage boot\n    . . safety               estimated safety of the car\n \n    Input attributes are printed in lowercase. Besides the target\n    concept (CAR), the model includes three intermediate concepts:\n    PRICE, TECH, COMFORT. Every concept is in the original model\n    related to its lower level descendants by a set of examples (for\n    these examples sets see http://www-ai.ijs.si/BlazZupan/car.html).\n \n    The Car Evaluation Database contains examples with the structural\n    information removed, i.e., directly relates CAR to the six input\n    attributes: buying, maint, doors, persons, lug_boot, safety.\n \n    Because of known underlying concept structure, this database may be\n    particularly useful for testing constructive induction and\n    structure discovery methods.\n \n 5. Number of Instances: 1728\n    (instances completely cover the attribute space)\n \n 6. Number of Attributes: 6\n \n 7. Attribute Values:\n \n    buying       v-high, high, med, low\n    maint        v-high, high, med, low\n    doors        2, 3, 4, 5-more\n    persons      2, 4, more\n    lug_boot     small, med, big\n    safety       low, med, high\n \n 8. Missing Attribute Values: none\n \n 9. Class Distribution (number of instances per class)\n \n    class      N          N[%]\n    -----------------------------\n    unacc     1210     (70.023 %) \n    acc        384     (22.222 %) \n    good        69     ( 3.993 %) \n    v-good      65     ( 3.762 %) \n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:20:52', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/21/dataset_21_car.arff', 'true', 11, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:20:52'),
(12, 1, 0, 'mfeat-zernike', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThe multi-feature digit dataset\n -------------------------------\n \n Oowned and donated by:\n ----------------------\n \n Robert P.W. Duin\n Department of Applied Physics \n Delft University of Technology \n P.O. Box 5046, 2600 GA Delft\n The Netherlands\n \n email: duin@ph.tn.tudelft.nl\n http : //www.ph.tn.tudelft.nl/~duin\n tel +31 15 2786143\n \n Usage\n -----\n A slightly different version of the database is used in\n \n M. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten\n      digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4,\n      1998, 381-386.\n \n M. van Breukelen and R.P.W. Duin, Neural Network Initialization by Combined\n      Classifiers, in: A.K. Jain, S. Venkatesh, B.C. Lovell (eds.), ICPR\'98,\n      Proc. 14th Int. Conference on Pattern Recognition (Brisbane, Aug. 16-20),\n \n The database as it is is used in:\n \n A.K. Jain, R.P.W. Duin, J. Mao, Statisitcal Pattern Recognition: A Review,\n      in preparation\n \n Description\n -----------\n \n This dataset consists of features of handwritten numerals (`0\'--`9\')\n extracted from a collection of Dutch utility maps. 200 patterns per\n class (for a total of 2,000 patterns) have been digitized in  binary\n images. These digits are represented in terms of the following six\n feature sets (files): \n \n 1. mfeat-fou: 76 Fourier coefficients of the character shapes; \n 2. mfeat-fac: 216 profile correlations; \n 3. mfeat-kar: 64 Karhunen-Love coefficients; \n 4. mfeat-pix: 240 pixel averages in 2 x 3 windows; \n 5. mfeat-zer: 47 Zernike moments; \n 6. mfeat-mor: 6 morphological features. \n \n In each file the 2000 patterns are stored in ASCI on 2000 lines. The\n first 200 patterns are of class `0\', followed by sets of 200 patterns\n for each of the classes `1\' - `9\'. Corresponding patterns in different\n feature sets (files) correspond to the same original character.\n \n The source image dataset is lost. Using the pixel-dataset (mfeat-pix)\n sampled versions of the original images may be obtained (15 x 16 pixels).\n \n Total number of instances:\n --------------------------\n 2000 (200 instances per class)\n \n Total number of attributes:\n ---------------------------\n 649 (distributed over 6 datasets,see above)\n \n no missing attributes\n \n Total number of classes:\n ------------------------\n 10\n \n Format:\n ------\n 6 files, see above.\n Each file contains 2000 lines, one for each instance.\n Attributes are SPACE separated and can be loaded by Matlab as\n > load filename\n No missing attributes. Some are integer, others are real.\n \n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:21:00', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/22/dataset_22_mfeat-zernike.arff', 'true', 12, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:21:00'),
(13, 1, 0, 'cmc', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Contraceptive Method Choice\n \n 2. Sources:\n    (a) Origin:  This dataset is a subset of the 1987 National Indonesia\n                 Contraceptive Prevalence Survey\n    (b) Creator: Tjen-Sien Lim (limt@stat.wisc.edu)\n    (c) Donor:   Tjen-Sien Lim (limt@stat.wisc.edu)\n    (c) Date:    June 7, 1997\n \n 3. Past Usage:\n    Lim, T.-S., Loh, W.-Y. & Shih, Y.-S. (1999). A Comparison of\n    Prediction Accuracy, Complexity, and Training Time of Thirty-three\n    Old and New Classification Algorithms. Machine Learning. Forthcoming.\n    (ftp://ftp.stat.wisc.edu/pub/loh/treeprogs/quest1.7/mach1317.pdf or\n    (http://www.stat.wisc.edu/~limt/mach1317.pdf)\n \n 4. Relevant Information:\n    This dataset is a subset of the 1987 National Indonesia Contraceptive\n    Prevalence Survey. The samples are married women who were either not \n    pregnant or do not know if they were at the time of interview. The \n    problem is to predict the current contraceptive method choice \n    (no use, long-term methods, or short-term methods) of a woman based \n    on her demographic and socio-economic characteristics.\n \n 5. Number of Instances: 1473\n \n 6. Number of Attributes: 10 (including the class attribute)\n \n 7. Attribute Information:\n \n    1. Wife\'s age                     (numerical)\n    2. Wife\'s education               (categorical)      1=low, 2, 3, 4=high\n    3. Husband\'s education            (categorical)      1=low, 2, 3, 4=high\n    4. Number of children ever born   (numerical)\n    5. Wife\'s religion                (binary)           0=Non-Islam, 1=Islam\n    6. Wife\'s now working?            (binary)           0=Yes, 1=No\n    7. Husband\'s occupation           (categorical)      1, 2, 3, 4\n    8. Standard-of-living index       (categorical)      1=low, 2, 3, 4=high\n    9. Media exposure                 (binary)           0=Good, 1=Not good\n    10. Contraceptive method used     (class attribute)  1=No-use \n                                                         2=Long-term\n                                                         3=Short-term\n \n 8. Missing Attribute Values: None\n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:21:03', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/23/dataset_23_cmc.arff', 'true', 13, 'Contraceptive_method_used', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:21:03'),
(14, 1, 0, 'mushroom', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Mushroom Database\n \n 2. Sources: \n     (a) Mushroom records drawn from The Audubon Society Field Guide to North\n         American Mushrooms (1981). G. H. Lincoff (Pres.), New York: Alfred\n         A. Knopf\n     (b) Donor: Jeff Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)\n     (c) Date: 27 April 1987\n \n 3. Past Usage:\n     1. Schlimmer,J.S. (1987). Concept Acquisition Through Representational\n        Adjustment (Technical Report 87-19).  Doctoral disseration, Department\n        of Information and Computer Science, University of California, Irvine.\n        --- STAGGER: asymptoted to 95% classification accuracy after reviewing\n            1000 instances.\n     2. Iba,W., Wogulis,J., & Langley,P. (1988).  Trading off Simplicity\n        and Coverage in Incremental Concept Learning. In Proceedings of \n        the 5th International Conference on Machine Learning, 73-79.\n        Ann Arbor, Michigan: Morgan Kaufmann.  \n        -- approximately the same results with their HILLARY algorithm    \n     3. In the following references a set of rules (given below) were\n         learned for this data set which may serve as a point of\n         comparison for other researchers.\n \n         Duch W, Adamczak R, Grabczewski K (1996) Extraction of logical rules\n         from training data using backpropagation networks, in: Proc. of the\n         The 1st Online Workshop on Soft Computing, 19-30.Aug.1996, pp. 25-30,\n         available on-line at: http://www.bioele.nuee.nagoya-u.ac.jp/wsc1/\n \n         Duch W, Adamczak R, Grabczewski K, Ishikawa M, Ueda H, Extraction of\n         crisp logical rules using constrained backpropagation networks -\n         comparison of two new approaches, in: Proc. of the European Symposium\n         on Artificial Neural Networks (ESANN\'97), Bruge, Belgium 16-18.4.1997,\n         pp. xx-xx\n \n         Wlodzislaw Duch, Department of Computer Methods, Nicholas Copernicus\n         University, 87-100 Torun, Grudziadzka 5, Poland\n         e-mail: duch@phys.uni.torun.pl\n         WWW     http://www.phys.uni.torun.pl/kmk/\n         \n         Date: Mon, 17 Feb 1997 13:47:40 +0100\n         From: Wlodzislaw Duch <duch@phys.uni.torun.pl>\n         Organization: Dept. of Computer Methods, UMK\n \n         I have attached a file containing logical rules for mushrooms.\n         It should be helpful for other people since only in the last year I\n         have seen about 10 papers analyzing this dataset and obtaining quite\n         complex rules. We will try to contribute other results later.\n \n         With best regards, Wlodek Duch\n         ________________________________________________________________\n \n         Logical rules for the mushroom data sets.\n \n         Logical rules given below seem to be the simplest possible for the\n         mushroom dataset and therefore should be treated as benchmark results.\n \n         Disjunctive rules for poisonous mushrooms, from most general\n         to most specific:\n \n         P_1) odor=NOT(almond.OR.anise.OR.none)\n              120 poisonous cases missed, 98.52% accuracy\n \n         P_2) spore-print-color=green\n              48 cases missed, 99.41% accuracy\n          \n         P_3) odor=none.AND.stalk-surface-below-ring=scaly.AND.\n                   (stalk-color-above-ring=NOT.brown) \n              8 cases missed, 99.90% accuracy\n          \n         P_4) habitat=leaves.AND.cap-color=white\n                  100% accuracy     \n \n         Rule P_4) may also be\n \n         P_4\') population=clustered.AND.cap_color=white\n \n         These rule involve 6 attributes (out of 22). Rules for edible\n         mushrooms are obtained as negation of the rules given above, for\n         example the rule:\n \n         odor=(almond.OR.anise.OR.none).AND.spore-print-color=NOT.green\n \n         gives 48 errors, or 99.41% accuracy on the whole dataset.\n \n         Several slightly more complex variations on these rules exist,\n         involving other attributes, such as gill_size, gill_spacing,\n         stalk_surface_above_ring, but the rules given above are the simplest\n         we have found.\n \n \n 4. Relevant Information:\n     This data set includes descriptions of hypothetical samples\n     corresponding to 23 species of gilled mushrooms in the Agaricus and\n     Lepiota Family (pp. 500-525).  Each species is identified as\n     definitely edible, definitely poisonous, or of unknown edibility and\n     not recommended.  This latter class was combined with the poisonous\n     one.  The Guide clearly states that there is no simple rule for\n     determining the edibility of a mushroom; no rule like ``leaflets\n     three, let it be\'\' for Poisonous Oak and Ivy.\n \n 5. Number of Instances: 8124\n \n 6. Number of Attributes: 22 (all nominally valued)\n \n 7. Attribute Information: (classes: edible=e, poisonous=p)\n      1. cap-shape:                bell=b,conical=c,convex=x,flat=f,\n                                   knobbed=k,sunken=s\n      2. cap-surface:              fibrous=f,grooves=g,scaly=y,smooth=s\n      3. cap-color:                brown=n,buff=b,cinnamon=c,gray=g,green=r,\n                                   pink=p,purple=u,red=e,white=w,yellow=y\n      4. bruises?:                 bruises=t,no=f\n      5. odor:                     almond=a,anise=l,creosote=c,fishy=y,foul=f,\n                                   musty=m,none=n,pungent=p,spicy=s\n      6. gill-attachment:          attached=a,descending=d,free=f,notched=n\n      7. gill-spacing:             close=c,crowded=w,distant=d\n      8. gill-size:                broad=b,narrow=n\n      9. gill-color:               black=k,brown=n,buff=b,chocolate=h,gray=g,\n                                   green=r,orange=o,pink=p,purple=u,red=e,\n                                   white=w,yellow=y\n     10. stalk-shape:              enlarging=e,tapering=t\n     11. stalk-root:               bulbous=b,club=c,cup=u,equal=e,\n                                   rhizomorphs=z,rooted=r,missing=?\n     12. stalk-surface-above-ring: ibrous=f,scaly=y,silky=k,smooth=s\n     13. stalk-surface-below-ring: ibrous=f,scaly=y,silky=k,smooth=s\n     14. stalk-color-above-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o,\n                                   pink=p,red=e,white=w,yellow=y\n     15. stalk-color-below-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o,\n                                   pink=p,red=e,white=w,yellow=y\n     16. veil-type:                partial=p,universal=u\n     17. veil-color:               brown=n,orange=o,white=w,yellow=y\n     18. ring-number:              none=n,one=o,two=t\n     19. ring-type:                cobwebby=c,evanescent=e,flaring=f,large=l,\n                                   none=n,pendant=p,sheathing=s,zone=z\n     20. spore-print-color:        black=k,brown=n,buff=b,chocolate=h,green=r,\n                                   orange=o,purple=u,white=w,yellow=y\n     21. population:               abundant=a,clustered=c,numerous=n,\n                                   scattered=s,several=v,solitary=y\n     22. habitat:                  grasses=g,leaves=l,meadows=m,paths=p,\n                                   urban=u,waste=w,woods=d\n \n 8. Missing Attribute Values: 2480 of them (denoted by \"?\"), all for\n    attribute #11.\n \n 9. Class Distribution: \n     --    edible: 4208 (51.8%)\n     -- poisonous: 3916 (48.2%)\n     --     total: 8124 instances', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:21:11', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/24/dataset_24_mushroom.arff', 'true', 14, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:21:11'),
(15, 1, 0, 'optdigits', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title of Database: Optical Recognition of Handwritten Digits\n \n 2. Source:\n 	E. Alpaydin, C. Kaynak\n 	Department of Computer Engineering\n 	Bogazici University, 80815 Istanbul Turkey\n 	alpaydin@boun.edu.tr\n 	July 1998\n \n 3. Past Usage:\n 	C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n 	Applications to Handwritten Digit Recognition, \n 	MSc Thesis, Institute of Graduate Studies in Science and \n 	Engineering, Bogazici University.\n \n 	E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika,\n 	to appear. ftp://ftp.icsi.berkeley.edu/pub/ai/ethem/kyb.ps.Z\n \n 4. Relevant Information:\n 	We used preprocessing programs made available by NIST to extract\n 	normalized bitmaps of handwritten digits from a preprinted form. From\n 	a total of 43 people, 30 contributed to the training set and different\n 	13 to the test set. 32x32 bitmaps are divided into nonoverlapping \n 	blocks of 4x4 and the number of on pixels are counted in each block.\n 	This generates an input matrix of 8x8 where each element is an \n 	integer in the range 0..16. This reduces dimensionality and gives \n 	invariance to small distortions.\n \n 	For info on NIST preprocessing routines, see \n 	M. D. Garris, J. L. Blue, G. T. Candela, D. L. Dimmick, J. Geist, \n 	P. J. Grother, S. A. Janet, and C. L. Wilson, NIST Form-Based \n 	Handprint Recognition System, NISTIR 5469, 1994.\n \n 5. Number of Instances\n 	optdigits.tra	Training	3823\n 	optdigits.tes	Testing		1797\n 	\n 	The way we used the dataset was to use half of training for \n 	actual training, one-fourth for validation and one-fourth\n 	for writer-dependent testing. The test set was used for \n 	writer-independent testing and is the actual quality measure.\n \n 6. Number of Attributes\n 	64 input+1 class attribute\n \n 7. For Each Attribute:\n 	All input attributes are integers in the range 0..16.\n 	The last attribute is the class code 0..9\n \n 8. Missing Attribute Values\n 	None\n \n 9. Class Distribution\n 	Class:	No of examples in training set\n 	0:  376\n 	1:  389\n 	2:  380\n 	3:  389\n 	4:  387\n 	5:  376\n 	6:  377\n 	7:  387\n 	8:  380\n 	9:  382\n \n 	Class: No of examples in testing set\n 	0:  178\n 	1:  182\n 	2:  177\n 	3:  183\n 	4:  181\n 	5:  182\n 	6:  181\n 	7:  179\n 	8:  174\n 	9:  180\n \n Accuracy on the testing set with k-nn \n using Euclidean distance as the metric\n \n  k =  1   : 98.00\n  k =  2   : 97.38\n  k =  3   : 97.83\n  k =  4   : 97.61\n  k =  5   : 97.89\n  k =  6   : 97.77\n  k =  7   : 97.66\n  k =  8   : 97.66\n  k =  9   : 97.72\n  k = 10   : 97.55\n  k = 11   : 97.89', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:21:34', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/28/dataset_28_optdigits.arff', 'true', 15, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:21:34'),
(16, 1, 0, 'credit-a', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Credit Approval\n \n 2. Sources: \n     (confidential)\n     Submitted by quinlan@cs.su.oz.au\n \n 3.  Past Usage:\n \n     See Quinlan,\n     * \"Simplifying decision trees\", Int J Man-Machine Studies 27,\n       Dec 1987, pp. 221-234.\n     * \"C4.5: Programs for Machine Learning\", Morgan Kaufmann, Oct 1992\n   \n 4.  Relevant Information:\n \n     This file concerns credit card applications.  All attribute names\n     and values have been changed to meaningless symbols to protect\n     confidentiality of the data.\n   \n     This dataset is interesting because there is a good mix of\n     attributes -- continuous, nominal with small numbers of\n     values, and nominal with larger numbers of values.  There\n     are also a few missing values.\n   \n 5.  Number of Instances: 690\n \n 6.  Number of Attributes: 15 + class attribute\n \n 7.  Attribute Information:\n \n     A1:	b, a.\n     A2:	continuous.\n     A3:	continuous.\n     A4:	u, y, l, t.\n     A5:	g, p, gg.\n     A6:	c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\n     A7:	v, h, bb, j, n, z, dd, ff, o.\n     A8:	continuous.\n     A9:	t, f.\n     A10:	t, f.\n     A11:	continuous.\n     A12:	t, f.\n     A13:	g, p, s.\n     A14:	continuous.\n     A15:	continuous.\n     A16: +,-         (class attribute)\n \n 8.  Missing Attribute Values:\n     37 cases (5%) have one or more missing values.  The missing\n     values from particular attributes are:\n \n     A1:  12\n     A2:  12\n     A4:   6\n     A5:   6\n     A6:   9\n     A7:   9\n     A14: 13\n \n 9.  Class Distribution\n   \n     +: 307 (44.5%)\n     -: 383 (55.5%)', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:21:38', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/29/dataset_29_credit-a.arff', 'true', 16, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:21:38'),
(17, 1, 0, 'credit-g', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nDescription of the German credit dataset.\n \n 1. Title: German Credit data\n \n 2. Source Information\n \n Professor Dr. Hans Hofmann  \n Institut f\"ur Statistik und \"Okonometrie  \n Universit\"at Hamburg  \n FB Wirtschaftswissenschaften  \n Von-Melle-Park 5    \n 2000 Hamburg 13 \n \n 3. Number of Instances:  1000\n \n Two datasets are provided.  the original dataset, in the form provided\n by Prof. Hofmann, contains categorical/symbolic attributes and\n is in the file \"german.data\".   \n  \n For algorithms that need numerical attributes, Strathclyde University \n produced the file \"german.data-numeric\".  This file has been edited \n and several indicator variables added to make it suitable for \n algorithms which cannot cope with categorical variables.   Several\n attributes that are ordered categorical (such as attribute 17) have\n been coded as integer.    This was the form used by StatLog.\n \n \n 6. Number of Attributes german: 20 (7 numerical, 13 categorical)\n    Number of Attributes german.numer: 24 (24 numerical)\n \n \n 7.  Attribute description for german\n \n Attribute 1:  (qualitative)\n 	       Status of existing checking account\n                A11 :      ... <    0 DM\n 	       A12 : 0 <= ... <  200 DM\n 	       A13 :      ... >= 200 DM /\n 		     salary assignments for at least 1 year\n                A14 : no checking account\n \n Attribute 2:  (numerical)\n 	      Duration in month\n \n Attribute 3:  (qualitative)\n 	      Credit history\n 	      A30 : no credits taken/\n 		    all credits paid back duly\n               A31 : all credits at this bank paid back duly\n 	      A32 : existing credits paid back duly till now\n               A33 : delay in paying off in the past\n 	      A34 : critical account/\n 		    other credits existing (not at this bank)\n \n Attribute 4:  (qualitative)\n 	      Purpose\n 	      A40 : car (new)\n 	      A41 : car (used)\n 	      A42 : furniture/equipment\n 	      A43 : radio/television\n 	      A44 : domestic appliances\n 	      A45 : repairs\n 	      A46 : education\n 	      A47 : (vacation - does not exist?)\n 	      A48 : retraining\n 	      A49 : business\n 	      A410 : others\n \n Attribute 5:  (numerical)\n 	      Credit amount\n \n Attibute 6:  (qualitative)\n 	      Savings account/bonds\n 	      A61 :          ... <  100 DM\n 	      A62 :   100 <= ... <  500 DM\n 	      A63 :   500 <= ... < 1000 DM\n 	      A64 :          .. >= 1000 DM\n               A65 :   unknown/ no savings account\n \n Attribute 7:  (qualitative)\n 	      Present employment since\n 	      A71 : unemployed\n 	      A72 :       ... < 1 year\n 	      A73 : 1  <= ... < 4 years  \n 	      A74 : 4  <= ... < 7 years\n 	      A75 :       .. >= 7 years\n \n Attribute 8:  (numerical)\n 	      Installment rate in percentage of disposable income\n \n Attribute 9:  (qualitative)\n 	      Personal status and sex\n 	      A91 : male   : divorced/separated\n 	      A92 : female : divorced/separated/married\n               A93 : male   : single\n 	      A94 : male   : married/widowed\n 	      A95 : female : single\n \n Attribute 10: (qualitative)\n 	      Other debtors / guarantors\n 	      A101 : none\n 	      A102 : co-applicant\n 	      A103 : guarantor\n \n Attribute 11: (numerical)\n 	      Present residence since\n \n Attribute 12: (qualitative)\n 	      Property\n 	      A121 : real estate\n 	      A122 : if not A121 : building society savings agreement/\n 				   life insurance\n               A123 : if not A121/A122 : car or other, not in attribute 6\n 	      A124 : unknown / no property\n \n Attribute 13: (numerical)\n 	      Age in years\n \n Attribute 14: (qualitative)\n 	      Other installment plans \n 	      A141 : bank\n 	      A142 : stores\n 	      A143 : none\n \n Attribute 15: (qualitative)\n 	      Housing\n 	      A151 : rent\n 	      A152 : own\n 	      A153 : for free\n \n Attribute 16: (numerical)\n               Number of existing credits at this bank\n \n Attribute 17: (qualitative)\n 	      Job\n 	      A171 : unemployed/ unskilled  - non-resident\n 	      A172 : unskilled - resident\n 	      A173 : skilled employee / official\n 	      A174 : management/ self-employed/\n 		     highly qualified employee/ officer\n \n Attribute 18: (numerical)\n 	      Number of people being liable to provide maintenance for\n \n Attribute 19: (qualitative)\n 	      Telephone\n 	      A191 : none\n 	      A192 : yes, registered under the customers name\n \n Attribute 20: (qualitative)\n 	      foreign worker\n 	      A201 : yes\n 	      A202 : no\n \n \n \n 8.  Cost Matrix\n \n This dataset requires use of a cost matrix (see below)\n \n \n       1        2\n ----------------------------\n   1   0        1\n -----------------------\n   2   5        0\n \n (1 = Good,  2 = Bad)\n \n the rows represent the actual classification and the columns\n the predicted classification.\n \n It is worse to class a customer as good when they are bad (5), \n than it is to class a customer as bad when they are good (1).\n \n\n\n\n\n Relabeled values in attribute checking_status\n    From: A11                     To: \'<0\'                \n    From: A12                     To: \'0<=X<200\'          \n    From: A13                     To: \'>=200\'             \n    From: A14                     To: \'no checking\'       \n\n\n Relabeled values in attribute credit_history\n    From: A30                     To: \'no credits/all paid\'\n    From: A31                     To: \'all paid\'          \n    From: A32                     To: \'existing paid\'     \n    From: A33                     To: \'delayed previously\'\n    From: A34                     To: \'critical/other existing credit\'\n\n\n Relabeled values in attribute purpose\n    From: A40                     To: \'new car\'           \n    From: A41                     To: \'used car\'          \n    From: A42                     To: furniture/equipment \n    From: A43                     To: radio/tv            \n    From: A44                     To: \'domestic appliance\'\n    From: A45                     To: repairs             \n    From: A46                     To: education           \n    From: A47                     To: vacation            \n    From: A48                     To: retraining          \n    From: A49                     To: business            \n    From: A410                    To: other               \n\n\n Relabeled values in attribute savings_status\n    From: A61                     To: \'<100\'              \n    From: A62                     To: \'100<=X<500\'        \n    From: A63                     To: \'500<=X<1000\'       \n    From: A64                     To: \'>=1000\'            \n    From: A65                     To: \'no known savings\'  \n\n\n Relabeled values in attribute employment\n    From: A71                     To: unemployed          \n    From: A72                     To: \'<1\'                \n    From: A73                     To: \'1<=X<4\'            \n    From: A74                     To: \'4<=X<7\'            \n    From: A75                     To: \'>=7\'               \n\n\n Relabeled values in attribute personal_status\n    From: A91                     To: \'male div/sep\'      \n    From: A92                     To: \'female div/dep/mar\'\n    From: A93                     To: \'male single\'       \n    From: A94                     To: \'male mar/wid\'      \n    From: A95                     To: \'female single\'     \n\n\n Relabeled values in attribute other_parties\n    From: A101                    To: none                \n    From: A102                    To: \'co applicant\'      \n    From: A103                    To: guarantor           \n\n\n Relabeled values in attribute property_magnitude\n    From: A121                    To: \'real estate\'       \n    From: A122                    To: \'life insurance\'    \n    From: A123                    To: car                 \n    From: A124                    To: \'no known property\' \n\n\n Relabeled values in attribute other_payment_plans\n    From: A141                    To: bank                \n    From: A142                    To: stores              \n    From: A143                    To: none                \n\n\n Relabeled values in attribute housing\n    From: A151                    To: rent                \n    From: A152                    To: own                 \n    From: A153                    To: \'for free\'          \n\n\n Relabeled values in attribute job\n    From: A171                    To: \'unemp/unskilled non res\'\n    From: A172                    To: \'unskilled resident\'\n    From: A173                    To: skilled             \n    From: A174                    To: \'high qualif/self emp/mgmt\'\n\n\n Relabeled values in attribute own_telephone\n    From: A191                    To: none                \n    From: A192                    To: yes                 \n\n\n Relabeled values in attribute foreign_worker\n    From: A201                    To: yes                 \n    From: A202                    To: no                  \n\n\n Relabeled values in attribute class\n    From: 1                       To: good                \n    From: 2                       To: bad', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:21:47', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/31/dataset_31_credit-g.arff', 'true', 17, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:21:47'),
(18, 1, 0, 'pendigits', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title of Database: Pen-Based Recognition of Handwritten Digits\n \n 2. Source:\n 	E. Alpaydin, F. Alimoglu\n 	Department of Computer Engineering\n 	Bogazici University, 80815 Istanbul Turkey\n 	alpaydin@boun.edu.tr\n 	July 1998\n \n 3. Past Usage:\n 	F. Alimoglu (1996) Combining Multiple Classifiers for Pen-Based\n 	Handwritten Digit Recognition, \n 	MSc Thesis, Institute of Graduate Studies in Science and \n 	Engineering, Bogazici University.\n 	http://www.cmpe.boun.edu.tr/~alimoglu/alimoglu.ps.gz\n \n 	F. Alimoglu, E. Alpaydin, \"Methods of Combining Multiple Classifiers \n 	Based on Different Representations for Pen-based Handwriting\n 	Recognition,\" Proceedings of the Fifth Turkish Artificial \n 	Intelligence and Artificial Neural Networks Symposium (TAINN 96), \n 	June 1996, Istanbul, Turkey.\n 	http://www.cmpe.boun.edu.tr/~alimoglu/tainn96.ps.gz\n \n 	\n 4. Relevant Information:\n \n 	We create a digit database by collecting 250 samples from 44 writers.\n 	The samples written by 30 writers are used for training,\n 	cross-validation and writer dependent testing, and the digits \n 	written by the other 14 are used for writer independent testing. This\n 	database is also available in the UNIPEN format.\n \n 	We use a WACOM PL-100V pressure sensitive tablet with an integrated \n 	LCD display and a cordless stylus. The input and display areas are\n 	located in the same place. Attached to the serial port of an Intel \n 	486 based PC, it allows us to collect handwriting samples. The tablet\n 	sends $x$ and $y$ tablet coordinates and pressure level values of the\n 	pen at fixed time intervals (sampling rate) of 100 miliseconds. \n \n 	These writers are asked to write 250 digits in random order inside \n 	boxes of 500 by 500 tablet pixel resolution.  Subject are monitored \n 	only during the first entry screens. Each screen contains five boxes\n 	with the digits to be written displayed above. Subjects are told to\n 	write only inside these boxes.  If they make a mistake or are unhappy\n 	with their writing, they are instructed to clear the content of a box \n 	by using an on-screen button. The first ten digits are ignored \n 	because most writers are not familiar with this type of input devices,\n 	but subjects are not aware of this. \n \n 	In our study, we use only ($x, y$) coordinate information. The stylus\n 	pressure level values are ignored. First we apply normalization to \n 	make our representation invariant to translations and scale \n 	distortions. The raw data that we capture from the tablet consist of\n 	integer values between 0 and 500 (tablet input box resolution). The \n 	new coordinates are such that the coordinate which has the maximum \n 	range varies between 0 and 100. Usually $x$ stays in this range, since\n 	most characters are taller than they are wide.  \n \n 	In order to train and test our classifiers, we need to represent \n 	digits as constant length feature vectors. A commonly used technique\n 	leading to good results is resampling the ( x_t, y_t) points. \n 	Temporal resampling (points regularly spaced in time) or spatial\n 	resampling (points regularly spaced in arc length) can be used here. \n 	Raw point data are already regularly spaced in time but the distance\n 	between them is variable. Previous research showed that spatial\n 	resampling to obtain a constant number of regularly spaced points \n 	on the trajectory yields much better performance, because it provides \n 	a better alignment between points. Our resampling algorithm uses \n 	simple linear interpolation between pairs of points. The resampled\n 	digits are represented as a sequence of T points ( x_t, y_t )_{t=1}^T,\n 	regularly spaced in arc length, as opposed to the input sequence, \n 	which is regularly spaced in time.\n \n 	So, the input vector size is 2*T, two times the number of points\n 	resampled. We considered spatial resampling to T=8,12,16 points in our\n 	experiments and found that T=8 gave the best trade-off between \n 	accuracy and complexity.\n \n \n 5. Number of Instances\n 	pendigits.tra	Training	7494\n 	pendigits.tes	Testing		3498\n 	\n 	The way we used the dataset was to use first half of training for \n 	actual training, one-fourth for validation and one-fourth\n 	for writer-dependent testing. The test set was used for \n 	writer-independent testing and is the actual quality measure.\n \n 6. Number of Attributes\n 	16 input+1 class attribute\n \n 7. For Each Attribute:\n 	All input attributes are integers in the range 0..100.\n 	The last attribute is the class code 0..9\n \n 8. Missing Attribute Values\n 	None\n \n 9. Class Distribution\n 	Class: No of examples in training set\n 	0:  780\n 	1:  779\n 	2:  780\n 	3:  719\n 	4:  780\n 	5:  720\n 	6:  720\n 	7:  778\n 	8:  719\n 	9:  719\n 	Class: No of examples in testing set\n 	0:  363\n 	1:  364\n 	2:  364\n 	3:  336\n 	4:  364\n 	5:  335\n 	6:  336\n 	7:  364\n 	8:  336\n 	9:  336\n \n Accuracy on the testing set with k-nn \n using Euclidean distance as the metric\n \n  k =  1 : 97.74\n  k =  2 : 97.37\n  k =  3 : 97.80\n  k =  4 : 97.66\n  k =  5 : 97.60\n  k =  6 : 97.57\n  k =  7 : 97.54\n  k =  8 : 97.54\n  k =  9 : 97.46\n  k = 10 : 97.48\n  k = 11 : 97.34', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:21:54', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/32/dataset_32_pendigits.arff', 'true', 18, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:21:54'),
(19, 1, 0, 'segment', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Image Segmentation data\n \n 2. Source Information\n    -- Creators: Vision Group, University of Massachusetts\n    -- Donor: Vision Group (Carla Brodley, brodley@cs.umass.edu)\n    -- Date: November, 1990\n  \n 3. Past Usage: None yet published\n \n 4. Relevant Information:\n \n    The instances were drawn randomly from a database of 7 outdoor \n    images.  The images were handsegmented to create a classification\n    for every pixel.  \n \n    Each instance is a 3x3 region.\n \n 5. Number of Instances: Training data: 210  Test data: 2100\n \n 6. Number of Attributes: 19 continuous attributes\n \n 7. Attribute Information:\n \n     1.  region-centroid-col:  the column of the center pixel of the region.\n     2.  region-centroid-row:  the row of the center pixel of the region.\n     3.  region-pixel-count:  the number of pixels in a region = 9.\n     4.  short-line-density-5:  the results of a line extractoin algorithm that \n          counts how many lines of length 5 (any orientation) with\n          low contrast, less than or equal to 5, go through the region.\n     5.  short-line-density-2:  same as short-line-density-5 but counts lines\n          of high contrast, greater than 5.\n     6.  vedge-mean:  measure the contrast of horizontally\n          adjacent pixels in the region.  There are 6, the mean and \n          standard deviation are given.  This attribute is used as\n         a vertical edge detector.\n     7.  vegde-sd:  (see 6)\n     8.  hedge-mean:  measures the contrast of vertically adjacent\n           pixels. Used for horizontal line detection. \n     9.  hedge-sd: (see 8).\n     10. intensity-mean:  the average over the region of (R + G + B)/3\n     11. rawred-mean: the average over the region of the R value.\n     12. rawblue-mean: the average over the region of the B value.\n     13. rawgreen-mean: the average over the region of the G value.\n     14. exred-mean: measure the excess red:  (2R - (G + B))\n     15. exblue-mean: measure the excess blue:  (2B - (G + R))\n     16. exgreen-mean: measure the excess green:  (2G - (R + B))\n     17. value-mean:  3-d nonlinear transformation\n          of RGB. (Algorithm can be found in Foley and VanDam, Fundamentals\n          of Interactive Computer Graphics)\n     18. saturatoin-mean:  (see 17)\n     19. hue-mean:  (see 17)\n \n 8. Missing Attribute Values: None\n \n 9. Class Distribution: \n \n    Classes:  brickface, sky, foliage, cement, window, path, grass.\n \n    30 instances per class for training data.\n    300 instances per class for test data.\n \n\n\n\n\n Relabeled values in attribute class\n    From: 1                       To: brickface           \n    From: 2                       To: sky                 \n    From: 3                       To: foliage             \n    From: 4                       To: cement              \n    From: 5                       To: window              \n    From: 6                       To: path                \n    From: 7                       To: grass', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:22:10', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/36/dataset_36_segment.arff', 'true', 19, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:22:10'),
(20, 1, 0, 'diabetes', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Pima Indians Diabetes Database\n \n 2. Sources:\n    (a) Original owners: National Institute of Diabetes and Digestive and\n                         Kidney Diseases\n    (b) Donor of database: Vincent Sigillito (vgs@aplcen.apl.jhu.edu)\n                           Research Center, RMI Group Leader\n                           Applied Physics Laboratory\n                           The Johns Hopkins University\n                           Johns Hopkins Road\n                           Laurel, MD 20707\n                           (301) 953-6231\n    (c) Date received: 9 May 1990\n \n 3. Past Usage:\n     1. Smith,~J.~W., Everhart,~J.~E., Dickson,~W.~C., Knowler,~W.~C., &\n        Johannes,~R.~S. (1988). Using the ADAP learning algorithm to forecast\n        the onset of diabetes mellitus.  In {it Proceedings of the Symposium\n        on Computer Applications and Medical Care} (pp. 261--265).  IEEE\n        Computer Society Press.\n \n        The diagnostic, binary-valued variable investigated is whether the\n        patient shows signs of diabetes according to World Health Organization\n        criteria (i.e., if the 2 hour post-load plasma glucose was at least \n        200 mg/dl at any survey  examination or if found during routine medical\n        care).   The population lives near Phoenix, Arizona, USA.\n \n        Results: Their ADAP algorithm makes a real-valued prediction between\n        0 and 1.  This was transformed into a binary decision using a cutoff of \n        0.448.  Using 576 training instances, the sensitivity and specificity\n        of their algorithm was 76% on the remaining 192 instances.\n \n 4. Relevant Information:\n       Several constraints were placed on the selection of these instances from\n       a larger database.  In particular, all patients here are females at\n       least 21 years old of Pima Indian heritage.  ADAP is an adaptive learning\n       routine that generates and executes digital analogs of perceptron-like\n       devices.  It is a unique algorithm; see the paper for details.\n \n 5. Number of Instances: 768\n \n 6. Number of Attributes: 8 plus class \n \n 7. For Each Attribute: (all numeric-valued)\n    1. Number of times pregnant\n    2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n    3. Diastolic blood pressure (mm Hg)\n    4. Triceps skin fold thickness (mm)\n    5. 2-Hour serum insulin (mu U/ml)\n    6. Body mass index (weight in kg/(height in m)^2)\n    7. Diabetes pedigree function\n    8. Age (years)\n    9. Class variable (0 or 1)\n \n 8. Missing Attribute Values: None\n \n 9. Class Distribution: (class value 1 is interpreted as \"tested positive for\n    diabetes\")\n \n    Class Value  Number of instances\n    0            500\n    1            268\n \n 10. Brief statistical analysis:\n \n     Attribute number:    Mean:   Standard Deviation:\n     1.                     3.8     3.4\n     2.                   120.9    32.0\n     3.                    69.1    19.4\n     4.                    20.5    16.0\n     5.                    79.8   115.2\n     6.                    32.0     7.9\n     7.                     0.5     0.3\n     8.                    33.2    11.8\n \n \n\n\n\n\n Relabeled values in attribute \'class\'\n    From: 0                       To: tested_negative     \n    From: 1                       To: tested_positive', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:22:13', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/37/dataset_37_diabetes.arff', 'true', 20, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:22:13'),
(21, 1, 0, 'sick', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n;\n ; Thyroid disease records supplied by the Garavan Institute and J. Ross\n ; Quinlan, New South Wales Institute, Syndney, Australia.\n ;\n ; 1987.\n ;\n \n sick, negative.			|  classes\n \n age:				continuous.\n sex:				M, F.\n on thyroxine:			f, t.\n query on thyroxine:		f, t.\n on antithyroid medication:	f, t.\n sick:				f, t.\n pregnant:			f, t.\n thyroid surgery:		f, t.\n I131 treatment:			f, t.\n query hypothyroid:		f, t.\n query hyperthyroid:		f, t.\n lithium:			f, t.\n goitre:				f, t.\n tumor:				f, t.\n hypopituitary:			f, t.\n psych:				f, t.\n TSH measured:			f, t.\n TSH:				continuous.\n T3 measured:			f, t.\n T3:				continuous.\n TT4 measured:			f, t.\n TT4:				continuous.\n T4U measured:			f, t.\n T4U:				continuous.\n FTI measured:			f, t.\n FTI:				continuous.\n TBG measured:			f, t.\n TBG:				continuous.\n referral source:		WEST, STMW, SVHC, SVI, SVHD, other.\n \n\n Num Instances:     3772\n Num Attributes:    30\n Num Continuous:    7 (Int 1 / Real 6)\n Num Discrete:      23\n Missing values:    6064 /  5.4%\n\n     name                      type enum ints real     missing    distinct  (1)\n   1 \'age\'                     Int    0% 100%   0%     1 /  0%    93 /  2%   0% \n   2 \'sex\'                     Enum  96%   0%   0%   150 /  4%     2 /  0%   0% \n   3 \'on thyroxine\'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   4 \'query on thyroxine\'      Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   5 \'on antithyroid medicati  Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   6 \'sick\'                    Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   7 \'pregnant\'                Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   8 \'thyroid surgery\'         Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   9 \'I131 treatment\'          Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  10 \'query hypothyroid\'       Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  11 \'query hyperthyroid\'      Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  12 \'lithium\'                 Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  13 \'goitre\'                  Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  14 \'tumor\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  15 \'hypopituitary\'           Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  16 \'psych\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  17 \'TSH measured\'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  18 \'TSH\'                     Real   0%  11%  79%   369 / 10%   287 /  8%   2% \n  19 \'T3 measured\'             Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  20 \'T3\'                      Real   0%   9%  71%   769 / 20%    69 /  2%   0% \n  21 \'TT4 measured\'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  22 \'TT4\'                     Real   0%  94%   0%   231 /  6%   241 /  6%   1% \n  23 \'T4U measured\'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  24 \'T4U\'                     Real   0%   2%  87%   387 / 10%   146 /  4%   1% \n  25 \'FTI measured\'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  26 \'FTI\'                     Real   0%  90%   0%   385 / 10%   234 /  6%   2% \n  27 \'TBG measured\'            Enum 100%   0%   0%     0 /  0%     1 /  0%   0% \n  28 \'TBG\'                     Real   0%   0%   0%  3772 /100%     0 /  0%   0% \n  29 \'referral source\'         Enum 100%   0%   0%     0 /  0%     5 /  0%   0% \n  30 \'Class\'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0%', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:22:19', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/38/dataset_38_sick.arff', 'true', 21, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:22:19'),
(22, 1, 0, 'soybean', '1', '1', '**Author**: R.S. Michalski and R.L. Chilausky (Donors: Ming Tan & Jeff Schlimmer)  \r\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Soybean+(Large)) - 1988  \r\n**Please cite**: R.S. Michalski and R.L. Chilausky \"Learning by Being Told and Learning from Examples: An Experimental Comparison of the Two Methods of Knowledge Acquisition in the Context of Developing an Expert System for Soybean Disease Diagnosis\", International Journal of Policy Analysis and Information Systems, Vol. 4, No. 2, 1980.  \r\n\r\n**Large Soybean Database**  \r\nThis is the large soybean database from the UCI repository, with its training and test database combined into a single file. There are 19 classes, only the first 15 of which have been used in prior work.  The folklore seems to be that the last four classes are unjustified by the data since they have so few examples. There are 35 categorical attributes, some nominal and some ordered.  The value \'dna\' means does not apply.  The values for attributes are encoded numerically, with the first value encoded as \'0\', the second as \'1\', and so forth.  An unknown values is encoded as \'?\'.', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:22:32', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/42/dataset_42_soybean.arff', 'true', 22, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:22:32'),
(23, 1, 0, 'spambase', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title:  SPAM E-mail Database\n \n 2. Sources:\n    (a) Creators: Mark Hopkins, Erik Reeber, George Forman, Jaap Suermondt\n         Hewlett-Packard Labs, 1501 Page Mill Rd., Palo Alto, CA 94304\n    (b) Donor: George Forman (gforman at nospam hpl.hp.com)  650-857-7835\n    (c) Generated: June-July 1999\n \n 3. Past Usage:\n    (a) Hewlett-Packard Internal-only Technical Report. External forthcoming.\n    (b) Determine whether a given email is spam or not.\n    (c) ~7% misclassification error.\n        False positives (marking good mail as spam) are very undesirable.\n        If we insist on zero false positives in the training/testing set,\n        20-25% of the spam passed through the filter.\n \n 4. Relevant Information:\n         The \"spam\" concept is diverse: advertisements for products/web\n         sites, make money fast schemes, chain letters, pornography...\n 	Our collection of spam e-mails came from our postmaster and \n 	individuals who had filed spam.  Our collection of non-spam \n 	e-mails came from filed work and personal e-mails, and hence\n 	the word \'george\' and the area code \'650\' are indicators of \n 	non-spam.  These are useful when constructing a personalized \n 	spam filter.  One would either have to blind such non-spam \n 	indicators or get a very wide collection of non-spam to \n 	generate a general purpose spam filter.\n \n         For background on spam:\n         Cranor, Lorrie F., LaMacchia, Brian A.  Spam! \n         Communications of the ACM, 41(8):74-83, 1998.\n \n 5. Number of Instances: 4601 (1813 Spam = 39.4%)\n \n 6. Number of Attributes: 58 (57 continuous, 1 nominal class label)\n \n 7. Attribute Information:\n The last column of \'spambase.data\' denotes whether the e-mail was \n considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \n Most of the attributes indicate whether a particular word or\n character was frequently occuring in the e-mail.  The run-length\n attributes (55-57) measure the length of sequences of consecutive \n capital letters.  For the statistical measures of each attribute, \n see the end of this file.  Here are the definitions of the attributes:\n \n 48 continuous real [0,100] attributes of type word_freq_WORD \n = percentage of words in the e-mail that match WORD,\n i.e. 100 * (number of times the WORD appears in the e-mail) / \n total number of words in e-mail.  A \"word\" in this case is any \n string of alphanumeric characters bounded by non-alphanumeric \n characters or end-of-string.\n \n 6 continuous real [0,100] attributes of type char_freq_CHAR\n = percentage of characters in the e-mail that match CHAR,\n i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n \n 1 continuous real [1,...] attribute of type capital_run_length_average\n = average length of uninterrupted sequences of capital letters\n \n 1 continuous integer [1,...] attribute of type capital_run_length_longest\n = length of longest uninterrupted sequence of capital letters\n \n 1 continuous integer [1,...] attribute of type capital_run_length_total\n = sum of length of uninterrupted sequences of capital letters\n = total number of capital letters in the e-mail\n \n 1 nominal {0,1} class attribute of type spam\n = denotes whether the e-mail was considered spam (1) or not (0), \n i.e. unsolicited commercial e-mail.  \n \n \n 8. Missing Attribute Values: None\n \n 9. Class Distribution:\n 	Spam	  1813  (39.4%)\n 	Non-Spam  2788  (60.6%)\n \n \n Attribute Statistics:\n    Min: Max:   Average:  Std.Dev: Coeff.Var_%: \n 1  0    4.54   0.10455   0.30536  292          \n 2  0    14.28  0.21301   1.2906   606          \n 3  0    5.1    0.28066   0.50414  180          \n 4  0    42.81  0.065425  1.3952   2130         \n 5  0    10     0.31222   0.67251  215          \n 6  0    5.88   0.095901  0.27382  286          \n 7  0    7.27   0.11421   0.39144  343          \n 8  0    11.11  0.10529   0.40107  381          \n 9  0    5.26   0.090067  0.27862  309          \n 10 0    18.18  0.23941   0.64476  269          \n 11 0    2.61   0.059824  0.20154  337          \n 12 0    9.67   0.5417    0.8617   159          \n 13 0    5.55   0.09393   0.30104  320          \n 14 0    10     0.058626  0.33518  572          \n 15 0    4.41   0.049205  0.25884  526          \n 16 0    20     0.24885   0.82579  332          \n 17 0    7.14   0.14259   0.44406  311          \n 18 0    9.09   0.18474   0.53112  287          \n 19 0    18.75  1.6621    1.7755   107          \n 20 0    18.18  0.085577  0.50977  596          \n 21 0    11.11  0.80976   1.2008   148          \n 22 0    17.1   0.1212    1.0258   846          \n 23 0    5.45   0.10165   0.35029  345          \n 24 0    12.5   0.094269  0.44264  470          \n 25 0    20.83  0.5495    1.6713   304          \n 26 0    16.66  0.26538   0.88696  334          \n 27 0    33.33  0.7673    3.3673   439          \n 28 0    9.09   0.12484   0.53858  431          \n 29 0    14.28  0.098915  0.59333  600          \n 30 0    5.88   0.10285   0.45668  444          \n 31 0    12.5   0.064753  0.40339  623          \n 32 0    4.76   0.047048  0.32856  698          \n 33 0    18.18  0.097229  0.55591  572          \n 34 0    4.76   0.047835  0.32945  689          \n 35 0    20     0.10541   0.53226  505          \n 36 0    7.69   0.097477  0.40262  413          \n 37 0    6.89   0.13695   0.42345  309          \n 38 0    8.33   0.013201  0.22065  1670         \n 39 0    11.11  0.078629  0.43467  553          \n 40 0    4.76   0.064834  0.34992  540          \n 41 0    7.14   0.043667  0.3612   827          \n 42 0    14.28  0.13234   0.76682  579          \n 43 0    3.57   0.046099  0.22381  486          \n 44 0    20     0.079196  0.62198  785          \n 45 0    21.42  0.30122   1.0117   336          \n 46 0    22.05  0.17982   0.91112  507          \n 47 0    2.17   0.0054445 0.076274 1400         \n 48 0    10     0.031869  0.28573  897          \n 49 0    4.385  0.038575  0.24347  631          \n 50 0    9.752  0.13903   0.27036  194          \n 51 0    4.081  0.016976  0.10939  644          \n 52 0    32.478 0.26907   0.81567  303          \n 53 0    6.003  0.075811  0.24588  324          \n 54 0    19.829 0.044238  0.42934  971          \n 55 1    1102.5 5.1915    31.729   611          \n 56 1    9989   52.173    194.89   374          \n 57 1    15841  283.29    606.35   214          \n 58 0    1      0.39404   0.4887   124          \n \n \n This file: \'spambase.DOCUMENTATION\' at the UCI Machine Learning Repository\n http://www.ics.uci.edu/~mlearn/MLRepository.html\n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:22:41', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/44/dataset_44_spambase.arff', 'true', 23, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:22:41'),
(24, 1, 0, 'splice', '1', '1', '**Author**: Genbank  \nDonor: G. Towell, M. Noordewier, and J. Shavlik  \n**Source**: [Genbank 64.1](genbank.bio.net) - 1/1/92  \n**Please cite**:   \n\nPrimate splice-junction gene sequences (DNA) with associated imperfect domain theory. All examples taken from Genbank 64.1. Categories \"ei\" and \"ie\" include every \"split-gene\" for primates in Genbank 64.1. Non-splice examples taken from sequences known not to include a splicing site.\n \nProblem Description:  \nSplice junctions are points on a DNA sequence at which \'superfluous\' DNA is removed during the process of protein creation in higher organisms. The problem posed in this dataset is to recognize, given a sequence of DNA, the boundaries between exons (the parts of the DNA sequence retained after splicing) and introns (the parts of the DNA sequence that are spliced out). This problem consists of two subtasks: recognizing exon/intron boundaries (referred to as EI sites), and recognizing intron/exon boundaries (IE sites). (In the biological community, IE borders are referred to a \'\'acceptors\'\' while EI borders are referred to as \'\'donors\'\'.)\n \nThis dataset has been developed to help evaluate a \"hybrid\" learning algorithm (KBANN) that uses examples to inductively refine preexisting knowledge.\n        \nAttributes:  \n>\n              1   One of {n ei ie}, indicating the class.\n              2   The instance name.\n           3-62   The remaining 60 fields are the sequence, starting at \n                  position -30 and ending at position +30. Each of\n                  these fields is almost always filled by one of \n                  {a, g, t, c}. Other characters indicate ambiguity among\n                  the standard characters according to the following table:\n    character: meaning\n        D: A or G or T\n        N: A or G or C or T\n        S: C or G\n        R: A or G\n\nNotes:  \n* Instance_name is an identifier and should be ignored for modelling', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:22:49', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/46/dataset_46_splice.arff', 'true', 24, 'Class', NULL, 'Instance_name', NULL, 'public', NULL, NULL, 'Instance_name is an identifier and should be ignored for modelling', '2014-09-19 17:06:29'),
(25, 1, 0, 'tic-tac-toe', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Tic-Tac-Toe Endgame database\n \n 2. Source Information\n    -- Creator: David W. Aha (aha@cs.jhu.edu)\n    -- Donor: David W. Aha (aha@cs.jhu.edu)\n    -- Date: 19 August 1991\n  \n 3. Known Past Usage: \n    1. Matheus,~C.~J., & Rendell,~L.~A. (1989).  Constructive\n       induction on decision trees.  In {it Proceedings of the\n       Eleventh International Joint Conference on Artificial Intelligence} \n       (pp. 645--650).  Detroit, MI: Morgan Kaufmann.\n       -- CITRE was applied to 100-instance training and 200-instance test\n          sets.  In a study using various amounts of domain-specific\n          knowledge, its highest average accuracy was 76.7% (using the\n          final decision tree created for testing).\n \n    2. Matheus,~C.~J. (1990). Adding domain knowledge to SBL through\n       feature construction.  In {it Proceedings of the Eighth National\n       Conference on Artificial Intelligence} (pp. 803--808). \n       Boston, MA: AAAI Press.\n       -- Similar experiments with CITRE, includes learning curves up\n          to 500-instance training sets but used _all_ instances in the\n          database for testing.  Accuracies reached above 90%, but specific\n          values are not given (see Chris\'s dissertation for more details).\n \n    3. Aha,~D.~W. (1991). Incremental constructive induction: An instance-based\n       approach.  In {it Proceedings of the Eighth International Workshop\n       on Machine Learning} (pp. 117--121).  Evanston, ILL: Morgan Kaufmann.\n       -- Used 70% for training, 30% of the instances for testing, evaluated\n          over 10 trials.  Results reported for six algorithms:\n          -- NewID:   84.0%\n          -- CN2:     98.1%  \n          -- MBRtalk: 88.4%\n          -- IB1:     98.1% \n          -- IB3:     82.0%\n          -- IB3-CI:  99.1%\n       -- Results also reported when adding an additional 10 irrelevant \n          ternary-valued attributes; similar _relative_ results except that\n          IB1\'s performance degraded more quickly than the others.\n \n 4. Relevant Information:\n \n    This database encodes the complete set of possible board configurations\n    at the end of tic-tac-toe games, where \"x\" is assumed to have played\n    first.  The target concept is \"win for x\" (i.e., true when \"x\" has one\n    of 8 possible ways to create a \"three-in-a-row\").  \n \n    Interestingly, this raw database gives a stripped-down decision tree\n    algorithm (e.g., ID3) fits.  However, the rule-based CN2 algorithm, the\n    simple IB1 instance-based learning algorithm, and the CITRE \n    feature-constructing decision tree algorithm perform well on it.\n \n 5. Number of Instances: 958 (legal tic-tac-toe endgame boards)\n \n 6. Number of Attributes: 9, each corresponding to one tic-tac-toe square\n \n 7. Attribute Information: (x=player x has taken, o=player o has taken, b=blank)\n \n     1. top-left-square: {x,o,b}\n     2. top-middle-square: {x,o,b}\n     3. top-right-square: {x,o,b}\n     4. middle-left-square: {x,o,b}\n     5. middle-middle-square: {x,o,b}\n     6. middle-right-square: {x,o,b}\n     7. bottom-left-square: {x,o,b}\n     8. bottom-middle-square: {x,o,b}\n     9. bottom-right-square: {x,o,b}\n    10. Class: {positive,negative}\n \n 8. Missing Attribute Values: None\n \n 9. Class Distribution: About 65.3% are positive (i.e., wins for \"x\")\n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:22:59', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/50/dataset_50_tic-tac-toe.arff', 'true', 25, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:22:59'),
(26, 1, 0, 'vehicle', '1', '1', '**Author**:  Peter Mowforth  \n**Source**: UCI -   \n**Please cite**: Siebert,JP. Turing Institute Research Memorandum TIRM-87-018 \"Vehicle Recognition Using Rule Based Methods\" (March 1987)  \n\n NAME\n         vehicle silhouettes\n \n PURPOSE\n         to classify a given silhouette as one of four types of vehicle,\n         using  a set of features extracted from the silhouette. The\n         vehicle may be viewed from one of many different angles.  \n \n PROBLEM TYPE\n         classification\n         \n SOURCE\n         Drs.Pete Mowforth and Barry Shepherd\n         Turing Institute\n         George House\n         36 North Hanover St.\n         Glasgow\n         G1 2AD\n \n CONTACT\n         Alistair Sutherland\n         Statistics Dept.\n         Strathclyde University\n         Livingstone Tower\n         26 Richmond St.\n         GLASGOW G1 1XH\n         Great Britain\n         \n         Tel: 041 552 4400 x3033\n         \n         Fax: 041 552 4711 \n         \n         e-mail: alistair@uk.ac.strathclyde.stams\n \n HISTORY\n         This data was originally gathered at the TI in 1986-87 by\n         JP Siebert. It was partially financed by Barr and Stroud Ltd.\n         The original purpose was to find a method of distinguishing\n         3D objects within a 2D image by application of an ensemble of\n         shape feature extractors to the 2D silhouettes of the objects.\n         Measures of shape features extracted from example silhouettes\n         of objects to be discriminated were used to generate a class-\n         ification rule tree by means of computer induction.\n          This object recognition strategy was successfully used to \n         discriminate between silhouettes of model cars, vans and buses\n         viewed from constrained elevation but all angles of rotation.\n          The rule tree classification performance compared favourably\n         to MDC (Minimum Distance Classifier) and k-NN (k-Nearest Neigh-\n         bour) statistical classifiers in terms of both error rate and\n         computational efficiency. An investigation of these rule trees\n         generated by example indicated that the tree structure was \n         heavily influenced by the orientation of the objects, and grouped\n         similar object views into single decisions.\n \n DESCRIPTION\n          The features were extracted from the silhouettes by the HIPS\n         (Hierarchical Image Processing System) extension BINATTS, which \n         extracts a combination of scale independent features utilising\n         both classical moments based measures such as scaled variance,\n         skewness and kurtosis about the major/minor axes and heuristic\n         measures such as hollows, circularity, rectangularity and\n         compactness.\n          Four \"Corgie\" model vehicles were used for the experiment:\n         a double decker bus, Cheverolet van, Saab 9000 and an Opel Manta 400.\n         This particular combination of vehicles was chosen with the \n         expectation that the bus, van and either one of the cars would\n         be readily distinguishable, but it would be more difficult to\n         distinguish between the cars.\n          The images were acquired by a camera looking downwards at the\n         model vehicle from a fixed angle of elevation (34.2 degrees\n         to the horizontal). The vehicles were placed on a diffuse\n         backlit surface (lightbox). The vehicles were painted matte black\n         to minimise highlights. The images were captured using a CRS4000\n         framestore connected to a vax 750. All images were captured with\n         a spatial resolution of 128x128 pixels quantised to 64 greylevels.\n         These images were thresholded to produce binary vehicle silhouettes,\n         negated (to comply with the processing requirements of BINATTS) and\n         thereafter subjected to shrink-expand-expand-shrink HIPS modules to\n         remove \"salt and pepper\" image noise.\n          The vehicles were rotated and their angle of orientation was measured\n         using a radial graticule beneath the vehicle. 0 and 180 degrees\n         corresponded to \"head on\" and \"rear\" views respectively while 90 and\n         270 corresponded to profiles in opposite directions. Two sets of\n         60 images, each set covering a full 360 degree rotation, were captured\n         for each vehicle. The vehicle was rotated by a fixed angle between \n         images. These datasets are known as e2 and e3 respectively.\n          A further two sets of images, e4 and e5, were captured with the camera \n         at elevations of 37.5 degs and 30.8 degs respectively. These sets\n         also contain 60 images per vehicle apart from e4.van which contains\n         only 46 owing to the difficulty of containing the van in the image\n         at some orientations.\n \n ATTRIBUTES\n         \n         COMPACTNESS     (average perim)**2/area\n         \n         CIRCULARITY     (average radius)**2/area\n         \n         DISTANCE CIRCULARITY    area/(av.distance from border)**2\n         \n         RADIUS RATIO    (max.rad-min.rad)/av.radius\n         \n         PR.AXIS ASPECT RATIO    (minor axis)/(major axis)\n         \n         MAX.LENGTH ASPECT RATIO (length perp. max length)/(max length)\n         \n         SCATTER RATIO   (inertia about minor axis)/(inertia about major axis)\n         \n         ELONGATEDNESS           area/(shrink width)**2\n         \n         PR.AXIS RECTANGULARITY  area/(pr.axis length*pr.axis width)\n         \n         MAX.LENGTH RECTANGULARITY area/(max.length*length perp. to this)\n         \n         SCALED VARIANCE         (2nd order moment about minor axis)/area\n         ALONG MAJOR AXIS\n         \n         SCALED VARIANCE         (2nd order moment about major axis)/area\n         ALONG MINOR AXIS \n         \n         SCALED RADIUS OF GYRATION       (mavar+mivar)/area\n         \n         SKEWNESS ABOUT  (3rd order moment about major axis)/sigma_min**3\n         MAJOR AXIS\n         \n         SKEWNESS ABOUT  (3rd order moment about minor axis)/sigma_maj**3\n         MINOR AXIS\n                 \n         KURTOSIS ABOUT  (4th order moment about major axis)/sigma_min**4\n         MINOR AXIS  \n                 \n         KURTOSIS ABOUT  (4th order moment about minor axis)/sigma_maj**4\n         MAJOR AXIS\n         \n         HOLLOWS RATIO   (area of hollows)/(area of bounding polygon)\n         \n          Where sigma_maj**2 is the variance along the major axis and\n         sigma_min**2 is the variance along the minor axis, and\n         \n         area of hollows= area of bounding poly-area of object \n         \n          The area of the bounding polygon is found as a side result of\n         the computation to find the maximum length. Each individual\n         length computation yields a pair of calipers to the object\n         orientated at every 5 degrees. The object is propagated into\n         an image containing the union of these calipers to obtain an\n         image of the bounding polygon. \n         \n NUMBER OF CLASSES\n \n         4       OPEL, SAAB, BUS, VAN\n \n NUMBER OF EXAMPLES\n \n                 Total no. = 946\n                 \n                 No. in each class\n                 \n                   opel 240\n                   saab 240\n                   bus  240\n                   van  226\n                 \n                 \n                 100 examples are being kept by Strathclyde for validation.\n                 So StatLog partners will receive 846 examples.\n \n NUMBER OF ATTRIBUTES\n \n                 No. of atts. = 18', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:23:10', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/54/dataset_54_vehicle.arff', 'true', 26, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:23:10'),
(27, 1, 0, 'waveform-5000', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Waveform Database Generator (written in C)\n  \n 2. Source:\n    (a) Breiman,L., Friedman,J.H., Olshen,R.A., & Stone,C.J. (1984). \n        Classification and Regression Trees.  Wadsworth International\n        Group: Belmont, California.  (see pages 43-49).\n    (b) Donor: David Aha \n    (c) Date: 11/10/1988\n \n 3. Past Usage:\n      1. CART book (above):\n         -- Optimal Bayes classification rate: 86% accuracy\n         -- CART decision tree algorithm: 72%\n         -- Nearest Neighbor Algorithm: 78%\n            --	300 training and 5000 test instances\n \n 4. Relevant Information:\n      -- 3 classes of waves\n      -- 21 attributes, all of which include noise\n      -- See the book for details (49-55, 169)\n      -- waveform.data.Z contains 5000 instances\n \n 5. Number of Instances: chosen by user\n \n 6. Number of Attributes:\n     -- 21 attributes with continuous values between 0 and 6\n \n 7. Attribute Information:\n     -- Each class is generated from a combination of 2 of 3 \"base\" waves\n     -- Each instance is generated f added noise (mean 0, variance 1) in \n        each attribute\n      -- See the book for details (49-55, 169)\n     \n 8. Missing Attribute Values: none\n \n 9. Class Distribution: 33% for each of 3 classes', 'ARFF', NULL, NULL, NULL, '2014-04-06 23:23:37', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/60/dataset_60_waveform-5000.arff', 'true', 27, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-06 23:23:37'),
(28, 1, 0, 'electricity', '1', '1', '**Author**: M. Harries, J. Gama, A. Bifet  \n**Source**: [Gama](http://www.inescporto.pt/~jgama/ales/ales_5.html) - 2009  \n**Please cite**:   \n\n**Electricity** is a widely used dataset described by M. Harries and analysed by Gama. This data was collected from the Australian New South Wales Electricity Market. In this market, prices are not fixed and are affected by demand and supply of the market. They are set every five minutes. The ELEC dataset contains 45, 312 instances. The class label identifies the change of the price relative to a moving average of the last 24 hours.', 'ARFF', NULL, NULL, NULL, '2014-04-10 02:42:23', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/2419/electricity-normalized.arff', 'true', 28, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-10 02:42:23'),
(29, 1, 0, 'satimage', '1', '1', '**Author**: Ashwin Srinivasan, Department of Statistics and Data Modeling, University of Strathclyde \r\n**Source**: https://archive.ics.uci.edu/ml/datasets/Statlog+(Landsat+Satellite)\r\n**Please cite**:   \r\n\r\nThe database consists of the multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. The aim is to predict this classification, given the multi-spectral values. In the sample database, the class of a pixel is coded as a number.', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:14:59', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3619/dataset_186_satimage.arff', 'true', 29, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:14:59'),
(30, 1, 0, 'abalone', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title of Database: Abalone data\n \n 2. Sources:\n \n    (a) Original owners of database:\n 	Marine Resources Division\n 	Marine Research Laboratories - Taroona\n 	Department of Primary Industry and Fisheries, Tasmania\n 	GPO Box 619F, Hobart, Tasmania 7001, Australia\n 	(contact: Warwick Nash +61 02 277277, wnash@dpi.tas.gov.au)\n \n    (b) Donor of database:\n 	Sam Waugh (Sam.Waugh@cs.utas.edu.au)\n 	Department of Computer Science, University of Tasmania\n 	GPO Box 252C, Hobart, Tasmania 7001, Australia\n \n    (c) Date received: December 1995\n \n \n 3. Past Usage:\n \n    Sam Waugh (1995) \"Extending and benchmarking Cascade-Correlation\", PhD\n    thesis, Computer Science Department, University of Tasmania.\n \n    -- Test set performance (final 1044 examples, first 3133 used for training):\n 	24.86% Cascade-Correlation (no hidden nodes)\n 	26.25% Cascade-Correlation (5 hidden nodes)\n 	21.5%  C4.5\n 	 0.0%  Linear Discriminate Analysis\n 	 3.57% k=5 Nearest Neighbour\n       (Problem encoded as a classification task)\n \n    -- Data set samples are highly overlapped.  Further information is required\n 	to separate completely using affine combinations.  Other restrictions\n 	to data set examined.\n \n    David Clark, Zoltan Schreter, Anthony Adams \"A Quantitative Comparison of\n    Dystal and Backpropagation\", submitted to the Australian Conference on\n    Neural Networks (ACNN\'96). Data set treated as a 3-category classification\n    problem (grouping ring classes 1-8, 9 and 10, and 11 on).\n \n    -- Test set performance (3133 training, 1044 testing as above):\n 	64%    Backprop\n 	55%    Dystal\n    -- Previous work (Waugh, 1995) on same data set:\n 	61.40% Cascade-Correlation (no hidden nodes)\n 	65.61% Cascade-Correlation (5 hidden nodes)\n 	59.2%  C4.5\n 	32.57% Linear Discriminate Analysis\n 	62.46% k=5 Nearest Neighbour\n \n \n 4. Relevant Information Paragraph:\n \n    Predicting the age of abalone from physical measurements.  The age of\n    abalone is determined by cutting the shell through the cone, staining it,\n    and counting the number of rings through a microscope -- a boring and\n    time-consuming task.  Other measurements, which are easier to obtain, are\n    used to predict the age.  Further information, such as weather patterns\n    and location (hence food availability) may be required to solve the problem.\n \n    From the original data examples with missing values were removed (the\n    majority having the predicted value missing), and the ranges of the\n    continuous values have been scaled for use with an ANN (by dividing by 200).\n \n    Data comes from an original (non-machine-learning) study:\n \n 	Warwick J Nash, Tracy L Sellers, Simon R Talbot, Andrew J Cawthorn and\n 	Wes B Ford (1994) \"The Population Biology of Abalone (_Haliotis_\n 	species) in Tasmania. I. Blacklip Abalone (_H. rubra_) from the North\n 	Coast and Islands of Bass Strait\", Sea Fisheries Division, Technical\n 	Report No. 48 (ISSN 1034-3288)\n \n \n 5. Number of Instances: 4177\n \n \n 6. Number of Attributes: 8\n \n \n 7. Attribute information:\n \n    Given is the attribute name, attribute type, the measurement unit and a\n    brief description.  The number of rings is the value to predict: either\n    as a continuous value or as a classification problem.\n \n 	Name		Data Type	Meas.	Description\n 	----		---------	-----	-----------\n 	Sex		nominal			M, F, and I (infant)\n 	Length		continuous	mm	Longest shell measurement\n 	Diameter	continuous	mm	perpendicular to length\n 	Height		continuous	mm	with meat in shell\n 	Whole weight	continuous	grams	whole abalone\n 	Shucked weight	continuous	grams	weight of meat\n 	Viscera weight	continuous	grams	gut weight (after bleeding)\n 	Shell weight	continuous	grams	after being dried\n 	Rings		integer			+1.5 gives the age in years\n \n    Statistics for numeric domains:\n \n 		Length	Diam	Height	Whole	Shucked	Viscera	Shell	Rings\n 	Min	0.075	0.055	0.000	0.002	0.001	0.001	0.002	    1\n 	Max	0.815	0.650	1.130	2.826	1.488	0.760	1.005	   29\n 	Mean	0.524	0.408	0.140	0.829	0.359	0.181	0.239	9.934\n 	SD	0.120	0.099	0.042	0.490	0.222	0.110	0.139	3.224\n 	Correl	0.557	0.575	0.557	0.540	0.421	0.504	0.628	  1.0\n \n \n 8. Missing Attribute Values: None\n \n \n 9. Class Distribution:\n \n 	Class	Examples\n 	-----	--------\n 	1	1\n 	2	1\n 	3	15\n 	4	57\n 	5	115\n 	6	259\n 	7	391\n 	8	568\n 	9	689\n 	10	634\n 	11	487\n 	12	267\n 	13	203\n 	14	126\n 	15	103\n 	16	67\n 	17	58\n 	18	42\n 	19	32\n 	20	26\n 	21	14\n 	22	6\n 	23	9\n 	24	2\n 	25	1\n 	26	1\n 	27	2\n 	29	1\n 	-----	----\n 	Total	4177\n \n Num Instances:     4177\n Num Attributes:    9\n Num Continuous:    8 (Int 1 / Real 7)\n Num Discrete:      1\n Missing values:    0 /  0.0%\n\n     name                      type enum ints real     missing    distinct  (1)\n   1 \'Sex\'                     Enum 100%   0%   0%     0 /  0%     3 /  0%   0% \n   2 \'Length\'                  Real   0%   0% 100%     0 /  0%   134 /  3%   0% \n   3 \'Diameter\'                Real   0%   0% 100%     0 /  0%   111 /  3%   0% \n   4 \'Height\'                  Real   0%   0% 100%     0 /  0%    51 /  1%   0% \n   5 \'Whole weight\'            Real   0%   0% 100%     0 /  0%  2429 / 58%  31% \n   6 \'Shucked weight\'          Real   0%   0% 100%     0 /  0%  1515 / 36%  10% \n   7 \'Viscera weight\'          Real   0%   0% 100%     0 /  0%   880 / 21%   3% \n   8 \'Shell weight\'            Real   0%   0% 100%     0 /  0%   926 / 22%   8% \n   9 \'Class_Rings\'             Int    0% 100%   0%     0 /  0%    28 /  1%   0%', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:15:04', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3620/dataset_187_abalone.arff', 'true', 30, 'Class_number_of_rings', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:15:04'),
(31, 1, 0, 'eucalyptus', '1', '1', '**Author**: Bruce Bulloch  \n**Source**: [WEKA Dataset Collection](http://www.cs.waikato.ac.nz/ml/weka/datasets.html)   \n**Please cite**:   \n\n**Eucalyptus Soil Conservation**  \nThe objective was to determine which seedlots in a species are best for soil conservation in seasonally dry hill country. Determination is found by measurement of height, diameter by height, survival, and other contributing factors. \n \nIt is important to note that eucalypt trial methods changed over time; earlier trials included mostly 15 - 30cm tall seedling grown in peat plots and the later trials have included mostly three replications of eight trees grown. This change may contribute to less significant results.\n\nExperimental data recording procedures which require noting include:\n - instances with no data recorded due to experimental recording procedures\n   require that the absence of a species from one replicate at a site was\n   treated as a missing value, but if absent from two or more replicates at a\n   site the species was excluded from the site\'s analyses.\n - missing data for survival, vigour, insect resistance, stem form, crown form\n   and utility especially for the data recorded at the Morea Station; this \n   could indicate the death of species in these areas or a lack in collection\n   of data.  \n\n Attribute Information:  \n  1.  Abbrev - site abbreviation - enumerated\n  2.  Rep - site rep - integer\n  3.  Locality - site locality in the North Island - enumerated\n  4.  Map_Ref - map location in the North Island - enumerated\n  5.  Latitude - latitude approximation - enumerated\n  6.  Altitude - altitude approximation - integer\n  7.  Rainfall - rainfall (mm pa) - integer\n  8.  Frosts - frosts (deg. c) - integer\n  9.  Year - year of planting - integer\n  10. Sp - species code - enumerated\n  11. PMCno - seedlot number - integer\n  12. DBH - best diameter base height (cm) - real\n  13. Ht - height (m) - real\n  14. Surv - survival - integer\n  15. Vig - vigour - real\n  16. Ins_res - insect resistance - real\n  17. Stem_Fm - stem form - real\n  18. Crown_Fm - crown form - real\n  19. Brnch_Fm - branch form - real\n  Class:\n  20. Utility - utility rating - enumerated\n\n Class Distribution:\n  none    - 180\n  low     - 107\n  average - 130\n  good    - 214\n  best    - 105\n\n Contact: Bruce Bulloch, 128 Cook Street, Palmerston North, New Zealand', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:15:28', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3625/dataset_194_eucalyptus.arff', 'true', 31, 'Utility', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:15:28'),
(32, 94, 0, 'isolet', '1', NULL, '**Author**: Ron Cole and Mark Fanty (cole@cse.ogi.edu, fanty@cse.ogi.edu)  \n**Donor**: Tom Dietterich (tgd@cs.orst.edu)  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/ISOLET) - 1994  \n**Please cite**:   \n\n**ISOLET (Isolated Letter Speech Recognition)**  \nThis data set was generated as follows. 150 subjects spoke the name of each letter of the alphabet twice. Hence, we have 52 training examples from each speaker. The speakers are grouped into sets of 30 speakers each, 4 groups can serve as trainings set, the last group as the test set.\n\nYou will note that 3 examples are missing.  I believe they were dropped due to difficulties in recording.\n\nI believe this is a good domain for a noisy, perceptual task.  It is also a very good domain for testing the scaling abilities of algorithms. For example, C4.5 on this domain is slower than backpropagation!\n\nPast Usage:\n* Fanty, M., Cole, R. (1991).  Spoken letter recognition.  In Lippman, R. P., Moody, J., and Touretzky, D. S. (Eds). Advances in Neural Information Processing Systems 3.  San Mateo, CA: Morgan Kaufmann.\nGoal: Predict which letter-name was spoken, a simple classification task.  95.9% correct classification using the OPT backpropagation implementation.  Training on isolet1+2+3+4, testing on isolet5.  Network architecture: 56 hidden units, 26 output units (one-per-class).\n\n* Dietterich, T. G., Bakiri, G. (1991)  Error-correcting output codes: A general method for improving multiclass inductive learning programs.  Proceedings of the Ninth National Conference on Artificial Intelligence (AAAI-91), Anaheim, CA: AAAI Press.\nGoal: same as above. 95.83% correct using OPT backpropagation.  (Architecture: 78 hidden units, 26 output units, one-per-class). 96.73% correct using a 30-bit error-correcting output code with OPT (Architecture: 156 hidden units, 30 output units).\n\n**Attributes**  \nAll attributes are continuous, real-valued attributes scaled into the range -1.0 to 1.0. The features are described in the paper by Cole and Fanty cited above. The features include spectral coefficients; contour features, sonorant features, pre-sonorant features, and post-sonorant features.  Exact order of appearance of the features is not known.', 'ARFF', NULL, NULL, '1994', '2014-08-20 20:59:05', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/52405/phpB0xrNj', 'true', 32, 'class', NULL, NULL, NULL, 'public', NULL, NULL, 'all numeric variables declared as factors before', '2014-09-25 23:26:09'),
(33, 2, 0, 'vowel', '2', '2', '**Author**: Peter Turney (peter@ai.iit.nrc.ca)   \n**Source**: [UCI](https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/vowel/) - date unknown  \n**Please cite**:   \n\n**Vowel Recognition Data**  \nIn my work on context-sensitive learning, I used the \"Deterding Vowel Recognition Data\", but I found it necessary to reformulate the data. Implicit in the original data is contextual information on the speaker\'s gender and identity. For my work, it was necessary to make this information explicit. This dataset adds the speaker\'s sex and identity as new features. \n\nNotes:  \n* This is version 2. Version 1 is hidden because it includes a feature dividing the data in train and test set. In OpenML this information is explicitly available in the corresponding task.', 'ARFF', '\"Peter Turney\"', '\"\"', '', '2014-08-22 16:57:30', NULL, 'Public', '', NULL, 'https://www.openml.org/data/download/52210/phpd8EoD9', 'true', 33, 'Class', '', NULL, '', 'public', NULL, 'http://www.openml.org/d/58', NULL, '2014-08-22 16:57:30'),
(34, 94, 0, 'scene', '1', '', '**Author**:   \n  \n**Source**: Unknown -   \n**Please cite**:   \n\nScene recognition dataset\n\nSource:\nMatthew R. Boutell, Jiebo Luo, Xipeng Shen, and Christopher M. Brown.\nLearning multi-label scene classification.\nPattern Recognition, 37(9):1757-1771, 2004. \n\n1: Description.\nScenes data set contains characteristics about images and thier classes. One image can belong to one or more classes.\n\n2: Type: Multi label \n3: Origin: Real world\n4: Instances: 2407\n5: Features: 294\n6: Labels: 6 \n7: Missing values: No', 'ARFF', '\"\"', '\"\"', '', '2014-08-25 11:43:22', NULL, 'Public', '', NULL, 'https://www.openml.org/data/download/1390080/phpuZu33P', 'true', 34, 'Urban', '', NULL, '', 'public', NULL, '', 'removed ranges after the definition of a numerical attribute', '2015-04-15 22:22:58'),
(35, 2, 0, 'monks-problems-1', '1', NULL, '**Author**: Sebastian Thrun  \n**Source**: [original](https://archive.ics.uci.edu/ml/datasets/MONK\'s+Problems) - October 1992  \n**Please cite**:   \n\nThe Monk\'s Problems: Problem 1\n\nThis is a merged version of the separate train and test set which are usually distributed. On OpenML this train-test split can be found as one of the possible tasks. \n\nSources:  \n(a) Donor: Sebastian Thrun School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213, USA  E-mail: thrun@cs.cmu.edu  \n(b) Date: October 1992\n\n4. Relevant Information:  The MONK\'s problem were the basis of a first international comparison of learning algorithms. The result of this comparison is summarized in \"The MONK\'s Problems - A Performance Comparison of Different Learning algorithms\" by S.B. Thrun, J. Bala, E. Bloedorn, I. Bratko, B. Cestnik, J. Cheng, K. De Jong, S. Dzeroski, S.E. Fahlman, D. Fisher, R. Hamann, K. Kaufman, S. Keller, I. Kononenko, J. Kreuziger, R.S. Michalski, T. Mitchell, P. Pachowicz, Y. Reich H. Vafaie, W. Van de Welde, W. Wenzel, J. Wnek, and J. Zhang has been published as Technical Report CS-CMU-91-197, Carnegie Mellon University in Dec. 1991.  One significant characteristic of this comparison is that it was performed by a collection of researchers, each of whom was an advocate of the technique they tested (often they were the creators of the various methods). In this sense, the results are less biased than in comparisons performed by a single person advocating a specific learning method, and more accurately reflect the generalization behavior of the learning techniques as applied by knowledgeable users.  There are three MONK\'s problems. The domains for all MONK\'s problems are the same (described below). One of the MONK\'s problems has noise added. For each problem, the domain has been partitioned into a train and test set.\n\nAttribute information: \n1. class: 0, 1  \n2. a1: 1, 2, 3 \n3. a2: 1, 2, 3 \n4. a3: 1, 2 \n5. a4: 1, 2, 3 \n6. a5: 1, 2, 3, 4 \n7. a6: 1, 2 8. \n\nTarget Concepts associated to the MONK\'s problem:  \nMONK-1: (a1 = a2) or (a5 = 1)  \nMONK-2: EXACTLY TWO of {a1 = 1, a2 = 1, a3 = 1, a4 = 1, a5 = 1, a6 = 1}  \nMONK-3: (a5 = 3 and a4 = 1) or (a5 /= 4 and a2 /= 3) (5% class noise added to the training set)', 'ARFF', '\"Sebastian Thrun\"', NULL, 'October 1992', '2014-08-26 17:11:18', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/52236/phpAyyBys', 'true', 35, 'class', NULL, NULL, NULL, 'public', NULL, 'https://archive.ics.uci.edu/ml/datasets/MONK\'s+Problems', NULL, '2014-08-26 17:11:18'),
(36, 2, 0, 'monks-problems-2', '1', NULL, '**Author**: Sebastian Thrun  \n**Source**: [original](https://archive.ics.uci.edu/ml/datasets/MONK\'s+Problems) - October 1992  \n**Please cite**:   \n\nThe Monk\'s Problems: Problem 2  \n\nThis is a merged version of the separate train and test set which are usually distributed. On OpenML this train-test split can be found as one of the possible tasks.   \n\nSources:  \n(a) Donor: Sebastian Thrun School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213, USA E-mail: thrun@cs.cmu.edu  \n(b) Date: October 1992  \n\nRelevant Information: The MONK\'s problem were the basis of a first international comparison of learning algorithms. The result of this comparison is summarized in \"The MONK\'s Problems - A Performance Comparison of Different Learning algorithms\" by S.B. Thrun, J. Bala, E. Bloedorn, I. Bratko, B. Cestnik, J. Cheng, K. De Jong, S. Dzeroski, S.E. Fahlman, D. Fisher, R. Hamann, K. Kaufman, S. Keller, I. Kononenko, J. Kreuziger, R.S. Michalski, T. Mitchell, P. Pachowicz, Y. Reich H. Vafaie, W. Van de Welde, W. Wenzel, J. Wnek, and J. Zhang has been published as Technical Report CS-CMU-91-197, Carnegie Mellon University in Dec. 1991. One significant characteristic of this comparison is that it was performed by a collection of researchers, each of whom was an advocate of the technique they tested (often they were the creators of the various methods). In this sense, the results are less biased than in comparisons performed by a single person advocating a specific learning method, and more accurately reflect the generalization behavior of the learning techniques as applied by knowledgeable users. There are three MONK\'s problems. The domains for all MONK\'s problems are the same (described below). One of the MONK\'s problems has noise added. For each problem, the domain has been partitioned into a train and test set.  \n\nAttribute information:  \n1. class: 0, 1  \n2. a1: 1, 2, 3  \n3. a2: 1, 2, 3  \n4. a3: 1, 2  \n5. a4: 1, 2, 3  \n6. a5: 1, 2, 3, 4  \n7. a6: 1, 2 \n\n8.   Target Concepts associated to the MONK\'s problem:  \nMONK-1: (a1 = a2) or (a5 = 1)  \nMONK-2: EXACTLY TWO of {a1 = 1, a2 = 1, a3 = 1, a4 = 1, a5 = 1, a6 = 1}  \nMONK-3: (a5 = 3 and a4 = 1) or (a5 /= 4 and a2 /= 3) (5% class noise added to the training set)', 'ARFF', '\"Sebastian Thrun\"', NULL, 'October 1992', '2014-08-26 17:29:02', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/52237/php4fATLZ', 'true', 36, 'class', NULL, NULL, NULL, 'public', NULL, 'https://archive.ics.uci.edu/ml/datasets/MONK\'s+Problems', NULL, '2014-08-26 17:29:02'),
(37, 2, 0, 'monks-problems-3', '1', NULL, '**Author**: Sebastian Thrun  \n**Source**: [original](https://archive.ics.uci.edu/ml/datasets/MONK\'s+Problems) -   \n**Please cite**:   \n\nThe Monk\'s Problems: Problem 3   \n\nThis is a merged version of the separate train and test set which are usually distributed. On OpenML this train-test split can be found as one of the possible tasks.   \n\nSources:  \n(a) Donor: Sebastian Thrun School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213, USA E-mail: thrun@cs.cmu.edu  \n(b) Date: October 1992   \n\nRelevant Information: The MONK\'s problem were the basis of a first international comparison of learning algorithms. The result of this comparison is summarized in \"The MONK\'s Problems - A Performance Comparison of Different Learning algorithms\" by S.B. Thrun, J. Bala, E. Bloedorn, I. Bratko, B. Cestnik, J. Cheng, K. De Jong, S. Dzeroski, S.E. Fahlman, D. Fisher, R. Hamann, K. Kaufman, S. Keller, I. Kononenko, J. Kreuziger, R.S. Michalski, T. Mitchell, P. Pachowicz, Y. Reich H. Vafaie, W. Van de Welde, W. Wenzel, J. Wnek, and J. Zhang has been published as Technical Report CS-CMU-91-197, Carnegie Mellon University in Dec. 1991. One significant characteristic of this comparison is that it was performed by a collection of researchers, each of whom was an advocate of the technique they tested (often they were the creators of the various methods). In this sense, the results are less biased than in comparisons performed by a single person advocating a specific learning method, and more accurately reflect the generalization behavior of the learning techniques as applied by knowledgeable users. There are three MONK\'s problems. The domains for all MONK\'s problems are the same (described below). One of the MONK\'s problems has noise added. For each problem, the domain has been partitioned into a train and test set.   \n\nAttribute information:  \n1. class: 0, 1  \n2. a1: 1, 2, 3  \n3. a2: 1, 2, 3  \n4. a3: 1, 2  \n5. a4: 1, 2, 3  \n6. a5: 1, 2, 3, 4  \n7. a6: 1, 2  \n\nTarget Concepts associated to the MONK\'s problem:  \nMONK-1: (a1 = a2) or (a5 = 1)  \nMONK-2: EXACTLY TWO of {a1 = 1, a2 = 1, a3 = 1, a4 = 1, a5 = 1, a6 = 1}  \nMONK-3: (a5 = 3 and a4 = 1) or (a5 /= 4 and a2 /= 3) (5% class noise added to the training set)', 'ARFF', '\"Sebastian Thrun\"', NULL, NULL, '2014-08-26 17:41:07', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/52238/phphZierv', 'true', 37, 'class', NULL, NULL, NULL, 'public', NULL, 'https://archive.ics.uci.edu/ml/datasets/MONK\'s+Problems', NULL, '2014-08-26 17:41:07'),
(38, 2, NULL, 'JapaneseVowels', '1', NULL, '**Author**: Mineichi Kudo, Jun Toyama, Masaru Shimbo ({mine,jun,shimbo}@main.eng.hokudai.ac.jp)  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Japanese+Vowels) - 2000  \n**Please cite**:   \n\n**Japanese vowels**  \nThis dataset records 640 time series of 12 LPC cepstrum coefficients taken from nine male speakers.\n\nThe data was collected for examining our newly developed classifier for multidimensional curves (multidimensional time series). Nine male speakers uttered two Japanese vowels /ae/ successively. For each utterance, with the analysis parameters described below, we applied 12-degree linear prediction analysis to it to obtain a discrete-time series with 12 LPC cepstrum coefficients. This means that one utterance by a speaker forms a time series whose length is in the range 7-29 and each point of a time series is of 12 features (12 coefficients).\n\nSimilar data are available for different utterances /ei/, /iu/, /uo/, /oa/ in addition to /ae/. Please contact the donor if you are interested in using this data.\n\nThe number of the time series is 640 in total. We used one set of 270 time series for training and the other set of 370 time series for testing.\n\nAnalysis parameters:  \n* Sampling rate : 10kHz\n* Frame length : 25.6 ms\n* Shift length : 6.4ms\n* Degree of LPC coefficients : 12\n\nEach line represents 12 LPC coefficients in the increasing order separated by spaces. This corresponds to one analysis\nframe. Lines are organized into blocks, which are a set of 7-29 lines separated by blank lines and corresponds to a single speech utterance of /ae/ with 7-29 frames.\n\nEach speaker is a set of consecutive blocks. In ae.train there are 30 blocks for each speaker. Blocks 1-30 represent speaker 1, blocks 31-60 represent speaker 2, and so on up to speaker 9. In ae.test, speakers 1 to 9 have the corresponding number of blocks: 31 35 88 44 29 24 40 50 29. Thus, blocks 1-31 represent speaker 1 (31 utterances of /ae/), blocks 32-66 represent speaker 2 (35 utterances of /ae/), and so on.\n\n**Past Usage**\n\nM. Kudo, J. Toyama and M. Shimbo. (1999). \"Multidimensional Curve Classification Using Passing-Through Regions\". Pattern Recognition Letters, Vol. 20, No. 11--13, pages 1103--1111.\n\nIf you publish any work using the dataset, please inform the donor. Use for commercial purposes requires donor permission.\n\nReferences  \n\n1. http://ips9.main.eng.hokudai.ac.jp/index_e.html\n2. mailto:mine@main.eng.hokudai.ac.jp\n3. mailto:jun@main.eng.hokudai.ac.jp\n4. mailto:shimbo@main.eng.hokudai.ac.jp\n5. http://kdd.ics.uci.edu/\n6. http://www.ics.uci.edu/\n7. http://www.uci.edu/', 'ARFF', NULL, NULL, NULL, '2014-09-27 10:56:03', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/52415/JapaneseVowels.arff', 'true', 38, 'speaker', NULL, NULL, NULL, 'public', NULL, NULL, 'set target feature', '2014-09-27 11:19:36'),
(39, 2, NULL, 'synthetic_control', '1', NULL, '**Author**: Dr Robert Alcock (rob@skyblue.csd.auth.gr)  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Synthetic+Control+Chart+Time+Series) - 1999  \n**Please cite**:   \n\n**Synthetic Control Chart Time Series**  \nThis data consists of synthetically generated control charts. This dataset contains 600 examples of control charts synthetically generated by the process in Alcock and Manolopoulos (1999). There are six different classes of control charts:\n\n1. Normal\n2. Cyclic\n3. Increasing trend\n4. Decreasing trend\n5. Upward shift\n6. Downward shift\n\n**Past Usage**  \nAlcock R.J. and Manolopoulos Y. Time-Series Similarity Queries Employing a Feature-Based Approach. 7th Hellenic Conference on\nInformatics. August 27-29. Ioannina,Greece 1999.\n\n**References and Further Information**  \nD.T. Pham and A.B. Chan \"Control Chart Pattern Recognition using a New Type of Self Organizing Neural Network\" Proc. Instn, Mech, Engrs. Vol 212, No 1, pp 115-127 1998.\n\nReferences  \n\n1. http://skyblue.csd.auth.gr/~rob/\n2. mailto:rob@skyblue.csd.auth.gr\n3. http://kdd.ics.uci.edu/\n4. http://www.ics.uci.edu/\n5. http://www.uci.edu/', 'ARFF', NULL, NULL, NULL, '2014-09-27 10:56:07', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/52417/synthetic_control.arff', 'true', 39, 'class', 'index', NULL, NULL, 'public', NULL, NULL, 'set index feature', '2014-09-27 11:35:53'),
(40, 2, NULL, 'irish', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nIrish Educational Transitions Data\n\nBelow are shown data on educational transitions for a sample of 500\nIrish schoolchildren aged 11 in 1967. The data were collected by\nGreaney and Kelleghan (1984), and reanalyzed by Raftery and Hout (1985, 1993).\n\nThe data were also used, in a simplified form, as an example to illustrate\nBayesian model selection methods by Raftery (1988) and Kass and Raftery (1993).\nIn that simplified form, primary terminal leavers and cases with any missing\ndata were removed, leaving 441 cases. The Leaving Certificate variable\nwas used as the dependent variable in a logistic regression analysis.\n\nThe variables shown are as follows:\n\n1. Sex: 1=male; 2=female.\n\n2. DVRT (Drumcondra Verbal Reasoning Test Score).\n\n3. Educational level attained:\n1		Primary terminal leaver\n2	 	Junior cycle incomplete: vocational school\n3		Junior cycle incomplete: secondary school\n4		Junior cycle terminal leaver: vocational school\n5		Junior cycle terminal leaver: secondary school\n6		Senior cycle incomplete: vocational school\n7		Senior cycle incomplete: secondary school\n8		Senior cycle terminal leaver: vocational school\n9		Senior cycle terminal leaver: secondary school\n10		3rd level incomplete\n11		3rd level complete\n\n4. Leaving Certificate. 1 if Leaving Certificate not taken; 2 if taken.\n\n5. Prestige score for father\'s occupation\n(calculated by Raftery and Hout, 1985). 0 if missing.\n\n6. Type of school: 1=secondary; 2=vocational; 9=primary terminal leaver.\n\nREFERENCES\n\nGreaney, V. and Kelleghan, T. (1984). Equality of Opportunity in Irish\nSchools. Dublin: Educational Company.\n\nKass, R.E. and Raftery, A.E. (1993). Bayes factors and model uncertainty.\nTechnical Report no. 254, Department of Statistics, University of Washington.\nRevised version to appear in Journal of the American Statistical\nAssociation.\n\nRaftery, A.E. (1988). Approximate Bayes factors for generalized linear models.\nTechnical Report no. 121, Department of Statistics, University of Washington.\n\nRaftery, A.E. and Hout, M. (1985). Does Irish education approach the\nmeritocratic ideal? A logistic analysis.\nEconomic and Social Review, 16, 115-140.\n\nRaftery, A.E. and Hout, M. (1993). Maximally maintained inequality:\nExpansion, reform and opportunity in Irish schools.\nSociology of Education, 66, 41-62.\n\n\nOWNERSHIP STATEMENT\n\nThis data belongs to Vincent Greaney and Thomas Kelleghan,\nEducational Research Centre, St. Patrick\'s College, Drumcondra,\nDublin 9, Ireland, who retain the copyright.\n\nIn the form given here, it may be used solely as an example for research\non the development of statistical methods. For any other use of the data,\npermission must be obtained from the owners.  Subject to this statement,\npermission is hereby given to StatLib to distribute this data freely.\n\nSubmitted by Adrian Raftery (raftery@stat.washington.edu).\n\nCopyright 1984 Vincent Greaney and Thomas Kelleghan.\n\n\n\n\nInformation about the dataset\nCLASSTYPE: nominal\nCLASSINDEX: 4', 'ARFF', NULL, NULL, NULL, '2014-09-28 23:50:51', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/52563/irish.arff', 'true', 40, 'Leaving_Certificate', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-09-28 23:50:51'),
(41, 2, NULL, 'analcatdata_authorship', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nanalcatdata    A collection of data sets used in the book \"Analyzing Categorical Data,\"\nby Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission\nconsists of a zip file containing two versions of each of 84 data sets,\nplus this README file. Each data set is given in comma-delimited ASCII\n(.csv) form, and Microsoft Excel (.xls) form.\n\nNOTICE: These data sets may be used freely for scientific, educational and/or\nnoncommercial purposes, provided suitable acknowledgment is given (by citing\nthe above-named reference).\n\nFurther details concerning the book, including information on statistical software\n(including sample S-PLUS/R and SAS code), are available at the web site\n\nhttp://www.stern.nyu.edu/~jsimonof/AnalCatData\n\n\nInformation about the dataset\nCLASSTYPE: nominal\nCLASSINDEX: last\n\n\nNote: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced\nwith Underscores', 'ARFF', NULL, NULL, NULL, '2014-09-28 23:51:06', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/52570/analcatdata_authorship.arff', 'true', 41, 'Author', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-09-28 23:51:06'),
(42, 2, NULL, 'analcatdata_dmft', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nanalcatdata    A collection of data sets used in the book \"Analyzing Categorical Data,\"\nby Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission\nconsists of a zip file containing two versions of each of 84 data sets,\nplus this README file. Each data set is given in comma-delimited ASCII\n(.csv) form, and Microsoft Excel (.xls) form.\n\nNOTICE: These data sets may be used freely for scientific, educational and/or\nnoncommercial purposes, provided suitable acknowledgment is given (by citing\nthe above-named reference).\n\nFurther details concerning the book, including information on statistical software\n(including sample S-PLUS/R and SAS code), are available at the web site\n\nhttp://www.stern.nyu.edu/~jsimonof/AnalCatData\n\n\nInformation about the dataset\nCLASSTYPE: nominal\nCLASSINDEX: last\n\n\nNote: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced\nwith Underscores', 'ARFF', NULL, NULL, NULL, '2014-09-28 23:51:25', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/52581/analcatdata_dmft.arff', 'true', 42, 'Prevention', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-09-28 23:51:25'),
(43, 2, NULL, 'profb', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nPRO FOOTBALL SCORES  (raw data appears after the description below)\n\nHow well do the oddsmakers of Las Vegas predict the outcome of\nprofessional football games?  Is there really a home field advantage - if\nso how large is it?  Are teams that play the Monday Night game at a\ndisadvantage when they play again the following Sunday?  Do teams benefit\nfrom having a \"bye\" week off in the current schedule?  These questions and\na host of others can be investigated using this data set.\n\nHal Stern from the Statistics Department at Harvard University has\nmade available his compilation of scores for all National Football League\ngames from the 1989, 1990, and 1991 seasons.  Dr. Stern used these data as\npart of his presentation \"Who\'s Number One?\" in the special \"Best of\nBoston\" session at the 1992 Joint Statistics Meetings.\n\nSeveral variables in the data are keyed to the oddsmakers \"point\nspread\" for each game.  The point spread is a value assigned before each\ngame to serve as a handicap for whichever is perceived to be the better\nteam.  Thus, to win against the point spread, the \"favorite\" team must beat\nthe \"underdog\" team by more points than the spread.  The underdog \"wins\"\nagainst the spread if it wins the game outright or manages to lose by fewer\npoints than the spread.  In theory, the point spread should represent the\n\"expert\" prediction as to the game\'s outcome.  In practice, it more usually\ndenotes a point at which an equal amount of money will be wagered both for\nand against the favored team.\n\nRaw data below contains 672 cases (all 224 regular season games in\neach season and informatino on the following 9 varialbes:     .\n\nHome/Away       = Favored team is at home (1) or away (0)\nFavorite Points = Points scored by the favored team\nUnderdog Points = Points scored by the underdog team\nPointspread     = Oddsmaker\'s points to handicap the favored team\nFavorite Name   = Code for favored team\'s name\nUnderdog name   = Code for underdog\'s name\nYear            = 89, 90, or 91\nWeek            = 1, 2, ... 17\nSpecial         = Mon.night (M), Sat. (S), Thur. (H), Sun. night (N)\not - denotes an overtime game\n\n\nData were submitted by: Robin Lock  (rlock@stlawu.bitnet)\nMathematics Department, St. Lawrence University\n\nData were compiled by: Hal Stern, Dept. of Statistics, Harvard University\n\n\n\nInformation about the dataset\nCLASSTYPE: nominal\nCLASSINDEX: 1', 'ARFF', NULL, NULL, NULL, '2014-09-28 23:51:27', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/52582/profb.arff', 'true', 43, 'Home/Away', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-09-28 23:51:27'),
(44, 2, NULL, 'collins', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThe following are data used in an analysis of the Brown and Frown corpora for my doctoral dissertation titled ``Variations in Written English: Characterizing Authors\' Rhetorical Language Choices Across Corpora of Published Texts\" (Completed at Carnegie Mellon Univ, 2003).  The source of the corpora was the ICAME CD-ROM  (get info at <http://www.hit.uib.no/icame/cd>).\n\nThe data were generated from the texts using tagging and visualization software, Docuscope.\n\nThe first row is the variable names. The genre of each text (assigned by the Brown corpus compilers) is in \'Genre\' column and the corpus is listed in the \'corpus\' column with 1=Brown and 2=Frown corpus.\n\nThe dataset may be freely used and distributed for non-commercial purposes.\n\nJeff Collins <jeff.collins@acm.org> 11 July 2003\n\n\n\nInformation about the dataset\nCLASSTYPE: nominal\nCLASSINDEX: last', 'ARFF', NULL, NULL, NULL, '2014-09-28 23:51:43', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/52590/collins.arff', 'true', 44, 'Corp.Genre', 'Counter', '\"Text\"', NULL, 'public', NULL, NULL, 'attribute counter is a row id', '2015-04-15 17:08:50'),
(45, 2, NULL, 'sylva_agnostic', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDatasets from the Agnostic Learning vs. Prior Knowledge Challenge (http://www.agnostic.inf.ethz.ch)\n\nDataset from: http://www.agnostic.inf.ethz.ch/datasets.php\n\nModified by TunedIT (converted to ARFF format)\n\n\nSYLVA is the ecology database\n\n\nThe task of SYLVA is to classify forest cover types. The forest cover type for 30 x 30 meter cells is obtained from US Forest Service (USFS) Region 2 Resource Information System (RIS) data. We brought it back to a two-class classification problem (classifying Ponderosa pine vs. everything else). The \"agnostic learning track\" data consists in 216 input variables. Each pattern is composed of 4 records: 2 true records matching the target and 2 records picked at random. Thus 1/2 of the features are distracters.\n\nData type: non-sparse\nNumber of features: 216\nNumber of examples and check-sums:\nPos_ex	Neg_ex	Tot_ex	Check_sum\nTrain	  805	12281	13086	238271607.00\nValid	   81	 1228	 1309	23817234.00\n\n\nThis dataset contains samples from both training and validation datasets.', 'ARFF', NULL, NULL, NULL, '2014-10-06 23:55:56', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/53919/sylva_agnostic.arff', 'true', 45, 'label', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-10-06 23:55:56'),
(46, 2, NULL, 'gina_agnostic', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDatasets from the Agnostic Learning vs. Prior Knowledge Challenge (http://www.agnostic.inf.ethz.ch)\n\nDataset from: http://www.agnostic.inf.ethz.ch/datasets.php\n\n\nModified by TunedIT (converted to ARFF format)\n\n\nGINA is digit recognition database\n\nThe task of GINA is handwritten digit recognition. For the \"agnostic learning track\" we chose the problem of separating two-digit odd numbers from two-digit even numbers. Only the unit digit is informative for that task, therefore at least 1/2 of the features are distracters. Additionally, the pixels that are almost always blank were removed and the pixel order was randomized to hide the feature identity.  This is a two class classification problem with sparse continuous input variables, in which each class is composed of several clusters. It is a problem with heterogeneous classes.\n\nData type: non-sparse\nNumber of features: 970\nNumber of examples and check-sums:\nPos_ex	Neg_ex	Tot_ex	Check_sum\nTrain	 1550	 1603	 3153	164947945.00\nValid	  155	  160	  315	16688946.00\n\n\nThis dataset contains samples from both training and validation datasets.', 'ARFF', NULL, NULL, NULL, '2014-10-06 23:56:01', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/53921/gina_agnostic.arff', 'true', 46, 'label', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-10-06 23:56:01'),
(47, 2, NULL, 'ada_agnostic', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDatasets from the Agnostic Learning vs. Prior Knowledge Challenge (http://www.agnostic.inf.ethz.ch)\n\nDataset from: http://www.agnostic.inf.ethz.ch/datasets.php\n\n\nModified by TunedIT (converted to ARFF format)\n\n\nADA is the marketing database\n\nThe task of ADA is to discover high revenue people from census data. This is a two-class classification problem. The raw data from the census bureau is known as the Adult database in the UCI machine-learning repository. The 14 original attributes (features) include age, workclass,  education,\nmarital status, occupation, native country, etc. It contains continuous, binary and categorical features. This dataset is from the \"agnostic learning track\", i.e. has access to a preprocessed numeric representation eliminating categorical variables, but the identity of the features is not revealed.\n\n\n\nData type: non-sparse\nNumber of features: 48\nNumber of examples and check-sums:\nPos_ex	Neg_ex	Tot_ex	Check_sum\nTrain	 1029	 3118	 4147	6798109.00\nValid	  103	  312	  415	681151.00\n\n\nThis dataset contains samples from both training and validation datasets.', 'ARFF', NULL, NULL, NULL, '2014-10-06 23:56:15', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/53926/ada_agnostic.arff', 'true', 47, 'label', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-10-06 23:56:15'),
(48, 2, NULL, 'mozilla4', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nThis is a PROMISE Software Engineering Repository data set made publicly\navailable in order to encourage repeatable, verifiable, refutable, and/or\nimprovable predictive models of software engineering.\n\nIf you publish material based on PROMISE data sets then, please\nfollow the acknowledgment guidelines posted on the PROMISE repository\nweb page http://promisedata.org/repository .\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n(c) 2007  A. Gunes Koru\nContact: gkoru AT umbc DOT edu Phone: +1 (410) 455 8843\nThis data set is distributed under the\nCreative Commons Attribution-Share Alike 3.0 License\nhttp://creativecommons.org/licenses/by-sa/3.0/\n\nYou are free:\n\n* to Share -- copy, distribute and transmit the work\n* to Remix -- to adapt the work\n\nUnder the following conditions:\n\nAttribution. You must attribute the work in the manner specified by\nthe author or licensor (but not in any way that suggests that they endorse\nyou or your use of the work).\n\nShare Alike. If you alter, transform, or build upon this work, you\nmay distribute the resulting work only under the same, similar or a\ncompatible license.\n\n* For any reuse or distribution, you must make clear to others the\nlicense terms of this work.\n* Any of the above conditions can be waived if you get permission from\nthe copyright holder.\n* Apart from the remix rights granted under this license, nothing in\nthis license impairs or restricts the author\'s moral rights.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\n1. Title: Recurrent event (defect fix) and size data for Mozilla Classes\nThis one includes a binary attribute (event) to show defect fix.\nThe data is at the \"observation\" level. Each modification made to\na C++ class was entered as an observation. A newly added class\ncreated an observation. The observation period was between\nMay 29, 2002 and Feb 22, 2006.\n\n2. Sources\n(a) Creator: A. Gunes Koru\n(b) Date: February 23, 2007\n(c) Contact: gkoru AT umbc DOT edu Phone: +1 (410) 455 8843\n\n3. Donor: A. Gunes Koru\n\n4. Past Usage: This data set was used for:\n\nA. Gunes Koru, Dongsong Zhang, and Hongfang Liu, \"Modeling the\nEffect of Size on Defect Proneness for Open-Source Software\",\nPredictive Models in Software Engineering Workshop, PROMISE 2007,\nMay 20th 2007, Minneapolis, Minnesota, US.\n\nAbstract:\nQuality is becoming increasingly important with the continuous\nadoption of open-source software.  Previous research has found that\nthere is generally a positive relationship between module size and\ndefect proneness. Therefore, in open-source software development, it\nis important to monitor module size and understand its impact on\ndefect proneness. However, traditional approaches to quality\nmodeling, which measure specific system snapshots and obtain future\ndefect counts, are not well suited because open-source modules\nusually evolve and their size changes over time. In this study, we\nused Cox proportional hazards modeling with recurrent events to\nstudy the effect of class size on defect-proneness in the Mozilla\nproduct. We found that the effect of size was significant, and we\nquantified this effect on defect proneness.\n\nThe full paper can be downloaded from A. Gunes Koru\'s Website\nhttp://umbc.edu/~gkoru\nby following the Publications link or from the Web site of PROMISE 2007.\n\n5. Features:\n\nThis data set is used to create a conditional Cox Proportional\nHazards Model\n\nid: A numeric identification assigned to each separate C++ class\n(Note that the id\'s do not increment from the first to the last\ndata row)\n\nstart: A time infinitesimally greater than the time of the modification\nthat created this observation (practically, modification time). When a\nclass is introduced to a system, a new observation is entered with start=0\n\nend: Either the time of the next modification, or the end of the\nobservation period, or the time of deletion, whichever comes first.\n\nevent: event is set to 1 if a defect fix takes place\nat the time represented by \'end\', or 0 otherwise.  A class deletion\nis handled easily by entering a final observation whose event is set\nto 1 if the class is deleted for corrective maintenance, or 0 otherwise.\n\nsize: It is a time-dependent covariate and its column carries the\nnumber of source Lines of Code of the C++ classes\nat time \'start\'. Blank and comment lines are not counted.\n\nstate: Initially set to 0, and it becomes 1 after the class\nexperiences an event, and remains at 1 thereafter.', 'ARFF', NULL, NULL, NULL, '2014-10-06 23:57:07', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/53929/mozilla4.arff', 'true', 48, 'state', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-10-06 23:57:07'),
(49, 2, NULL, 'pc4', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\n%-*- text -*-\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nThis is a PROMISE data set made publicly available in order to encourage\nrepeatable, verifiable, refutable, and/or improvable predictive models\nof software engineering.\n\nIf you publish material based on PROMISE data sets then, please\nfollow the acknowledgment guidelines posted on the PROMISE repository\nweb page http://promise.site.uottawa.ca/SERepository .\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n1. Title/Topic: PC4/ defect prediction\n\n(c) 2007 : Tim Menzies  : tim@menzies.us\nThis data set is distributed under the\nCreative Commons Attribution-Share Alike 3.0 License\nhttp://creativecommons.org/licenses/by-sa/3.0/\n\nYou are free:\n\n* to Share -- copy, distribute and transmit the work\n* to Remix -- to adapt the work\n\nUnder the following conditions:\n\nAttribution. You must attribute the work in the manner specified by\nthe author or licensor (but not in any way that suggests that they endorse\nyou or your use of the work).\n\nShare Alike. If you alter, transform, or build upon this work, you\nmay distribute the resulting work only under the same, similar or a\ncompatible license.\n\n* For any reuse or distribution, you must make clear to others the\nlicense terms of this work.\n* Any of the above conditions can be waived if you get permission from\nthe copyright holder.\n* Apart from the remix rights granted under this license, nothing in\nthis license impairs or restricts the author\'s moral rights.\nFor more deatils on this data set, see\nhttp://promisedata.org/repository/data/kc2/kc2.arff', 'ARFF', NULL, NULL, NULL, '2014-10-06 23:57:12', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/53932/pc4.arff', 'true', 49, 'c', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-10-06 23:57:12'),
(50, 2, NULL, 'pc3', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\n%-*- text -*-\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nThis is a PROMISE data set made publicly available in order to encourage\nrepeatable, verifiable, refutable, and/or improvable predictive models\nof software engineering.\n\nIf you publish material based on PROMISE data sets then, please\nfollow the acknowledgment guidelines posted on the PROMISE repository\nweb page http://promise.site.uottawa.ca/SERepository .\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n1. Title/Topic: PC3/software defect prediction\n\n(c) 2007 : Tim Menzies  : tim@menzies.us\nThis data set is distributed under the\nCreative Commons Attribution-Share Alike 3.0 License\nhttp://creativecommons.org/licenses/by-sa/3.0/\n\nYou are free:\n\n* to Share -- copy, distribute and transmit the work\n* to Remix -- to adapt the work\n\nUnder the following conditions:\n\nAttribution. You must attribute the work in the manner specified by\nthe author or licensor (but not in any way that suggests that they endorse\nyou or your use of the work).\n\nShare Alike. If you alter, transform, or build upon this work, you\nmay distribute the resulting work only under the same, similar or a\ncompatible license.\n\n* For any reuse or distribution, you must make clear to others the\nlicense terms of this work.\n* Any of the above conditions can be waived if you get permission from\nthe copyright holder.\n* Apart from the remix rights granted under this license, nothing in\nthis license impairs or restricts the author\'s moral rights.\nFor more deatils on this data set, see\nhttp://promisedata.org/repository/data/kc2/kc2.arff', 'ARFF', NULL, NULL, NULL, '2014-10-06 23:57:13', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/53933/pc3.arff', 'true', 50, 'c', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-10-06 23:57:13'),
(51, 2, NULL, 'jm1', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThis is a PROMISE data set made publicly available in order to encourage repeatable, verifiable, refutable, and/or improvable predictive models of software engineering.\n\nIf you publish material based on PROMISE data sets then, please follow the acknowledgment guidelines posted on [the PROMISE repository web page](http://promise.site.uottawa.ca/SERepository).\n\n## Title/Topic\nJM1/software defect prediction\n\n\n## Sources\n* **Creators:**  NASA, then the NASA Metrics Data Program, http://mdp.ivv.nasa.gov. \n* **Contacts:** \n  * Mike Chapman, Galaxy Global Corporation (Robert.Chapman@ivv.nasa.gov) +1-304-367-8341\n  * Pat Callis, NASA, NASA project manager for MDP (Patrick.E.Callis@ivv.nasa.gov) +1-304-367-8309\n\n* **Donor:** Tim Menzies (tim@barmag.net)\n\n* **Date:**  December 2nd, 2004\n\n## Past usage\n**_How Good is Your Blind Spot Sampling Policy?_; 2003; Tim Menzies and Justin S. Di Stefano; 2004 IEEE Conference on High Assurance Software Engineering (http://menzies.us/pdf/03blind.pdf).**\n\n### Results:\n* Very simple learners (ROCKY) perform as well in this domain as more sophisticated methods (e.g. J48, model trees, model trees) for predicting detects\n* Many learners have very low false alarm rates.\n* Probability of detection (PD) rises with effort and rarely rises above it.\n* High PDs are associated with high PFs (probability of failure)\n* PD, PF, effort can change significantly while accuracy remains essentially stable\n* With two notable exceptions, detectors learned from one data set (e.g. KC2) have nearly they same properties when applied to another (e.g. PC2, KC2). Exceptions:\n* LinesOfCode measures generate wider inter-data-set variances;\n* Precision\'s inter-data-set variances vary wildly\n\n**_\"Assessing Predictors of Software Defects\"_, T. Menzies and J. DiStefano and A. Orrego and R. Chapman, 2004,**\n**Proceedings, workshop on Predictive Software Models, Chicago, Available from http://menzies.us/pdf/04psm.pdf.**\n\n### Results:\n* From JM1, Naive Bayes generated PDs of 25% with PF of 20%\n* Naive Bayes out-performs J48 for defect detection\n* When learning on more and more data, little improvement is seen after processing 300 examples.\n* PDs are much higher from data collected below the sub-sub-system level.\n* Accuracy is a surprisingly uninformative measure of success for a defect detector. Two detectors with the same accuracy can have widely varying PDs and PFs.\n\n## Relevant information\n* JM1 is written in \"C\" and is a real-time predictive ground system: Uses simulations to generate predictions\n* Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality. The nature of association is under dispute.\n\nNotes on McCabe and Halstead follow.\n\n* The McCabe and Halstead measures are \"module\"-based where a \"module\" is the smallest unit of functionality. In C or Smalltalk, \"modules\" would be called \"function\" or \"method\" respectively.\n\n* Defect detectors can be assessed according to the following measures:\n\n    module actually has defects\n    +-------------+------------+\n    |     no      |     yes    |\n    +-----+-------------+------------+\n    classifier predicts no defects |  no |      a      |      b     |\n    +-----+-------------+------------+\n    classifier predicts some defects | yes |      c      |      d     |\n    +-----+-------------+------------+\n\n\n    accuracy                   = acc          = (a+d)/(a+b+c+d\n    probability of detection   = pd  = recall = d/(b+d)\n    probability of false alarm = pf           = c/(a+c)\n    precision                  = prec         = d/(c+d)\n    effort                     = amount of code selected by detector = (c.LOC + d.LOC)/(Total LOC)\n\n\nIdeally, detectors have high PDs, low PFs, and low effort. This ideal state rarely happens:\n\n* PD and effort are linked. The more modules that trigger the detector, the higher the PD. However, effort also gets increases\n* High PD or low PF comes at the cost of high PF or low PD (respectively). This linkage can be seen in a standard receiver operator curve (ROC).  Suppose, for example, LOC> x is used as the detector (i.e. we assume large modules have more errors). LOC > x represents a family of detectors. At x=0, EVERY module is predicted to have errors. This detector has a high PD but also a high false alarm rate. At x=0, NO module is predicted to have errors. This detector has a low false alarm rate but won\'t detect anything at all. At 0<x<1, a set of detectors are generated as shown below:\n\n    pd\n    1 |           x  x  x                KEY:\n    |        x     .                   \".\"  denotes the line PD=PF\n    |     x      .                     \"x\"  denotes the roc curve\n    |   x      .                            for a set of detectors\n    |  x     .\n    | x    .\n    | x  .\n    |x .\n    |x\n    x------------------ pf\n    0                   1\n\nNote that:\n* The only way to make no mistakes (PF=0) is to do nothing (PD=0)\n* The only way to catch more detects is to make more mistakes (increasing PD means increasing PF).\n* Our detector bends towards the \"sweet spot\" of <PD=1,PF=0> but does not reach it.\n* The line pf=pd on the above graph represents the \"no information\" line. If pf=pd then the detector is pretty useless. The better the detector, the more it rises above PF=PD towards the \"sweet spot\".\n\nNOTES ON MCCABE/HALSTEAD\n========================\nMcCabe argued that code with complicated pathways are more error-prone.  His metrics therefore reflect the pathways within a code module.\n\n    @Article{mccabe76,\n    title  = \"A Complexity Measure\",\n    author  = \"T.J. McCabe\",\n    pages  = \"308--320\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year  = \"1976\",\n    volume  = \"2\",\n    month  = \"December\",\n    number  = \"4\"}\n\nHalstead argued that code that is hard to read is more likely to be fault prone. Halstead estimates reading complexity by counting the number of concepts in a module; e.g. number of unique operators.\n\n    @Book{halstead77,\n    Author    = \"M.H. Halstead\",\n    Title    = \"Elements of Software Science\",\n    Publisher = \"Elsevier \",\n    Year    = 1977}\n\nWe study these static code measures since they are useful, easy to use, and widely used:\n\n* USEFUL: E.g. this data set can generate highly accurate predictors for defects\n* EASY TO USE: Static code measures (e.g. lines of code, the McCabe/Halstead measures) can be automatically and cheaply collected.\n* WIDELY USED: Many researchers use static measures to guide software quality predictions (see the reference list in the above \"blind spot\" paper. Verification and validation (V\\&V) textbooks advise using static code complexity measures to decide which modules are worthy of manual inspections.  Further, we know of several large government software contractors that won\'t review software modules _unless_ tools like McCabe predict that they are fault prone.  Hence, defect detectors have a major economic impact when they may force programmers to rewrite code.\n\nNevertheless, the merits of these metrics has been widely criticized.  Static code measures are hardly a complete characterization of the internals of a function. Fenton offers an insightful example where the same functionality is achieved using different programming language constructs resulting in different static measurements for that module. Fenton uses this example to argue the uselessness of static code measures.\n\n    @Book{fenton97,\n    author    = \"N.E. Fenton and S.L. Pfleeger\",\n    title     = {Software metrics: a Rigorous \\& Practical Approach},\n    publisher = {International Thompson Press},\n    year      = {1997}}\n\nAn alternative interpretation of Fenton\'s example is that static measures can never be a definite and certain indicator of the presence of a fault.  Rather, defect detectors based on static measures are best viewed as probabilistic statements that the frequency of faults tends to increase in code modules that trigger the detector.  By definition, such probabilistic statements will are not categorical claims with some a non-zero false alarm rate. The research challenge for data miners is to ensure that these false alarms do not cripple their learned theories.\n\nThe McCabe metrics are a collection of four software metrics: essential complexity, cyclomatic complexity, design complexity and LOC, Lines of Code.\n\n* Cyclomatic Complexity, or \"v(G)\", measures the number of \"linearly independent paths\". A set of paths is said to be linearly independent if no path in the set is a linear combination of any other paths in the set through a program\'s \"flowgraph\". A flowgraph is a directed graph where each node corresponds to a program statement, and each arc indicates the flow of control from one statement to another. \"v(G)\" is calculated by \"v(G) = e - n + 2\" where \"G\" is a program\'s flowgraph, \"e\" is the number of arcs in the flowgraph, and \"n\" is the number of nodes in the flowgraph. The standard McCabes rules (\"v(G)\">10), are used to identify fault-prone module.\n* Essential Complexity, or \"ev(G)$\" is the extent to which a flowgraph can be \"reduced\" by decomposing all the subflowgraphs of $G$ that are \"D-structured primes\". Such \"D-structured primes\" are also sometimes referred to as \"proper one-entry one-exit subflowgraphs\" (for a more thorough discussion of D-primes, see the Fenton text referenced above). \"ev(G)\" is calculated using \"ev(G)= v(G) - m\" where $m$ is the number of subflowgraphs of \"G\" that are D-structured primes.\n* Design Complexity, or \"iv(G)\", is the cyclomatic complexity of a module\'s reduced flowgraph.  The flowgraph, \"G\", of a module is reduced to eliminate any complexity which does not influence the interrelationship between design modules.  According to McCabe, this complexity measurement reflects the modules calling patterns to its immediate subordinate modules.\n* Lines of code is measured according to McCabe\'s line counting conventions.\n\nThe Halstead falls into three groups: the base measures, the derived measures, and lines of code measures.\n\n* Base measures:\n  * mu1             = number of unique operators\n  * mu2             = number of unique operands\n  * N1              = total occurrences of operators\n  * N2              = total occurrences of operands\n  * length     = N  = N1 + N2\n  * vocabulary = mu = mu1 + mu2\n  * Constants set for each function:\n  * mu1\' =  2 = potential operator count (just the function name and the \"return\" operator)\n  * mu2\'      = potential operand count. (the number of arguments to the module)\n\nFor example, the expression \"return max(w+x,x+y)\" has \"N1=4\" operators \"return, max, +,+)\", \"N2=4\" operands (w,x,x,y), \"mu1=3\" unique operators (return, max,+), and \"mu2=3\" unique operands (w,x,y).\n\n* Derived measures:\n  * P = volume = V = N * log2(mu) (the number of mental comparisons needed to write\na program of length N)\n  * V* = volume on minimal implementation = (2 + mu2\')*log2(2 + mu2\')\n  * L  = program length = V*/N\n  * D  = difficulty = 1/L\n  * L\' = 1/D\n  * I  = intelligence = L\'*V\'\n  * E  = effort to write program = V/L\n  * T  = time to write program = E/18 seconds\n\n## Number of instances\n10885\n\n## Number of attributes\n22 (5 different lines of code measure, 3 McCabe metrics, 4 base Halstead measures, 8 derived Halstead measures, a branch-count, and 1 goal field)\n\n## Attribute Information\n1. loc             : numeric % McCabe\'s line count of code\n2. v(g)            : numeric % McCabe \"cyclomatic complexity\"\n3. ev(g)           : numeric % McCabe \"essential complexity\"\n4. iv(g)           : numeric % McCabe \"design complexity\"\n5. n               : numeric % Halstead total operators + operands\n6. v               : numeric % Halstead \"volume\"\n7. l               : numeric % Halstead \"program length\"\n8. d               : numeric % Halstead \"difficulty\"\n9. i               : numeric % Halstead \"intelligence\"\n10. e               : numeric % Halstead \"effort\"\n11. b               : numeric % Halstead\n12. t               : numeric % Halstead\'s time estimator\n13. lOCode          : numeric % Halstead\'s line count\n14. lOComment       : numeric % Halstead\'s count of lines of comments\n15. lOBlank         : numeric % Halstead\'s count of blank lines\n16. lOCodeAndComment: numeric\n17. uniq_Op         : numeric % unique operators\n18. uniq_Opnd       : numeric % unique operands\n19. total_Op        : numeric % total operators\n20. total_Opnd      : numeric % total operands\n21: branchCount     : numeric % of the flow graph\n22. defects         : {false,true} % module has/has not one or more reported defects\n\n## Missing attributes\nNone\n\n## Class Distribution\nThe class value (defects) is discrete\nfalse: 2106 = 19.35%\ntrue:  8779 = 80.65%', 'ARFF', NULL, NULL, NULL, '2014-10-06 23:57:19', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/53936/jm1.arff', 'true', 51, 'defects', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-10-06 23:57:19'),
(52, 2, NULL, 'kc2', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\n%-*- text -*-\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nThis is a PROMISE Software Engineering Repository data set made publicly\navailable in order to encourage repeatable, verifiable, refutable, and/or\nimprovable predictive models of software engineering.\n\nIf you publish material based on PROMISE data sets then, please\nfollow the acknowledgment guidelines posted on the PROMISE repository\nweb page http://promise.site.uottawa.ca/SERepository .\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n1. Title/Topic: KC2/software defect prediction\n2. Sources:\n\n-- Creators:  NASA, then the NASA Metrics Data Program,\n-- http://mdp.ivv.nasa.gov. Contacts: Mike Chapman,\nGalaxy Global Corporation (Robert.Chapman@ivv.nasa.gov)\n+1-304-367-8341; Pat Callis, NASA, NASA project manager\nfor MDP (Patrick.E.Callis@ivv.nasa.gov) +1-304-367-8309\n\n-- Donor: Tim Menzies (tim@barmag.net)\n\n-- Date:  December 2 2004\n3. Past usage:\n\n1. How Good is Your Blind  Spot Sampling Policy?; 2003; Tim Menzies\nand Justin S. Di Stefano; 2004 IEEE Conference on High Assurance\nSoftware Engineering (http://menzies.us/pdf/03blind.pdf).\n\n-- Results:\n\n-- Very simple learners (ROCKY) perform as well in this domain\nas more sophisticated methods (e.g. J48, model trees, model\ntrees) for predicting detects\n\n-- Many learners have very low false alarm rates.\n\n-- Probability of detection (PD) rises with effort and rarely\nrises above it.\n\n-- High PDs are associated with high PFs (probability of\nfailure)\n\n-- PD, PF, effort can change significantly while accuracy\nremains essentially stable\n\n-- With two notable exceptions, detectors learned from one\ndata set (e.g. KC2) have nearly they same properties when\napplied to another (e.g. PC2, KC2). Exceptions:\n-- LinesOfCode measures generate wider inter-data-set variances;\n-- Precision\'s inter-data-set variances vary wildly\n\n2. \"Assessing Predictors of Software Defects\", T. Menzies and\nJ. DiStefano and A. Orrego and R. Chapman, 2004,\nProceedings, workshop on Predictive Software Models, Chicago,\nAvailable from http://menzies.us/pdf/04psm.pdf.\n-- Results:\n\n-- From KC2, Naive Bayes generated PDs of 50% with PF of 10%\n\n-- Naive Bayes out-performs J48 for defect detection\n\n-- When learning on more and more data, little improvement is\nseen after processing 300 examples.\n\n-- PDs are much higher from data collected below the sub-sub-\nsystem level.\n\n-- Accuracy is a surprisingly uninformative measure of success\nfor a defect detector. Two detectors with the same accuracy\ncan have widely varying PDs and PFs.\n4. Relevant information:\n\n-- Data from C++ functions. Science data processing; another part\nof the same project as KC1; different personnel than KC1.  Shared\nsome third-party software libraries with KC1, but no other software\noverlap.\n\n-- Data comes from McCabe and Halstead features extractors of\nsource code.  These features were defined in the 70s in an attempt\nto objectively characterize code features that are associated with\nsoftware quality.  The nature of association is under dispute.\nNotes on McCabe and Halstead follow.\n\n-- The McCabe and Halstead measures are \"module\"-based where a\n\"module\" is the smallest unit of functionality. In C or Smalltalk,\n\"modules\" would be called \"function\" or \"method\" respectively.\n\n-- Defect detectors can be assessed according to the following measures:\n\nmodule actually has defects\n+-------------+------------+\n|     no      |     yes    |\n+-----+-------------+------------+\nclassifier predicts no defects |  no |      a      |      b     |\n+-----+-------------+------------+\nclassifier predicts some defects | yes |      c      |      d     |\n+-----+-------------+------------+\n\naccuracy                   = acc          = (a+d)/(a+b+c+d\nprobability of detection   = pd  = recall = d/(b+d)\nprobability of false alarm = pf           = c/(a+c)\nprecision                  = prec         = d/(c+d)\neffort                     = amount of code selected by detector\n= (c.LOC + d.LOC)/(Total LOC)\n\nIdeally, detectors have high PDs, low PFs, and low\neffort. This ideal state rarely happens:\n\n-- PD and effort are linked. The more modules that trigger\nthe detector, the higher the PD. However, effort also gets\nincreases\n\n-- High PD or low PF comes at the cost of high PF or low PD\n(respectively). This linkage can be seen in a standard\nreceiver operator curve (ROC).  Suppose, for example, LOC> x\nis used as the detector (i.e. we assume large modules have\nmore errors). LOC > x represents a family of detectors. At\nx=0, EVERY module is predicted to have errors. This detector\nhas a high PD but also a high false alarm rate. At x=0, NO\nmodule is predicted to have errors. This detector has a low\nfalse alarm rate but won\'t detect anything at all. At 0<x<1,\na set of detectors are generated as shown below:\n\npd\n1 |           x  x  x                KEY:\n|        x     .                   \".\"  denotes the line PD=PF\n|     x      .                     \"x\"  denotes the roc curve\n|   x      .                            for a set of detectors\n|  x     .\n| x    .\n| x  .\n|x .\n|x\nx------------------ pf\n0                   1\n\nNote that:\n\n-- The only way to make no mistakes (PF=0) is to do nothing\n(PD=0)\n\n-- The only way to catch more detects is to make more\nmistakes (increasing PD means increasing PF).\n\n-- Our detector bends towards the \"sweet spot\" of\n<PD=1,PF=0> but does not reach it.\n\n-- The line pf=pd on the above graph represents the \"no information\"\nline. If pf=pd then the detector is pretty useless. The better\nthe detector, the more it rises above PF=PD towards the \"sweet spot\".\n\nNOTES ON MCCABE/HALSTEAD\n========================\nMcCabe argued that code with complicated pathways are more\nerror-prone.  His metrics therefore reflect the pathways within a\ncode module.\n@Article{mccabe76,\ntitle 	= \"A Complexity Measure\",\nauthor 	= \"T.J. McCabe\",\npages 	= \"308--320\",\njournal = \"IEEE Transactions on Software Engineering\",\nyear 	= \"1976\",\nvolume 	= \"2\",\nmonth 	= \"December\",\nnumber 	= \"4\"}\n\nHalstead argued that code that is hard to read is more likely to be\nfault prone. Halstead estimates reading complexity by counting the\nnumber of concepts in a module; e.g. number of unique operators.\n@Book{halstead77,\nAuthor 	  = \"M.H. Halstead\",\nTitle 	  = \"Elements of Software Science\",\nPublisher = \"Elsevier \",\nYear 	  = 1977}\n\nWe study these static code measures since they are useful, easy to\nuse, and widely used:\n\n-- USEFUL: E.g. this data set can generate highly accurate\npredictors for defects\n\n-- EASY TO USE: Static code measures (e.g. lines of code, the\nMcCabe/Halstead measures) can be automatically and cheaply\ncollected.\n\n-- WIDELY USED: Many researchers use static measures to guide\nsoftware quality predictions (see the reference list in the above\n\"blind spot\" paper. Verification and validation (V\\&V) textbooks\nadvise using static code complexity measures to decide which\nmodules are worthy of manual inspections.  Further, we know of\nseveral large government software contractors that won\'t review\nsoftware modules _unless_ tools like McCabe predict that they are\nfault prone.  Hence, defect detectors have a major economic impact\nwhen they may force programmers to rewrite code.\n\nNevertheless, the merits of these metrics has been widely\ncriticized.  Static code measures are hardly a complete\ncharacterization of the internals of a function. Fenton offers an\ninsightful example where the same functionality is achieved using\ndifferent programming language constructs resulting in different\nstatic measurements for that module. Fenton uses this example to\nargue the uselessness of static code measures.\n@book{fenton97,\nauthor    = \"N.E. Fenton and S.L. Pfleeger\",\ntitle     = {Software metrics: a Rigorous \\& Practical Approach},\npublisher = {International Thompson Press},\nyear      = {1997}}\n\nAn alternative interpretation of Fenton\'s example is that static\nmeasures can never be a definite and certain indicator of the\npresence of a fault.  Rather, defect detectors based on static\nmeasures are best viewed as probabilistic statements that the\nfrequency of faults tends to increase in code modules that trigger\nthe detector.  By definition, such probabilistic statements will\nare not categorical claims with some a non-zero false alarm\nrate. The research challenge for data miners is to ensure that\nthese false alarms do not cripple their learned theories.\n\nThe McCabe metrics are a collection of four software metrics:\nessential complexity, cyclomatic complexity, design complexity and\nLOC, Lines of Code.\n\n-- Cyclomatic Complexity, or \"v(G)\", measures the number of\n\"linearly independent paths\". A set of paths is said to be\nlinearly independent if no path in the set is a linear combination\nof any other paths in the set through a program\'s \"flowgraph\". A\nflowgraph is a directed graph where each node corresponds to a\nprogram statement, and each arc indicates the flow of control from\none statement to another. \"v(G)\" is calculated by \"v(G) = e - n + 2\"\nwhere \"G\" is a program\'s flowgraph, \"e\" is the number of arcs in\nthe flowgraph, and \"n\" is the number of nodes in the\nflowgraph. The standard McCabes rules (\"v(G)\">10), are used to\nidentify fault-prone module.\n\n-- Essential Complexity, or \"ev(G)$\" is the extent to which a\nflowgraph can be \"reduced\" by decomposing all the subflowgraphs\nof $G$ that are \"D-structured primes\". Such \"D-structured\nprimes\" are also sometimes referred to as \"proper one-entry\none-exit subflowgraphs\" (for a more thorough discussion of\nD-primes, see the Fenton text referenced above). \"ev(G)\" is\ncalculated using \"ev(G)= v(G) - m\" where $m$ is the number of\nsubflowgraphs of \"G\" that are D-structured primes.\n\n-- Design Complexity, or \"iv(G)\", is the cyclomatic complexity of a\nmodule\'s reduced flowgraph.  The flowgraph, \"G\", of a module is\nreduced to eliminate any complexity which does not influence the\ninterrelationship between design modules.  According to McCabe,\nthis complexity measurement reflects the modules calling patterns\nto its immediate subordinate modules.\n\n-- Lines of code is measured according to McCabe\'s line counting\nconventions.\n\nThe Halstead falls into three groups: the base measures, the\nderived measures, and lines of code measures.\n\n-- Base measures:\n-- mu1             = number of unique operators\n-- mu2             = number of unique operands\n-- N1              = total occurrences of operators\n-- N2              = total occurrences of operands\n-- length     = N  = N1 + N2\n-- vocabulary = mu = mu1 + mu2\n-- Constants set for each function:\n-- mu1\' =  2 = potential operator count (just the function\nname and the \"return\" operator)\n-- mu2\'      = potential operand count. (the number\nof arguments to the module)\n\nFor example, the expression \"return max(w+x,x+y)\" has \"N1=4\"\noperators \"return, max, +,+)\", \"N2=4\" operands (w,x,x,y),\n\"mu1=3\" unique operators (return, max,+), and \"mu2=3\" unique\noperands (w,x,y).\n\n-- Derived measures:\n-- P = volume = V = N * log2(mu) (the number of mental\ncomparisons needed to write\na program of length N)\n-- V* = volume on minimal implementation\n= (2 + mu2\')*log2(2 + mu2\')\n-- L  = program length = V*/N\n-- D  = difficulty = 1/L\n-- L\' = 1/D\n-- I  = intelligence = L\'*V\'\n-- E  = effort to write program = V/L\n-- T  = time to write program = E/18 seconds\n5. Number of instances: 522\n6. Number of attributes: 22 (5 different lines of code measure,\n3 McCabe metrics, 4 base Halstead measures, 8 derived\nHalstead measures, a branch-count, and 1 goal field)\n7. Attribute Information:\n\n\n1. loc             : numeric % McCabe\'s line count of code\n2. v(g)            : numeric % McCabe \"cyclomatic complexity\"\n3. ev(g)           : numeric % McCabe \"essential complexity\"\n4. iv(g)           : numeric % McCabe \"design complexity\"\n5. n               : numeric % Halstead total operators + operands\n6. v               : numeric % Halstead \"volume\"\n7. l               : numeric % Halstead \"program length\"\n8. d               : numeric % Halstead \"difficulty\"\n9. i               : numeric % Halstead \"intelligence\"\n10. e               : numeric % Halstead \"effort\"\n11. b               : numeric % Halstead\n12. t               : numeric % Halstead\'s time estimator\n13. lOCode          : numeric % Halstead\'s line count\n14. lOComment       : numeric % Halstead\'s count of lines of comments\n15. lOBlank         : numeric % Halstead\'s count of blank lines\n16. lOCodeAndComment: numeric\n17. uniq_Op         : numeric % unique operators\n18. uniq_Opnd       : numeric % unique operands\n19. total_Op        : numeric % total operators\n20. total_Opnd      : numeric % total operands\n21: branchCount     : numeric % of the flow graph\n22. problems        : {no,yes}% module has/has not one or more\n% reported defects\n8. Missing attributes: none\n9. Class Distribution: the class value (problems) is discrete\nyes: 105 = 20.5%\nno:  415 = 79.5%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%', 'ARFF', NULL, NULL, NULL, '2014-10-06 23:57:36', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/53946/kc2.arff', 'true', 52, 'problems', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-10-06 23:57:36'),
(53, 2, NULL, 'kc1', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\n%-*- text -*-\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nThis is a PROMISE Software Engineering Repository data set made publicly\navailable in order to encourage repeatable, verifiable, refutable, and/or\nimprovable predictive models of software engineering.\n\nIf you publish material based on PROMISE data sets then, please\nfollow the acknowledgment guidelines posted on the PROMISE repository\nweb page http://promise.site.uottawa.ca/SERepository .\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n1. Title/Topic: KC1/software defect prediction\n2. Sources:\n\n-- Creators:  NASA, then the NASA Metrics Data Program,\n-- http://mdp.ivv.nasa.gov. Contacts: Mike Chapman,\nGalaxy Global Corporation (Robert.Chapman@ivv.nasa.gov)\n+1-304-367-8341; Pat Callis, NASA, NASA project manager\nfor MDP (Patrick.E.Callis@ivv.nasa.gov) +1-304-367-8309\n\n-- Donor: Tim Menzies (tim@barmag.net)\n\n-- Date:  December 2 2004\n3. Past usage:\n\n1. How Good is Your Blind  Spot Sampling Policy?; 2003; Tim Menzies\nand Justin S. Di Stefano; 2004 IEEE Conference on High Assurance\nSoftware Engineering (http://menzies.us/pdf/03blind.pdf).\n\n-- Results:\n\n-- Very simple learners (ROCKY) perform as well in this domain\nas more sophisticated methods (e.g. J48, model trees, model\ntrees) for predicting detects\n\n-- Many learners have very low false alarm rates.\n\n-- Probability of detection (PD) rises with effort and rarely\nrises above it.\n\n-- High PDs are associated with high PFs (probability of\nfailure)\n\n-- PD, PF, effort can change significantly while accuracy\nremains essentially stable\n\n-- With two notable exceptions, detectors learned from one\ndata set (e.g. KC2) have nearly they same properties when\napplied to another (e.g. PC2, KC2). Exceptions:\n-- LinesOfCode measures generate wider inter-data-set variances;\n-- Precision\'s inter-data-set variances vary wildly\n\n2. \"Assessing Predictors of Software Defects\", T. Menzies and\nJ. DiStefano and A. Orrego and R. Chapman, 2004,\nProceedings, workshop on Predictive Software Models, Chicago,\nAvailable from http://menzies.us/pdf/04psm.pdf.\n-- Results:\n\n-- From KC2, Naive Bayes generated PDs of 45% with PF of 10%\n\n-- Naive Bayes out-performs J48 for defect detection\n\n-- When learning on more and more data, little improvement is\nseen after processing 300 examples.\n\n-- PDs are much higher from data collected below the sub-sub-\nsystem level.\n\n-- Accuracy is a surprisingly uninformative measure of success\nfor a defect detector. Two detectors with the same accuracy\ncan have widely varying PDs and PFs.\n4. Relevant information:\n\n\n-- KC1 is a \"C++\" system implementing storage management for\nreceiving and processing ground data\n\n-- Data comes from McCabe and Halstead features extractors of\nsource code.  These features were defined in the 70s in an attempt\nto objectively characterize code features that are associated with\nsoftware quality.  The nature of association is under dispute.\nNotes on McCabe and Halstead follow.\n\n-- The McCabe and Halstead measures are \"module\"-based where a\n\"module\" is the smallest unit of functionality. In C or Smalltalk,\n\"modules\" would be called \"function\" or \"method\" respectively.\n\n-- Defect detectors can be assessed according to the following measures:\n\nmodule actually has defects\n+-------------+------------+\n|     no      |     yes    |\n+-----+-------------+------------+\nclassifier predicts no defects |  no |      a      |      b     |\n+-----+-------------+------------+\nclassifier predicts some defects | yes |      c      |      d     |\n+-----+-------------+------------+\n\naccuracy                   = acc          = (a+d)/(a+b+c+d\nprobability of detection   = pd  = recall = d/(b+d)\nprobability of false alarm = pf           = c/(a+c)\nprecision                  = prec         = d/(c+d)\neffort                     = amount of code selected by detector\n= (c.LOC + d.LOC)/(Total LOC)\n\nIdeally, detectors have high PDs, low PFs, and low\neffort. This ideal state rarely happens:\n\n-- PD and effort are linked. The more modules that trigger\nthe detector, the higher the PD. However, effort also gets\nincreases\n\n-- High PD or low PF comes at the cost of high PF or low PD\n(respectively). This linkage can be seen in a standard\nreceiver operator curve (ROC).  Suppose, for example, LOC> x\nis used as the detector (i.e. we assume large modules have\nmore errors). LOC > x represents a family of detectors. At\nx=0, EVERY module is predicted to have errors. This detector\nhas a high PD but also a high false alarm rate. At x=0, NO\nmodule is predicted to have errors. This detector has a low\nfalse alarm rate but won\'t detect anything at all. At 0<x<1,\na set of detectors are generated as shown below:\n\npd\n1 |           x  x  x                KEY:\n|        x     .                   \".\"  denotes the line PD=PF\n|     x      .                     \"x\"  denotes the roc curve\n|   x      .                            for a set of detectors\n|  x     .\n| x    .\n| x  .\n|x .\n|x\nx------------------ pf\n0                   1\n\nNote that:\n\n-- The only way to make no mistakes (PF=0) is to do nothing\n(PD=0)\n\n-- The only way to catch more detects is to make more\nmistakes (increasing PD means increasing PF).\n\n-- Our detector bends towards the \"sweet spot\" of\n<PD=1,PF=0> but does not reach it.\n\n-- The line pf=pd on the above graph represents the \"no information\"\nline. If pf=pd then the detector is pretty useless. The better\nthe detector, the more it rises above PF=PD towards the \"sweet spot\".\n\nNOTES ON MCCABE/HALSTEAD\n========================\nMcCabe argued that code with complicated pathways are more\nerror-prone.  His metrics therefore reflect the pathways within a\ncode module.\n@Article{mccabe76,\ntitle 	= \"A Complexity Measure\",\nauthor 	= \"T.J. McCabe\",\npages 	= \"308--320\",\njournal = \"IEEE Transactions on Software Engineering\",\nyear 	= \"1976\",\nvolume 	= \"2\",\nmonth 	= \"December\",\nnumber 	= \"4\"}\n\nHalstead argued that code that is hard to read is more likely to be\nfault prone. Halstead estimates reading complexity by counting the\nnumber of concepts in a module; e.g. number of unique operators.\n@Book{halstead77,\nAuthor 	  = \"M.H. Halstead\",\nTitle 	  = \"Elements of Software Science\",\nPublisher = \"Elsevier \",\nYear 	  = 1977}\n\nWe study these static code measures since they are useful, easy to\nuse, and widely used:\n\n-- USEFUL: E.g. this data set can generate highly accurate\npredictors for defects\n\n-- EASY TO USE: Static code measures (e.g. lines of code, the\nMcCabe/Halstead measures) can be automatically and cheaply\ncollected.\n\n-- WIDELY USED: Many researchers use static measures to guide\nsoftware quality predictions (see the reference list in the above\n\"blind spot\" paper. Verification and validation (V\\&V) textbooks\nadvise using static code complexity measures to decide which\nmodules are worthy of manual inspections.  Further, we know of\nseveral large government software contractors that won\'t review\nsoftware modules _unless_ tools like McCabe predict that they are\nfault prone.  Hence, defect detectors have a major economic impact\nwhen they may force programmers to rewrite code.\n\nNevertheless, the merits of these metrics has been widely\ncriticized.  Static code measures are hardly a complete\ncharacterization of the internals of a function. Fenton offers an\ninsightful example where the same functionality is achieved using\ndifferent programming language constructs resulting in different\nstatic measurements for that module. Fenton uses this example to\nargue the uselessness of static code measures.\n@book{fenton97,\nauthor    = \"N.E. Fenton and S.L. Pfleeger\",\ntitle     = {Software metrics: a Rigorous \\& Practical Approach},\npublisher = {International Thompson Press},\nyear      = {1997}}\n\nAn alternative interpretation of Fenton\'s example is that static\nmeasures can never be a definite and certain indicator of the\npresence of a fault.  Rather, defect detectors based on static\nmeasures are best viewed as probabilistic statements that the\nfrequency of faults tends to increase in code modules that trigger\nthe detector.  By definition, such probabilistic statements will\nare not categorical claims with some a non-zero false alarm\nrate. The research challenge for data miners is to ensure that\nthese false alarms do not cripple their learned theories.\n\nThe McCabe metrics are a collection of four software metrics:\nessential complexity, cyclomatic complexity, design complexity and\nLOC, Lines of Code.\n\n-- Cyclomatic Complexity, or \"v(G)\", measures the number of\n\"linearly independent paths\". A set of paths is said to be\nlinearly independent if no path in the set is a linear combination\nof any other paths in the set through a program\'s \"flowgraph\". A\nflowgraph is a directed graph where each node corresponds to a\nprogram statement, and each arc indicates the flow of control from\none statement to another. \"v(G)\" is calculated by \"v(G) = e - n + 2\"\nwhere \"G\" is a program\'s flowgraph, \"e\" is the number of arcs in\nthe flowgraph, and \"n\" is the number of nodes in the\nflowgraph. The standard McCabes rules (\"v(G)\">10), are used to\nidentify fault-prone module.\n\n-- Essential Complexity, or \"ev(G)$\" is the extent to which a\nflowgraph can be \"reduced\" by decomposing all the subflowgraphs\nof $G$ that are \"D-structured primes\". Such \"D-structured\nprimes\" are also sometimes referred to as \"proper one-entry\none-exit subflowgraphs\" (for a more thorough discussion of\nD-primes, see the Fenton text referenced above). \"ev(G)\" is\ncalculated using \"ev(G)= v(G) - m\" where $m$ is the number of\nsubflowgraphs of \"G\" that are D-structured primes.\n\n-- Design Complexity, or \"iv(G)\", is the cyclomatic complexity of a\nmodule\'s reduced flowgraph.  The flowgraph, \"G\", of a module is\nreduced to eliminate any complexity which does not influence the\ninterrelationship between design modules.  According to McCabe,\nthis complexity measurement reflects the modules calling patterns\nto its immediate subordinate modules.\n\n-- Lines of code is measured according to McCabe\'s line counting\nconventions.\n\nThe Halstead falls into three groups: the base measures, the\nderived measures, and lines of code measures.\n\n-- Base measures:\n-- mu1             = number of unique operators\n-- mu2             = number of unique operands\n-- N1              = total occurrences of operators\n-- N2              = total occurrences of operands\n-- length     = N  = N1 + N2\n-- vocabulary = mu = mu1 + mu2\n-- Constants set for each function:\n-- mu1\' =  2 = potential operator count (just the function\nname and the \"return\" operator)\n-- mu2\'      = potential operand count. (the number\nof arguments to the module)\n\nFor example, the expression \"return max(w+x,x+y)\" has \"N1=4\"\noperators \"return, max, +,+)\", \"N2=4\" operands (w,x,x,y),\n\"mu1=3\" unique operators (return, max,+), and \"mu2=3\" unique\noperands (w,x,y).\n\n-- Derived measures:\n-- P = volume = V = N * log2(mu) (the number of mental\ncomparisons needed to write\na program of length N)\n-- V* = volume on minimal implementation\n= (2 + mu2\')*log2(2 + mu2\')\n-- L  = program length = V*/N\n-- D  = difficulty = 1/L\n-- L\' = 1/D\n-- I  = intelligence = L\'*V\'\n-- E  = effort to write program = V/L\n-- T  = time to write program = E/18 seconds\n5. Number of instances: 2109\n6. Number of attributes: 22 (5 different lines of code measure,\n3 McCabe metrics, 4 base Halstead measures, 8 derived\nHalstead measures, a branch-count, and 1 goal field)\n7. Attribute Information:\n\n1. loc             : numeric % McCabe\'s line count of code\n2. v(g)            : numeric % McCabe \"cyclomatic complexity\"\n3. ev(g)           : numeric % McCabe \"essential complexity\"\n4. iv(g)           : numeric % McCabe \"design complexity\"\n5. n               : numeric % Halstead total operators + operands\n6. v               : numeric % Halstead \"volume\"\n7. l               : numeric % Halstead \"program length\"\n8. d               : numeric % Halstead \"difficulty\"\n9. i               : numeric % Halstead \"intelligence\"\n10. e               : numeric % Halstead \"effort\"\n11. b               : numeric % Halstead\n12. t               : numeric % Halstead\'s time estimator\n13. lOCode          : numeric % Halstead\'s line count\n14. lOComment       : numeric % Halstead\'s count of lines of comments\n15. lOBlank         : numeric % Halstead\'s count of blank lines\n16. lOCodeAndComment: numeric\n17. uniq_Op         : numeric % unique operators\n18. uniq_Opnd       : numeric % unique operands\n19. total_Op        : numeric % total operators\n20. total_Opnd      : numeric % total operands\n21: branchCount     : numeric % of the flow graph\n22. problems        : {false,true}% module has/has not one or more\n% reported defects\n8. Missing attributes: none\n9. Class Distribution: the class value (problems) is discrete\nyes:  326 = 15.45%\nno:  1783 = 84.54%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%', 'ARFF', NULL, NULL, NULL, '2014-10-06 23:57:43', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/53950/kc1.arff', 'true', 53, 'defects', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-10-06 23:57:43'),
(54, 2, NULL, 'pc1', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\n%-*- text -*-\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nThis is a PROMISE Software Engineering Repository data set made publicly\navailable in order to encourage repeatable, verifiable, refutable, and/or\nimprovable predictive models of software engineering.\n\nIf you publish material based on PROMISE data sets then, please\nfollow the acknowledgment guidelines posted on the PROMISE repository\nweb page http://promise.site.uottawa.ca/SERepository .\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n1. Title/Topic: PC1/software defect prediction\n2. Sources:\n\n-- Creators:  NASA, then the NASA Metrics Data Program,\n-- http://mdp.ivv.nasa.gov. Contacts: Mike Chapman,\nGalaxy Global Corporation (Robert.Chapman@ivv.nasa.gov)\n+1-304-367-8341; Pat Callis, NASA, NASA project manager\nfor MDP (Patrick.E.Callis@ivv.nasa.gov) +1-304-367-8309\n\n-- Donor: Tim Menzies (tim@barmag.net)\n\n-- Date:  December 2 2004\n3. Past usage:\n\n1. How Good is Your Blind  Spot Sampling Policy?; 2003; Tim Menzies\nand Justin S. Di Stefano; 2004 IEEE Conference on High Assurance\nSoftware Engineering (http://menzies.us/pdf/03blind.pdf).\n\n-- Results:\n\n-- Very simple learners (ROCKY) perform as well in this domain\nas more sophisticated methods (e.g. J48, model trees, model\ntrees) for predicting detects\n\n-- Many learners have very low false alarm rates.\n\n-- Probability of detection (PD) rises with effort and rarely\nrises above it.\n\n-- High PDs are associated with high PFs (probability of\nfailure)\n\n-- PD, PF, effort can change significantly while accuracy\nremains essentially stable\n\n-- With two notable exceptions, detectors learned from one\ndata set (e.g. KC2) have nearly they same properties when\napplied to another (e.g. PC2, KC2). Exceptions:\n-- LinesOfCode measures generate wider inter-data-set variances;\n-- Precision\'s inter-data-set variances vary wildly\n\n2. \"Assessing Predictors of Software Defects\", T. Menzies and\nJ. DiStefano and A. Orrego and R. Chapman, 2004,\nProceedings, workshop on Predictive Software Models, Chicago,\nAvailable from http://menzies.us/pdf/04psm.pdf.\n-- Results:\n\n-- From JM1, Naive Bayes generated PDs of 20% with PF of 25%\n\n-- Naive Bayes out-performs J48 for defect detection\n\n-- When learning on more and more data, little improvement is\nseen after processing 300 examples.\n\n-- PDs are much higher from data collected below the sub-sub-\nsystem level.\n\n-- Accuracy is a surprisingly uninformative measure of success\nfor a defect detector. Two detectors with the same accuracy\ncan have widely varying PDs and PFs.\n4. Relevant information:\n\n-- Data from C  functions. flight software\nfor earth orbiting satellite.\n\n-- Data comes from McCabe and Halstead features extractors of\nsource code.  These features were defined in the 70s in an attempt\nto objectively characterize code features that are associated with\nsoftware quality.  The nature of association is under dispute.\nNotes on McCabe and Halstead follow.\n\n-- The McCabe and Halstead measures are \"module\"-based where a\n\"module\" is the smallest unit of functionality. In C or Smalltalk,\n\"modules\" would be called \"function\" or \"method\" respectively.\n\n-- Defect detectors can be assessed according to the following measures:\n\nmodule actually has defects\n+-------------+------------+\n|     no      |     yes    |\n+-----+-------------+------------+\nclassifier predicts no defects |  no |      a      |      b     |\n+-----+-------------+------------+\nclassifier predicts some defects | yes |      c      |      d     |\n+-----+-------------+------------+\n\naccuracy                   = acc          = (a+d)/(a+b+c+d\nprobability of detection   = pd  = recall = d/(b+d)\nprobability of false alarm = pf           = c/(a+c)\nprecision                  = prec         = d/(c+d)\neffort                     = amount of code selected by detector\n= (c.LOC + d.LOC)/(Total LOC)\n\nIdeally, detectors have high PDs, low PFs, and low\neffort. This ideal state rarely happens:\n\n-- PD and effort are linked. The more modules that trigger\nthe detector, the higher the PD. However, effort also gets\nincreases\n\n-- High PD or low PF comes at the cost of high PF or low PD\n(respectively). This linkage can be seen in a standard\nreceiver operator curve (ROC).  Suppose, for example, LOC> x\nis used as the detector (i.e. we assume large modules have\nmore errors). LOC > x represents a family of detectors. At\nx=0, EVERY module is predicted to have errors. This detector\nhas a high PD but also a high false alarm rate. At x=0, NO\nmodule is predicted to have errors. This detector has a low\nfalse alarm rate but won\'t detect anything at all. At 0<x<1,\na set of detectors are generated as shown below:\n\npd\n1 |           x  x  x                KEY:\n|        x     .                   \".\"  denotes the line PD=PF\n|     x      .                     \"x\"  denotes the roc curve\n|   x      .                            for a set of detectors\n|  x     .\n| x    .\n| x  .\n|x .\n|x\nx------------------ pf\n0                   1\n\nNote that:\n\n-- The only way to make no mistakes (PF=0) is to do nothing\n(PD=0)\n\n-- The only way to catch more detects is to make more\nmistakes (increasing PD means increasing PF).\n\n-- Our detector bends towards the \"sweet spot\" of\n<PD=1,PF=0> but does not reach it.\n\n-- The line pf=pd on the above graph represents the \"no information\"\nline. If pf=pd then the detector is pretty useless. The better\nthe detector, the more it rises above PF=PD towards the \"sweet spot\".\n\nNOTES ON MCCABE/HALSTEAD\n========================\nMcCabe argued that code with complicated pathways are more\nerror-prone.  His metrics therefore reflect the pathways within a\ncode module.\n@Article{mccabe76,\ntitle 	= \"A Complexity Measure\",\nauthor 	= \"T.J. McCabe\",\npages 	= \"308--320\",\njournal = \"IEEE Transactions on Software Engineering\",\nyear 	= \"1976\",\nvolume 	= \"2\",\nmonth 	= \"December\",\nnumber 	= \"4\"}\n\nHalstead argued that code that is hard to read is more likely to be\nfault prone. Halstead estimates reading complexity by counting the\nnumber of concepts in a module; e.g. number of unique operators.\n@Book{halstead77,\nAuthor 	  = \"M.H. Halstead\",\nTitle 	  = \"Elements of Software Science\",\nPublisher = \"Elsevier \",\nYear 	  = 1977}\n\nWe study these static code measures since they are useful, easy to\nuse, and widely used:\n\n-- USEFUL: E.g. this data set can generate highly accurate\npredictors for defects\n\n-- EASY TO USE: Static code measures (e.g. lines of code, the\nMcCabe/Halstead measures) can be automatically and cheaply\ncollected.\n\n-- WIDELY USED: Many researchers use static measures to guide\nsoftware quality predictions (see the reference list in the above\n\"blind spot\" paper. Verification and validation (V\\&V) textbooks\nadvise using static code complexity measures to decide which\nmodules are worthy of manual inspections.  Further, we know of\nseveral large government software contractors that won\'t review\nsoftware modules _unless_ tools like McCabe predict that they are\nfault prone.  Hence, defect detectors have a major economic impact\nwhen they may force programmers to rewrite code.\n\nNevertheless, the merits of these metrics has been widely\ncriticized.  Static code measures are hardly a complete\ncharacterization of the internals of a function. Fenton offers an\ninsightful example where the same functionality is achieved using\ndifferent programming language constructs resulting in different\nstatic measurements for that module. Fenton uses this example to\nargue the uselessness of static code measures.\n@book{fenton97,\nauthor    = \"N.E. Fenton and S.L. Pfleeger\",\ntitle     = {Software metrics: a Rigorous \\& Practical Approach},\npublisher = {International Thompson Press},\nyear      = {1997}}\n\nAn alternative interpretation of Fenton\'s example is that static\nmeasures can never be a definite and certain indicator of the\npresence of a fault.  Rather, defect detectors based on static\nmeasures are best viewed as probabilistic statements that the\nfrequency of faults tends to increase in code modules that trigger\nthe detector.  By definition, such probabilistic statements will\nare not categorical claims with some a non-zero false alarm\nrate. The research challenge for data miners is to ensure that\nthese false alarms do not cripple their learned theories.\n\nThe McCabe metrics are a collection of four software metrics:\nessential complexity, cyclomatic complexity, design complexity and\nLOC, Lines of Code.\n\n-- Cyclomatic Complexity, or \"v(G)\", measures the number of\n\"linearly independent paths\". A set of paths is said to be\nlinearly independent if no path in the set is a linear combination\nof any other paths in the set through a program\'s \"flowgraph\". A\nflowgraph is a directed graph where each node corresponds to a\nprogram statement, and each arc indicates the flow of control from\none statement to another. \"v(G)\" is calculated by \"v(G) = e - n + 2\"\nwhere \"G\" is a program\'s flowgraph, \"e\" is the number of arcs in\nthe flowgraph, and \"n\" is the number of nodes in the\nflowgraph. The standard McCabes rules (\"v(G)\">10), are used to\nidentify fault-prone module.\n\n-- Essential Complexity, or \"ev(G)$\" is the extent to which a\nflowgraph can be \"reduced\" by decomposing all the subflowgraphs\nof $G$ that are \"D-structured primes\". Such \"D-structured\nprimes\" are also sometimes referred to as \"proper one-entry\none-exit subflowgraphs\" (for a more thorough discussion of\nD-primes, see the Fenton text referenced above). \"ev(G)\" is\ncalculated using \"ev(G)= v(G) - m\" where $m$ is the number of\nsubflowgraphs of \"G\" that are D-structured primes.\n\n-- Design Complexity, or \"iv(G)\", is the cyclomatic complexity of a\nmodule\'s reduced flowgraph.  The flowgraph, \"G\", of a module is\nreduced to eliminate any complexity which does not influence the\ninterrelationship between design modules.  According to McCabe,\nthis complexity measurement reflects the modules calling patterns\nto its immediate subordinate modules.\n\n-- Lines of code is measured according to McCabe\'s line counting\nconventions.\n\nThe Halstead falls into three groups: the base measures, the\nderived measures, and lines of code measures.\n\n-- Base measures:\n-- mu1             = number of unique operators\n-- mu2             = number of unique operands\n-- N1              = total occurrences of operators\n-- N2              = total occurrences of operands\n-- length     = N  = N1 + N2\n-- vocabulary = mu = mu1 + mu2\n-- Constants set for each function:\n-- mu1\' =  2 = potential operator count (just the function\nname and the \"return\" operator)\n-- mu2\'      = potential operand count. (the number\nof arguments to the module)\n\nFor example, the expression \"return max(w+x,x+y)\" has \"N1=4\"\noperators \"return, max, +,+)\", \"N2=4\" operands (w,x,x,y),\n\"mu1=3\" unique operators (return, max,+), and \"mu2=3\" unique\noperands (w,x,y).\n\n-- Derived measures:\n-- P = volume = V = N * log2(mu) (the number of mental\ncomparisons needed to write\na program of length N)\n-- V* = volume on minimal implementation\n= (2 + mu2\')*log2(2 + mu2\')\n-- L  = program length = V*/N\n-- D  = difficulty = 1/L\n-- L\' = 1/D\n-- I  = intelligence = L\'*V\'\n-- E  = effort to write program = V/L\n-- T  = time to write program = E/18 seconds\n5. Number of instances: 1109\n6. Number of attributes: 22 (5 different lines of code measure,\n3 McCabe metrics, 4 base Halstead measures, 8 derived\nHalstead measures, a branch-count, and 1 goal field)\n7. Attribute Information:\n\n1. loc             : numeric % McCabe\'s line count of code\n2. v(g)            : numeric % McCabe \"cyclomatic complexity\"\n3. ev(g)           : numeric % McCabe \"essential complexity\"\n4. iv(g)           : numeric % McCabe \"design complexity\"\n5. n               : numeric % Halstead total operators + operands\n6. v               : numeric % Halstead \"volume\"\n7. l               : numeric % Halstead \"program length\"\n8. d               : numeric % Halstead \"difficulty\"\n9. i               : numeric % Halstead \"intelligence\"\n10. e               : numeric % Halstead \"effort\"\n11. b               : numeric % Halstead\n12. t               : numeric % Halstead\'s time estimator\n13. lOCode          : numeric % Halstead\'s line count\n14. lOComment       : numeric % Halstead\'s count of lines of comments\n15. lOBlank         : numeric % Halstead\'s count of blank lines\n16. lOCodeAndComment: numeric\n17. uniq_Op         : numeric % unique operators\n18. uniq_Opnd       : numeric % unique operands\n19. total_Op        : numeric % total operators\n20. total_Opnd      : numeric % total operands\n21: branchCount     : numeric % of the flow graph\n22. defects         : {false,true} % module has/has not one or more\n% reported defects\n8. Missing attributes: none\n9. Class Distribution: the class value (defects) is discrete\nfalse:   77 =  6.94%\ntrue:  1032 = 93.05%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%', 'ARFF', NULL, NULL, NULL, '2014-10-06 23:57:45', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/53951/pc1.arff', 'true', 54, 'defects', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-10-06 23:57:45'),
(55, 2, NULL, 'KDDCup09_churn', '1', NULL, '**Author**: Orange Telecom  \n**Source**: [ACM KDD Cup](http://www.sigkdd.org/kddcup/index.php) - 2009  \n**Please cite**: \n\nThe KDD Cup 2009 offers the opportunity to work on large marketing databases from the French Telecom company Orange to predict the propensity of customers to switch provider (churn). \n\nChurn (wikipedia definition): Churn rate is also sometimes called attrition rate. It is one of two primary factors that determine\nthe steady-state level of customers a business will support. In its broadest sense, churn rate is a measure of the number\nof individuals or items moving into or out of a collection over a specific period of time.\n\nThe term is used in many contexts, but is most widely applied in business with respect to a contractual customer base. For instance, it is an important factor for any business with a subscriber-based service model, including mobile telephone networks and pay TV operators. The term is also used to refer to participant turnover in peer-to-peer networks.\n\nThe training set contains 50,000 examples.\nThe first predictive 190 variables are numerical and the last 40 predictive variables are categorical.\nThe last target variable is binary {-1,1}.', 'ARFF', NULL, NULL, NULL, '2014-10-07 00:08:02', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/53995/KDDCup09_churn.arff', 'true', 55, 'CHURN', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-10-07 00:08:02'),
(56, 2, NULL, 'KDDCup09_upselling', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDatasets from ACM KDD Cup (http://www.sigkdd.org/kddcup/index.php)\n\nKDD Cup 2009\nhttp://www.kddcup-orange.com\n\nConverted to ARFF format by TunedIT\nCustomer Relationship Management (CRM) is a key element of modern marketing strategies. The KDD Cup 2009 offers the opportunity to work on large marketing databases from the French Telecom company Orange to predict the propensity of customers to switch provider (churn), buy new products or services (appetency), or buy upgrades or add-ons proposed to them to make the sale more profitable (up-selling).\nThe most practical way, in a CRM system, to build knowledge on customer is to produce scores. A score (the output of a model) is an evaluation for all instances of a target variable to explain (i.e. churn, appetency or up-selling). Tools which produce scores allow to project, on a given population, quantifiable information. The score is computed using input variables which describe instances. Scores are then used by the information system (IS), for example, to personalize the customer relationship. An industrial customer analysis platform able to build prediction models with a very large number of input variables has been developed by Orange Labs. This platform implements several processing methods for instances and variables selection, prediction and indexation based on an efficient model combined with variable selection regularization and model averaging method. The main characteristic of this platform is its ability to scale on very large datasets with hundreds of thousands of instances and thousands of variables. The rapid and robust detection of the variables that have most contributed to the output prediction can be a key factor in a marketing application.\nUp-selling (wikipedia definition): Up-selling is a sales technique whereby a salesman attempts to have the customer purchase more expensive\nitems, upgrades, or other add-ons in an attempt to make a more profitable sale.\nUp-selling usually involves marketing more profitable services or products, but up-selling can also be simply exposing the customer\nto other options he or she may not have considered previously.\nUp-selling can imply selling something additional, or selling something that is more profitable or otherwise preferable for the seller instead of the original sale.\nThe training set contains 50,000 examples.\nThe first predictive 190 variables are numerical and the last 40 predictive variables are categorical.\nThe last target variable is binary {-1,1}.', 'ARFF', NULL, NULL, NULL, '2014-10-07 00:08:27', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/53997/KDDCup09_upselling.arff', 'true', 56, 'UPSELLING', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-10-07 00:08:27'),
(57, 2, NULL, 'musk', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDataset from the MLRR repository: http://axon.cs.byu.edu:5000/', 'ARFF', NULL, NULL, NULL, '2014-10-07 00:41:54', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/53999/musk.arff', 'true', 57, 'class', 'ID', '\"conformation_name\"', NULL, 'public', NULL, NULL, 'ID is a row id', '2015-04-15 17:37:23'),
(58, 2, NULL, 'MagicTelescope', '1', NULL, '**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDataset from the MLRR repository: http://axon.cs.byu.edu:5000/', 'ARFF', NULL, NULL, NULL, '2014-10-07 00:42:01', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/54003/MagicTelescope.arff', 'true', 58, 'class:', 'ID', NULL, NULL, 'public', NULL, NULL, 'ID is a row id', '2015-04-15 17:41:20'),
(59, 2, NULL, 'Internet-Advertisements', '1', NULL, '**Author**: Nicholas Kushmerick  \n**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/Internet+Advertisements) - 1998  \n**Please cite**:   \n\nThis dataset represents a set of possible advertisements on Internet pages. The features encode the geometry of the image (if available) as well as phrases occurring in the URL, the image\'s URL and alt text, the anchor text, and words occurring near the anchor text. The task is to predict whether an image is an advertisement (\"ad\") or not (\"nonad\").\n\nRelevant Papers: N. Kushmerick (1999). \"Learning to remove Internet advertisements\", 3rd Int Conf Autonomous Agents.  \nAvailable at: http://rexa.info/paper/2fdc1cee89b7f4f2c9227d6f5d9b05d22c5ab3e9', 'ARFF', '\"Nicholas Kushmerick\"', NULL, NULL, '2014-10-30 11:15:44', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/116567/phpCzcrGG', 'true', 59, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-10-30 11:15:44'),
(60, 2, NULL, 'Click_prediction_small', '5', NULL, '**Author**: Tencent Inc.  \n**Source**: [KDD Cup](https://www.kddcup2012.org/) - 2012  \n**Please cite**:   \n\n**0.1% balanced subsample of the original KDD dataset**  \n\nThis data is derived from the 2012 KDD Cup. The data is subsampled to 0.1% of the original number of instances, downsampling the majority class (click=0) so that the target feature is reasonably balanced (5 to 1).\n\nThe data is about advertisements shown alongside search results in a search engine, and whether or not people clicked on these ads. \nThe task is to build the best possible model to predict whether a user will click on a given ad.\n\nA search session contains information on user id, the query issued by the user, ads displayed to the user, and target feature indicating whether a user clicked at least one of the ads in this session. The number of ads displayed to a user in a session is called ‘depth’. The order of an ad in the displayed list is called ‘position’.  An ad is displayed as a short text called ‘title’, followed by a slightly longer text called ’description’, and a URL  called ‘display URL’.   \nTo construct this dataset each session was split into multiple instances. Each instance describes an ad displayed under a certain setting  (‘depth’, ‘position’).  Instances with the same user id, ad id, query, and setting are merged. Each ad and each user have some additional properties located in separate data files that can be looked up using ids in the instances.\n\nThe dataset has the following features:  \n* Click – binary variable indicating whether a user clicked on at least one ad. \n* Impression - the number of search sessions in which AdID was impressed by UserID who issued Query.\n* Url_hash - URL is hashed for anonymity\n* AdID \n* AdvertiserID - some advertisers consistently optimize their ads, so the title and description of their ads are more attractive than those of others’ ads.\n* Depth - number of ads displayed to a user in a session\n* Position - order of an ad in the displayed list\n* QueryID - is the key of the data file \'queryid_tokensid.txt\'. (follow the link to the original KDD Cup page, track 2)\n* KeywordID - is the key of  \'purchasedkeyword_tokensid.txt\' (follow the link to the original KDD Cup page, track 2)\n* TitleID - is the key of \'titleid_tokensid.txt\'\n* DescriptionID - is the key of \'descriptionid_tokensid.txt\' (follow the link to the original KDD Cup page, track 2)\n* UserID – is also the key of \'userid_profile.txt\' (follow the link to the original KDD Cup page, track 2). 0 is a special value denoting that the user could be identified.', 'ARFF', NULL, NULL, NULL, '2014-11-27 01:18:40', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/184157/phpfGCaQC', 'true', 60, 'click', NULL, '\"url_hash\",\"query_id\"', NULL, 'public', NULL, NULL, NULL, '2014-11-27 01:26:36'),
(61, 64, NULL, 'artificial-characters', '1', NULL, '**Author**: H. Altay Guvenir, Burak Acar, Haldun Muderrisoglu    \n\n**Source**: UCI\n\n**Please cite**:   \n\nDataset artificially generated by using first order theory which describes structure of ten capital letters of English alphabet', 'ARFF', NULL, NULL, NULL, '2015-05-21 20:58:53', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1586212/phpPQrHPH', 'true', 61, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-05-21 20:58:53'),
(62, 64, NULL, 'bank-marketing', '1', NULL, '**Author**: Paulo Cortez, Sérgio Moro   \n**Source**: UCI    \n**Please cite**: S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM\'2011, pp. 117-121, Guimarães, Portugal, October, 2011. EUROSIS.       \n\nAvailable at: [pdf] http://hdl.handle.net/1822/14838\n              [bib] http://www3.dsi.uminho.pt/pcortez/bib/2011-esm-1.txt\n \n1. Title: Bank Marketing\n \n2. Sources\n    Created by: Paulo Cortez (Univ. Minho) and Sérgio Moro (ISCTE-IUL) @ 2012\n    \n3. Past Usage:\n \n   The full dataset was described and analyzed in:\n \n S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM\'2011, pp. 117-121, Guimarães, Portugal, October, 2011. EUROSIS.\n\n4. Relevant Information:\n\nThe data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be (or not) subscribed. \n\nThe classification goal is to predict if the client will subscribe a term deposit (variable y).\n\n5. Attribute information:\n \nFor more information, read [Moro et al., 2011].\n\nInput variables:\n# bank client data:\n1 - age (numeric)\n2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\", \"student\",\"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \n3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\"  means divorced or widowed)\n4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n5 - default: has credit in default? (binary: \"yes\",\"no\")\n6 - balance: average yearly balance, in euros (numeric) \n7 - housing: has housing loan? (binary: \"yes\",\"no\")\n8 - loan: has personal loan? (binary: \"yes\",\"no\")\n# related with the last contact of the current campaign:\n9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \n10 - day: last contact day of the month (numeric)\n11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n12 - duration: last contact duration, in seconds (numeric)\n# other attributes:\n13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n15 - previous: number of contacts performed before this campaign and for this client (numeric)\n16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n \nOutput variable (desired target):\n17 - y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")\n', 'ARFF', NULL, NULL, NULL, '2015-05-21 22:16:49', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1586218/phpkIxskf', 'true', 62, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-05-21 22:16:49'),
(63, 64, NULL, 'banknote-authentication', '1', NULL, '**Author**: Volker Lohweg  \n**Source**: UCI\n**Please cite**:   \n\nSource:\n\nOwner of database: Volker Lohweg (University of Applied Sciences, Ostwestfalen-Lippe, volker.lohweg \'@\' hs-owl.de) \n\nDonor of database: Helene Doerksen (University of Applied Sciences, Ostwestfalen-Lippe, helene.doerksen \'@\' hs-owl.de) . Date received: August, 2012 \n\nData Set Information:\n \nData were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.\n\nAttribute Information:\n \n1. variance of Wavelet Transformed image (continuous) \n2. skewness of Wavelet Transformed image (continuous) \n3. curtosis of Wavelet Transformed image (continuous) \n4. entropy of image (continuous) \n5. class (integer)', 'ARFF', '\"Volker Lohweg\"', NULL, NULL, '2015-05-21 22:40:57', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1586223/php50jXam', 'true', 63, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2016-01-18 18:45:44'),
(64, 64, NULL, 'blood-transfusion-service-center', '1', NULL, '**Author**: Prof. I-Cheng Yeh  \n**Source**: UCI\n**Please cite**: Yeh, I-Cheng, Yang, King-Jang, and Ting, Tao-Ming, \"Knowledge discovery on RFM model using Bernoulli sequence, \"Expert Systems with Applications, 2008 (doi:10.1016/j.eswa.2008.07.018).   \n\nTitle: Blood Transfusion Service Center Data Set\n\nAbstract: Data taken from the Blood Transfusion Service Center in Hsin-Chu City in Taiwan -- this is a classification problem.\n\n-----------------------------------------------------\nDate Donated: 2008-10-03\n-----------------------------------------------------\n  \nSource:\n  \nOriginal Owner and Donor\nProf. I-Cheng Yeh, Department of Information Management, Chung-Hua University,  Hsin Chu, Taiwan 30067, R.O.C.\ne-mail:icyeh \'at\' chu.edu.tw, TEL:886-3-5186511\nDate Donated: October 3, 2008 \n\n-----------------------------------------------------\n  \nData Set Information:\n  \nTo demonstrate the RFMTC marketing model (a modified version of RFM), this study adopted the donor database of Blood Transfusion Service Center in Hsin-Chu City in Taiwan. The center passes their blood transfusion service bus to one university in Hsin-Chu City to gather blood donated about every three months. To build a FRMTC model, we selected 748 donors at random from the donor database. These 748 donor data, each one included R (Recency - months since last donation), F (Frequency - total number of donation), M (Monetary - total blood donated in c.c.), T (Time - months since first donation), and a binary variable representing whether he/she donated blood in March 2007 (1 stand for donating blood; 0 stands for not donating blood).\n\n-----------------------------------------------------\n  \nAttribute Information:\n  \nGiven is the variable name, variable type, the measurement unit and a brief description. The \"Blood Transfusion Service Center\" is a classification problem. The order of this listing corresponds to the order of numerals along the rows of the database.\n\nR (Recency - months since last donation),\nF (Frequency - total number of donation),\nM (Monetary - total blood donated in c.c.),\nT (Time - months since first donation), and a binary variable representing whether he/she donated blood in March 2007 (1 stand for donating blood; 0 stands for not donating blood).\n \nCitation Request:\n  \nNOTE: Reuse of this database is unlimited with retention of copyright notice for Prof. I-Cheng Yeh and the following published paper:\n\nYeh, I-Cheng, Yang, King-Jang, and Ting, Tao-Ming, \"Knowledge discovery on RFM model using Bernoulli sequence, \"Expert Systems with Applications, 2008 (doi:10.1016/j.eswa.2008.07.018).', 'ARFF', NULL, NULL, NULL, '2015-05-21 22:49:48', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1586225/php0iVrYT', 'true', 64, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 21:02:59'),
(65, 64, NULL, 'cardiotocography', '1', NULL, '**Author**: J. P. Marques de Sá, J. Bernardes, D. Ayers de Campos.  \n**Source**: UCI  \n**Please cite**:     \n\n* Source:\n\nMarques de Sá, J.P., jpmdesa \'@\' gmail.com, Biomedical Engineering Institute, Porto, Portugal. \nBernardes, J., joaobern \'@\' med.up.pt, Faculty of Medicine, University of Porto, Portugal. \nAyres de Campos, D., sisporto \'@\' med.up.pt, Faculty of Medicine, University of Porto, Portugal.\n\n\n* Data Set Information:\n\n2126 fetal cardiotocograms (CTGs) were automatically processed and the respective diagnostic features measured. The CTGs were also classified by three expert obstetricians and a consensus classification label assigned to each of them. Classification was both with respect to a morphologic pattern (A, B, C. ...) and to a fetal state (N, S, P). Therefore the dataset can be used either for 10-class or 3-class experiments.\n\n\n* Attribute Information:\n\nLB - FHR baseline (beats per minute) \nAC - # of accelerations per second \nFM - # of fetal movements per second \nUC - # of uterine contractions per second \nDL - # of light decelerations per second \nDS - # of severe decelerations per second \nDP - # of prolongued decelerations per second \nASTV - percentage of time with abnormal short term variability \nMSTV - mean value of short term variability \nALTV - percentage of time with abnormal long term variability \nMLTV - mean value of long term variability \nWidth - width of FHR histogram \nMin - minimum of FHR histogram \nMax - Maximum of FHR histogram \nNmax - # of histogram peaks \nNzeros - # of histogram zeros \nMode - histogram mode \nMean - histogram mean \nMedian - histogram median \nVariance - histogram variance \nTendency - histogram tendency \nCLASS - FHR pattern class code (1 to 10) \nNSP - fetal state class code (N=normal; S=suspect; P=pathologic)\n\n\n* Relevant Papers:\n\nAyres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5:311-318 ', 'ARFF', NULL, NULL, NULL, '2015-05-21 23:05:18', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1586231/php9HX2u8', 'true', 65, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:49:14'),
(66, 64, NULL, 'climate-model-simulation-crashes', '1', NULL, '**Author**:   \n**Source**: UCI\n\n**Please cite**:   \n\nSource:\n\nD. Lucas (ddlucas .at. alum.mit.edu), Lawrence Livermore National Laboratory; R. Klein (rklein .at. astron.berkeley.edu), Lawrence Livermore National Laboratory & U.C. Berkeley; J. Tannahill (tannahill1 .at. llnl.gov), Lawrence Livermore National Laboratory; D. Ivanova (ivanova2 .at. llnl.gov), Lawrence Livermore National Laboratory; S. Brandon (brandon1 .at. llnl.gov), Lawrence Livermore National Laboratory; D. Domyancic (domyancic1 .at. llnl.gov), Lawrence Livermore National Laboratory; Y. Zhang (zhang24 .at. llnl.gov), Lawrence Livermore National Laboratory .\n\nThis data was constructed using LLNL\'s UQ Pipeline, was created under the auspices of the US Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344, was funded by LLNL\'s Uncertainty Quantification Strategic Initiative Laboratory Directed Research and Development Project under tracking code 10-SI-013, and is released under UCRL number LLNL-MISC-633994.\n\n\nData Set Information:\n\nThis dataset contains records of simulation crashes encountered during climate model uncertainty quantification (UQ) ensembles. Ensemble members were constructed using a Latin hypercube method in LLNL\'s UQ Pipeline software system to sample the uncertainties of 18 model parameters within the Parallel Ocean Program (POP2) component of the Community Climate System Model (CCSM4). Three separate Latin hypercube ensembles were conducted, each containing 180 ensemble members. 46 out of the 540 simulations failed for numerical reasons at combinations of parameter values. The goal is to use classification to predict simulation outcomes (fail or succeed) from input parameter values, and to use sensitivity analysis and feature selection to determine the causes of simulation crashes. Further details about the data and methods are given in the publication \'Failure Analysis of Parameter-Induced Simulation Crashes in Climate Models,\' Geoscientific Model Development ([Web Link]).\n\n\nAttribute Information:\n\nThe goal is to predict climate model simulation outcomes (column 21, fail or succeed) given scaled values of climate model input parameters (columns 3-20). \n\nColumn 1: Latin hypercube study ID (study 1 to study 3) \nColumn 2: simulation ID (run 1 to run 180) \nColumns 3-20: values of 18 climate model parameters scaled in the interval [0, 1] \nColumn 21: simulation outcome (0 = failure, 1 = success)\n\nRelevant Papers:\n\nLucas, D. D., Klein, R., Tannahill, J., Ivanova, D., Brandon, S., Domyancic, D., and Zhang, Y.: Failure analysis of parameter-induced simulation crashes in climate models, Geosci. Model Dev. Discuss., 6, 585-623, [Web Link], 2013.', 'ARFF', NULL, NULL, NULL, '2015-05-21 23:11:45', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1586232/phpXeun7q', 'true', 66, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:49:00'),
(67, 64, NULL, 'cnae-9', '1', NULL, '**Author**: Patrick Marques Ciarelli, Elias Oliviera   \n**Source**: UCI\n\n**Please cite**:   \n\nSource:\n\nPatrick Marques Ciarelli, pciarelli \'@\' lcad.inf.ufes.br, Department of Electrical Engineering, Federal University of Espirito Santo \nElias Oliveira, elias \'@\' lcad.inf.ufes.br, Department of Information Science, Federal University of Espirito Santo\n\n\nData Set Information:\n\nThis is a data set containing 1080 documents of free text business descriptions of Brazilian companies categorized into a \nsubset of 9 categories cataloged in a table called National Classification of Economic Activities (Classificação Nacional de \nAtividade Econômicas - CNAE). The original texts were pre-processed to obtain the current data set: initially, it was kept only \nletters and then it was removed prepositions of the texts. Next, the words were transformed to their canonical form. Finally, \neach document was represented as a vector, where the weight of each word is its frequency in the document. This data set is \nhighly sparse (99.22% of the matrix is filled with zeros).\n\n\nAttribute Information:\n\nIn the data set there are 857 attributes, 1 attributes with the class of instance and 856 with word frequency: \n1. category: range 1 - 9 (integer) \n2 - 857. word frequency: (integer)\n\n\nRelevant Papers:\n\nPatrick Marques Ciarelli, Elias Oliveira, \'Agglomeration and Elimination of Terms for Dimensionality Reduction\', \nNinth International Conference on Intelligent Systems Design and Applications, pp.547-552, 2009 \n\nPatrick Marques Ciarelli, Elias Oliveira, Evandro O. T. Salles, \'An Evolving System Based on Probabilistic Neural Network\', \nBrazilian Symposium on Artificial Neural Network, 2010', 'ARFF', NULL, NULL, NULL, '2015-05-21 23:19:32', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1586233/phpmcGu2X', 'true', 67, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-05-21 23:19:32'),
(68, 64, NULL, 'eeg-eye-state', '1', NULL, '**Author**: Oliver Roesler, it12148\'@\'lehre.dhbw-stuttgart.de  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/EEG+Eye+State), Baden-Wuerttemberg, Cooperative State University (DHBW), Stuttgart, Germany  \n**Please cite**:   \n\nAll data is from one continuous EEG measurement with the Emotiv EEG Neuroheadset. The duration of the measurement was 117 seconds. The eye state was detected via a camera during the EEG measurement and added later manually to the file after analysing the video frames. \'1\' indicates the eye-closed and \'0\' the eye-open state. All values are in chronological order with the first measured value at the top of the data.\n', 'ARFF', NULL, NULL, NULL, '2015-05-22 16:40:04', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1587924/phplE7q6h', 'true', 68, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:42:10'),
(69, 64, NULL, 'first-order-theorem-proving', '1', NULL, '**Author**: James P Bridge, Sean B Holden and Lawrence C Paulson \n  \n**Source**: UCI  \n\n**Please cite**: James P Bridge, Sean B Holden and Lawrence C Paulson . Machine learning for first-order theorem proving: learning to select a good heuristic. Journal of Automated Reasoning, Springer 2012/13. \n\nSource:\n\nJames P Bridge, Sean B Holden and Lawrence C Paulson \n\nUniversity of Cambridge \nComputer Laboratory \nWilliam Gates Building \n15 JJ Thomson Avenue \nCambridge CB3 0FD \nUK \n\n+44 (0)1223 763500 \nforename.surname \'@\' cl.cam.ac.uk\n\n\nData Set Information:\n\nSee the file dataset file.\n\n\nAttribute Information:\n\nThe attributes are a mixture of static and dynamic features derived from theorems to be proved. See the paper for full details.\n', 'ARFF', NULL, NULL, NULL, '2015-05-22 17:30:40', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1587932/phpPbCMyg', 'true', 69, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:36:55'),
(70, 64, NULL, 'gas-drift', '1', NULL, '**Author**: Alexander Vergara\n\n**Source**: UCI  \n\n**Please cite**: Alexander Vergara and Shankar Vembu and Tuba Ayhan and Margaret A. Ryan and Margie L. Homer and Ramón Huerta, Chemical gas sensor drift compensation using classifier ensembles, Sensors and Actuators B: Chemical (2012) doi: 10.1016/j.snb.2012.01.074. \n\nTitle: Gas Sensor Array Drift Dataset Data Set\n\nSource:\n\nCreators: Alexander Vergara (vergara \'@\' ucsd.edu) \nBioCircutis Institute \nUniversity of California San Diego \nSan Diego, California, USA \nDonors of the Dataset: Alexander Vergara (vergara \'@\' ucsd.edu) \nRamon Huerta (rhuerta \'@\' ucsd.edu) \n\n\nData Set Information:\n\nThis archive contains 13910 measurements from 16 chemical sensors utilized in simulations for drift compensation in a discrimination task of 6 gases at various levels of concentrations. The goal is to achieve good performance (or as low degradation as possible) over time, as reported in the paper mentioned below in Section 2: Data collection. The primary purpose of providing this dataset is to make it freely accessible on-line to the chemo-sensor research community and artificial intelligence to develop strategies to cope with sensor/concept drift. The dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.\nThe dataset was gathered within January 2007 to February 2011 (36 months) in a gas delivery platform facility situated at the ChemoSignals Laboratory in the BioCircuits Institute, University of California San Diego. Being completely operated by a fully computerized environment â€”controlled by a LabVIEWâ€“National Instruments software on a PC fitted with the appropriate serial data acquisition boards. The measurement system platform provides versatility for obtaining the desired concentrations of the chemical substances of interest with high accuracy and in a highly reproducible manner, minimizing thereby the common mistakes caused by human intervention and making it possible to exclusively concentrate on the chemical sensors for compensating real drift.\nThe resulting dataset comprises recordings from six distinct pure gaseous substances, namely Ammonia, Acetaldehyde, Acetone, Ethylene, Ethanol, and Toluene, each dosed at a wide variety of concentration values ranging from 5 to 1000 ppmv. See Tables 1 and 2 of the below cited manuscript for details on the gas identity name, concentration values, and time distribution sequence of the measurement recordings considered in this dataset.\n\nBatch10.dat was updated on 10/14/2013 to correct some corrupted values in the last 120 lines of the file.\n\nAn extension of this dataset with the concentration values is available at Gas Sensor Array Drift Dataset at Different Concentrations Data Set [Web Link]\n\n\nAttribute Information:\n\nThe response of the said sensors is read-out in the form of the resistance across the active layer of each sensor; hence each measurement produced a 16-channel time series, each of which represented by an aggregate of features reflecting all the dynamic processes occurring at the sensor surface in reaction to the chemical substance being evaluated. In particular, two distinct types of features were considered in the creation of this dataset: (i) The so-called steady-state feature (Î”R), defined as the difference of the maximal resistance change and the baseline and its normalized version expressed by the ratio of the maximal resistance and the baseline values when the chemical vapor is present in the test chamber. And (ii), an aggregate of features reflecting the sensor dynamics of the increasing/decaying transient portion of the sensor response during the entire measurement procedure under controlled conditions, namely the exponential moving average (emaÎ±). These aggregate of features is a transform, borrowed from the field of econometrics originally introduced to the chemo-sensing community by Muezzinoglu et al. (2009), that converts the said transient portion into a real scalar, by estimating the maximum value â€”minimum for the decaying portion of the sensor responseâ€” of its exponential moving average (emaÎ±), with an initial condition set to zero and a scalar smoothing parameter of the operator, Î±, that defines both the quality of the feature and the time of its occurrence along the time series the scalar, set to range between 0 and 1. In particular, three different values for Î± were set to obtain three different feature values from the pre-recorded rising portion of the sensor response and three additional features with the same Î± values but for the decaying portion of the sensor response, covering thus the entire sensor response dynamics. For a more detailed analysis and discussion on these features as well as a graphical illustration of them please refer to Section 2.3 and Figure 2, respectively of the annotated manuscript.\nOnce the abovementioned features are calculated, one is to form a feature vector containing the 8 features extracted from each particular sensor multiplied by the 16 sensors considered here. In the end, the resulting 128-dimensional feature vector containing all the features indicated above (8 features Ã— 16 sensors) is organized as follows:\nÎ”R_1, |Î”R|_1, EMAi0.001_1, EMAi0.01_1, EMAi0.1_1, EMAd0.001_1, EMAd0.01_1, EMAd0.1_1, Î”R_2, |Î”R|_2, EMAi0.001_2, EMAi0.01_2, EMAi0.1_2, EMAd0.001_2, EMAd0.01_2, EMAd0.1_2,..., Î”R_16, |Î”R|_16, EMAi0.001_16, EMAi0.01_16, EMAi0.1_16, EMAd0.001_16, EMAd0.01_16, EMAd0.1_16,\n\nwhere: â€œÎ”R_1â€ and â€œ|Î”R|_1â€ is the Î”R and the normalized Î”R feature, respectively, â€œEMAi0.001_1â€, â€œEMAi0.01_1â€, and â€œEMAi0.1_1â€, the emaÎ± of the rising transient portion of the sensor response for Î± equals to 0.001, 0.01, and 0.1, respectively, and â€œEMAd0.001_1â€, â€œEMAd0.01_1â€, and â€œEMAd0.1_1â€, the emaÎ± of the decaying transient portion of the sensor response for Î± equals to 0.001, 0.01, and 0.1, respectively, all corresponding to sensor # 1; â€œÎ”R_2â€ and â€œ|Î”R|_2â€ is the Î”R and the normalized Î”R feature, respectively, â€œEMAi0.001_2â€, â€œEMAi0.01_2â€, and â€œEMAi0.1_2â€, the emaÎ± of the rising transient portion of the sensor response for Î± equals to 0.001, 0.01, and 0.1, respectively, and â€œEMAd0.001_2â€, â€œEMAd0.01_2â€, and â€œEMAd0.1_2â€, the emaÎ± of the decaying transient portion of the sensor response for Î± equals to 0.001, 0.01, and 0.1, respectively, all corresponding to sensor # 2; and so forth up until sensor # 16, forming thus the 128-dimensional feature vector that is to be fetched to the classifiers for training.\nFor processing purposes, the data is organized into ten batches, each containing the number of measurements per class and month indicated in the table below. This reorganization of data was done to ensure having a sufficient and as uniformly distributed as possible number of experiments in each class and month when training the classifier.\n\nDataset organization details. Each row corresponds to months that were combined to form a batch:\nBatch ID Month IDs\nBatch 1 Months 1 and 2\nBatch 2 Months 3, 4, 8, 9 and 10\nBatch 3 Months 11, 12, and 13\nBatch 4 Months 14 and 15\nBatch 5 Month 16\nBatch 6 Months 17, 18, 19, and 20\nBatch 7 Month 21\nBatch 8 Months 22 and 23\nBatch 9 Months 24 and 30\nBatch 10 Month 36\n\nThe data format follows the same coding style as in libsvm, in which one indicates the class each data point belongs to (1: Ethanol; 2: Ethylene; 3:Ammonia; 4: Acetaldehyde; 5: Acetone; 6: Toluene), and, then, the collection of features in a format x:v, where x stands for the feature number and v for the actual value of the feature. For example, in \n\n1 1:15596.162100 2:1.868245 3:2.371604 4:2.803678 5:7.512213 â€¦ 128:-2.654529 \n\nThe number â€œ1â€ stands for the class number (in this case Ethanol), whereas the remaining 128 columns list the actual feature values for each measurement recording organized as described above. \nFinally, to make the results presented in the associated article reproducible for the reader, please use the following parameter values in the training task:\nâ€¢ folds: 10\nâ€¢ log2c = -5, 10, 1\nâ€¢ log2g = -10, 5, 1\nâ€¢ Scale the features in the training set appropriately to lie between -1 and +1.\nâ€¢ And use the following cross validation parameters:\n\nBatch C Gamma (É¤) Rate\n1 256.0 0.03125 98.8764\n2 64.0 0.00390625 99.7588\n3 128.0 0.03125 100.0\n4 1.0 0.25 100.0\n5 2.0 0.015625 99.4924\n6 256.0 0.0009765625 99.5217\n7 64.0 0.0625 99.9723\n8 1024.0 0.0078125 99.6599\n9 2.0 0.00390625 100.0', 'ARFF', NULL, NULL, NULL, '2015-05-22 20:11:33', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1588715/phpbL6t4U', 'true', 70, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-05-22 20:11:33'),
(71, 64, NULL, 'har', '1', NULL, '**Author**: Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto and Xavier Parra\n\n**Source**: UCI\n\n**Please cite**: Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.   \n\nTitle: Human Activity Recognition Using Smartphones\n\nAbstract: Human Activity Recognition database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors.\n\nSource:\n\nJorge L. Reyes-Ortiz(1,2), Davide Anguita(1), Alessandro Ghio(1), Luca Oneto(1) and Xavier Parra(2)\n1 - Smartlab - Non-Linear Complex Systems Laboratory DITEN - Università degli Studi di Genova, Genoa (I-16145), Italy. \n2 - CETpD - Technical Research Centre for Dependency Care and Autonomous Living Universitat Politècnica de Catalunya (BarcelonaTech). Vilanova i la Geltrú (08800), Spain, activityrecognition \'@\' smartlab.ws\n\n\nData Set Information:\n\nThe experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. \n\nThe sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.\n\nCheck the README.txt file for further details about this dataset. \n\nA video of the experiment including an example of the 6 recorded activities with one of the participants can be seen in the following link: [Web Link]\n\n\nAttribute Information:\n\nFor each record in the dataset it is provided: \n- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration. \n- Triaxial Angular velocity from the gyroscope. \n- A 561-feature vector with time and frequency domain variables. \n- Its activity label. \n- An identifier of the subject who carried out the experiment.\n\n\nRelevant Papers:\n\nDavide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012 \n\nDavide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, Jorge L. Reyes-Ortiz. Energy Efficient Smartphone-Based Activity Recognition using Fixed-Point Arithmetic. Journal of Universal Computer Science. Special Issue in Ambient Assisted Living: Home Care. Volume 19, Issue 9. May 2013\n\nDavide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. 4th International Workshop of Ambient Assited Living, IWAAL 2012, Vitoria-Gasteiz, Spain, December 3-5, 2012. Proceedings. Lecture Notes in Computer Science 2012, pp 216-223. \n\nJorge Luis Reyes-Ortiz, Alessandro Ghio, Xavier Parra-Llanas, Davide Anguita, Joan Cabestany, Andreu Català. Human Activity and Motion Disorder Recognition: Towards Smarter Interactive Cognitive Environments. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.\n\n', 'ARFF', NULL, NULL, NULL, '2015-05-22 20:38:11', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1589271/php88ZB4Q', 'true', 71, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-05-22 20:38:11'),
(72, 64, NULL, 'hill-valley', '1', NULL, '**Author**: Lee Graham, Franz Oppacher\n**Source**: UCI\n\n**Please cite**:   \n\n1. Source:\n\nLee Graham (lee \'@\' stellaralchemy.com) \n\nFranz Oppacher (oppacher \'@\' scs.carleton.ca) \nCarleton University, Department of Computer Science \nIntelligent Systems Research Unit \n1125 Colonel By Drive, Ottawa, Ontario, Canada, K1S5B6 \n\n\n2. Attribute Information:\n\n1-100: Labeled “X##”. Floating point values (numeric) \n101: Labeled “class”. Binary {0, 1} representing {valley, hill} ', 'ARFF', NULL, NULL, NULL, '2015-05-22 21:11:58', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1590101/php3isjYz', 'true', 72, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-05-22 21:11:58'),
(73, 64, NULL, 'ilpd', '1', NULL, '**Author**: Bendi Venkata Ramana, M. Surendra Prasad Babu, N. B. Venkateswarlu \n  \n**Source**: UCI  \n\n**Please cite**:   \n\nSource:\n\n1. Bendi Venkata Ramana,  \nramana.bendi \'@\' gmail.com \nAssociate Professor, \nDepartment of Information Technology, \nAditya Instutute of Technology and Management, \nTekkali - 532201, Andhra Pradesh, India. \n\n2. Prof. M. Surendra Prasad Babu \ndrmsprasadbabu \'@\' yahoo.co.in \nDeptartment of Computer Science & Systems Engineering, \nAndhra University College of Engineering, \nVisakhapatnam-530 003 Andhra Pradesh, India. \n\n3.Prof. N. B. Venkateswarlu \nvenkat_ritch \'@\' yahoo.com \nDepartment of Computer Science and Engineering, \nAditya Instutute of Technology and Management, \nTekkali - 532201, Andhra Pradesh, India.\n\n\nData Set Information:\n\nThis data set contains 416 liver patient records and 167 non liver patient records.The data set was collected from north east of Andhra Pradesh, India. Selector is a class label used to divide into groups(liver patient or not). This data set contains 441 male patient records and 142 female patient records. \n\nAny patient whose age exceeded 89 is listed as being of age \"90\".\n\nAttribute Information:\n\n1. Age Age of the patient \n2. Gender Gender of the patient \n3. TB Total Bilirubin \n4. DB Direct Bilirubin \n5. Alkphos Alkaline Phosphotase \n6. Sgpt Alamine Aminotransferase \n7. Sgot Aspartate Aminotransferase \n8. TP Total Protiens \n9. ALB Albumin \n10. A/G Ratio Albumin and Globulin Ratio \n11. Selector field used to split the data into two sets (labeled by the experts) \n\n\nRelevant Papers:\n\n1. Bendi Venkata Ramana, Prof. M. S. Prasad Babu and Prof. N. B. Venkateswarlu, â€œA Critical Comparative Study of Liver Patients from USA and INDIA: An Exploratory Analysisâ€, International Journal of Computer Science Issues, ISSN :1694-0784, May 2012. \n2. Bendi Venkata Ramana, Prof. M. S. Prasad Babu and Prof. N. B. Venkateswarlu, â€œA Critical Study of Selected Classification Algorithms for Liver Disease Diagnosisâ€, International Journal of Database Management Systems (IJDMS), Vol.3, No.2, ISSN : 0975-5705, PP 101-114, May 2011.', 'ARFF', NULL, NULL, NULL, '2015-05-22 22:40:56', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1590565/phpOJxGL9', 'true', 73, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:32:35'),
(74, 64, NULL, 'madelon', '1', NULL, '**Author**: Isabelle Guyon  \n**Source**: UCI  \n**Please cite**: Isabelle Guyon, Steve R. Gunn, Asa Ben-Hur, Gideon Dror, 2004. Result analysis of the NIPS 2003 feature selection challenge.\n\nAbstract: \n\nMADELON is an artificial dataset, which was part of the NIPS 2003 feature selection challenge. This is a two-class classification problem with continuous input variables. The difficulty is that the problem is multivariate and highly non-linear.\n\nSource:\n\nIsabelle Guyon \nClopinet \n955 Creston Road \nBerkeley, CA 90708 \nisabelle \'@\' clopinet.com \n\n\nData Set Information:\n\nMADELON is an artificial dataset containing data points grouped in 32 clusters placed on the vertices of a five dimensional hypercube and randomly labeled +1 or -1. The five dimensions constitute 5 informative features. 15 linear combinations of those features were added to form a set of 20 (redundant) informative features. Based on those 20 features one must separate the examples into the 2 classes (corresponding to the +-1 labels). We added a number of distractor feature called \'probes\' having no predictive power. The order of the features and patterns were randomized. \n\nThis dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website is still open for post-challenge submissions.  All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003. Such information was made available only after the end of the challenge. \n\nThe data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link]. \n\nThe data are in the following format: \ndataname.param: Parameters and statistics about the data \ndataname.feat: Identities of the features (in the order the features are found in the data). \ndataname_train.data: Training set (a space-delimited regular matrix, patterns in lines, features in columns). \ndataname_valid.data: Validation set. \ndataname_test.data: Test set. \ndataname_train.labels: Labels (truth values of the classes) for training examples. \ndataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now). \ndataname_test.labels: Test set labels (withheld, so the data can still be use as a benchmark). \n\n\nAttribute Information:\nWe do not provide attribute information, to avoid biasing the feature selection process.\n\n\nRelevant Papers:\n\nThe best challenge entrants wrote papers collected in the book: \nIsabelle Guyon, Steve Gunn, Masoud Nikravesh, Lofti Zadeh (Eds.), Feature Extraction, Foundations and Applications. Studies in Fuzziness and Soft Computing. Physica-Verlag, Springer.\n\nSee also: \nIsabelle Guyon, et al, 2007. Competitive baseline methods set new standards for the NIPS 2003 feature selection benchmark. Pattern Recognition Letters 28 (2007) 1438–1444. \n\nand the associated technical report: \nIsabelle Guyon, et al. 2006. Feature selection with the CLOP package. Technical Report.\n', 'ARFF', NULL, NULL, NULL, '2015-05-22 23:46:18', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1590986/phpfLuQE4', 'true', 74, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-05-22 23:46:18'),
(75, 64, NULL, 'nomao', '1', NULL, '**Author**:   \n**Source**: UCI\n**Please cite**:   \n\nRelevant Papers: Laurent Candillier and Vincent Lemaire. Design and Analysis of the Nomao Challenge - Active Learning in the Real-World. In: Proceedings of the ALRA : Active Learning in Real-world Applications, Workshop ECML-PKDD 2012, Friday, September 28, 2012, Bristol, UK.\n\n1. Data set title:\nNomao Data Set \n\n\n2. Abstract: \nNomao collects data about places (name, phone, localization...) from many sources. Deduplication consists in detecting what data refer to the same place. Instances in the dataset compare 2 spots.\n\n3. Data Set Characteristics:  \n\n- Univariate\n- Area: Computer\n- Attribute Characteristics: Real\n- Associated Tasks: Classification\n- Missing Values?: Yes\n\n\n4. Source:\n\n(a) Original owner of database (name / phone / snail address / email address) \nNomao / 00 33 5 62 48 33 90 / 1 avenue Jean Rieux, 31500 Toulouse / challenge \'@\' nomao.com \n(b) Donor of database (name / phone / snail address / email address) \nLaurent Candillier / - / 1 avenue Jean Rieux, 31500 Toulouse / laurent \'@\' nomao.com\n\n\n5. Data Set Information:\n\nThe dataset has been enriched during the Nomao Challenge: organized along with the ALRA workshop (Active Learning in Real-world Applications): held at the ECML-PKDD 2012 conference.', 'ARFF', NULL, NULL, NULL, '2015-05-25 19:09:04', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1592278/phpDYCOet', 'true', 75, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-05-25 19:09:04'),
(76, 64, NULL, 'ozone-level-8hr', '1', NULL, '**Author**: Kun Zhang, Wei Fan, XiaoJing Yuan\n\n**Source**: UCI\n\n**Please cite**:   \n\n\n1 . Abstract: \nTwo ground ozone level data sets are included in this collection. One is the eight hour peak set (eighthr.data), the other is the one hour peak set (onehr.data). Those data were collected from 1998 to 2004 at the Houston, Galveston and Brazoria area.\n\n2. Source:\n\nKun Zhang, zhang.kun05 \'@\' gmail.com, Department of Computer Science, Xavier University of Lousiana \nWei Fan, wei.fan \'@\' gmail.com, IBM T.J.Watson Research \nXiaoJing Yuan, xyuan \'@\' uh.edu, Engineering Technology Department, College of Technology, University of Houston \n\n\n3. Data Set Information:\n\nAll the attribute start with T means the temperature measured at different time throughout the day; and those starts with WS indicate the wind speed at various time. \n\nWSR_PK: continuous. peek wind speed -- resultant (meaning average of wind vector) \nWSR_AV: continuous. average wind speed \nT_PK: continuous. Peak T \nT_AV: continuous. Average T \nT85: continuous. T at 850 hpa level (or about 1500 m height) \nRH85: continuous. Relative Humidity at 850 hpa \nU85: continuous. (U wind - east-west direction wind at 850 hpa) \nV85: continuous. V wind - N-S direction wind at 850 \nHT85: continuous. Geopotential height at 850 hpa, it is about the same as height at low altitude \nT70: continuous. T at 700 hpa level (roughly 3100 m height) \n\nRH70: continuous. \nU70: continuous. \nV70: continuous. \nHT70: continuous. \n\nT50: continuous. T at 500 hpa level (roughly at 5500 m height) \n\nRH50: continuous. \nU50: continuous. \nV50: continuous. \nHT50: continuous. \n\nKI: continuous. K-Index [Web Link] \nTT: continuous. T-Totals [Web Link] \nSLP: continuous. Sea level pressure \nSLP_: continuous. SLP change from previous day \n\nPrecp: continuous. -- precipitation\n\n\n4. Attribute Information:\n\nThe following are specifications for several most important attributes that are highly valued by Texas Commission on Environmental Quality (TCEQ). More details can be found in the two relevant papers. \n\nO 3 - Local ozone peak prediction \nUpwind - Upwind ozone background level \nEmFactor - Precursor emissions related factor \nTmax - Maximum temperature in degrees F \nTb - Base temperature where net ozone production begins (50 F) \nSRd - Solar radiation total for the day \nWSa - Wind speed near sunrise (using 09-12 UTC forecast mode) \nWSp - Wind speed mid-day (using 15-21 UTC forecast mode) \n\n\n5. Relevant Papers:\n\nForecasting skewed biased stochastic ozone days: analyses, solutions and beyond, Knowledge and Information Systems, Vol. 14, No. 3, 2008. \n\nIt Discusses details about the dataset, its use as well as various experiments (both cross-validation and streaming) using many state-of-the-art methods. \nA shorter version of the paper (does not contain some detailed experiments as the journal paper above) is in: \nForecasting Skewed Biased Stochastic Ozone Days: Analyses and Solutions. ICDM 2006: 753-764 \n\n', 'ARFF', NULL, NULL, NULL, '2015-05-25 19:22:29', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1592279/phpdReP6S', 'true', 76, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:25:43'),
(77, 64, NULL, 'phoneme', '1', NULL, '**Author**:   \n**Source**: KEEL\n**Please cite**:   \n\n* Title:\n\nPhoneme dataset\n\n* Abstract:\n\nThe aim of this dataset is to distinguish between nasal (class 0) and oral sounds (class 1). The class distribution is 3,818 samples in class 0 and 1,586 samples in class 1. The phonemes are transcribed as follows: sh as in she, dcl as in dark, iy as the vowel in she, aa as the vowel in dark, and ao as the first vowel in water.\n\n* Attributes information:\n\n@relation phoneme\n@attribute Aa real [-1.7, 4.107]\n@attribute Ao real [-1.327, 4.378]\n@attribute Dcl real [-1.823, 3.199]\n@attribute Iy real [-1.581, 2.826]\n@attribute Sh real [-1.284, 2.719]\n@attribute Class {0, 1}\n@inputs Aa, Ao, Dcl, Iy, Sh\n@outputs Class', 'ARFF', NULL, NULL, NULL, '2015-05-25 19:34:17', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1592281/php8Mz7BG', 'true', 77, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:25:20'),
(78, 64, NULL, 'one-hundred-plants-margin', '1', NULL, '**Author**: James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.  \n\n**Source**: UCI \n\n**Please cite**: Charles Mallah, James Cope, James Orwell. Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. Signal Processing, Pattern Recognition and Applications, in press. 2013.   \n\n1. One-hundred plant species leaves data set (class = margin).\n \n2. Sources:\n   (a) Original owners of colour Leaves Samples:\n\n James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.\n The colour images are not included in this submission.\n The Leaves were collected in the Royal Botanic Gardens, Kew, UK.\n email: james.cope@kingston.ac.uk\n   \n   (b) This dataset consists of work carried out by James Cope, Charles Mallah, and James Orwell.\n Donor of database Charles Mallah: charles.mallah@kingston.ac.uk; James Cope:  james.cope@kingston.ac.uk\n\n   (c) Date received 03/12/2012\n\n3. Past Usage:\n\n   (a) This is a new data set, provisional paper: \n\n Charles Mallah, James Cope, James Orwell. Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. Signal Processing, Pattern Recognition and Applications, in press.\n\n   (b) Previous parts of the data set relate to feature extraction of leaves from: \n\n J. Cope, P. Remagnino, S. Barman, and P. Wilkin.\n Plant texture classification using gabor cooccurrences.\n Advances in Visual Computing,\n pages 669ñ677, 2010.\n\n T. Beghin, J. Cope, P. Remagnino, and S. Barman.\n Shape and texture based plant leaf classification. In\n Advanced Concepts for Intelligent Vision Systems,\n pages 345ñ353. Springer, 2010.\n\n4. Relevant Information Paragraph:\n The data directory contains the binary images (masks) of the leaf samples. The colour images are not included.\n The data set features are organised as the following:\n * \'data_Sha_64.txt\'\n  * \'data_Tex_64.txt\'\n * [THIS DATASET]\'data_Mar_64.txt\'\n\n One file for each 64-element feature vectors. Each row begins with the class label.\n The remaining 64 elements is the feature vector.\n\n5. Number of Instances\n\n 1600 samples each of three features (16 samples per leaf class).\n\n6. Number of Attributes\n\n    Three 64 element feature vectors per sample.\n\n7. Vectors\n There are three features: Shape, Margin and Texture. As discussed in the paper(s) above.\n For Each feature, a 64 element vector is given per sample of leaf.\n These vectors are taken as a contigous descriptors (for shape) or histograms (for texture and margin).\n\n8. Missing Attribute Values: none\n\n9. Class Distribution: 16 instances per class', 'ARFF', NULL, NULL, NULL, '2015-05-25 20:51:03', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1592283/phpCsX3fx', 'true', 78, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:21:22'),
(79, 64, NULL, 'one-hundred-plants-shape', '1', NULL, '**Author**: James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.  \n\n**Source**: UCI \n\n**Please cite**: Charles Mallah, James Cope, James Orwell. Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. Signal Processing, Pattern Recognition and Applications, in press. 2013.   \n\n1. One-hundred plant species leaves data set (class = shape).\n \n2. Sources:\n   (a) Original owners of colour Leaves Samples:\n\n James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.\n The colour images are not included in this submission.\n The Leaves were collected in the Royal Botanic Gardens, Kew, UK.\n email: james.cope@kingston.ac.uk\n   \n   (b) This dataset consists of work carried out by James Cope, Charles Mallah, and James Orwell.\n Donor of database Charles Mallah: charles.mallah@kingston.ac.uk; James Cope:  james.cope@kingston.ac.uk\n\n   (c) Date received 03/12/2012\n\n3. Past Usage:\n\n   (a) This is a new data set, provisional paper: \n\n Charles Mallah, James Cope, James Orwell. Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. Signal Processing, Pattern Recognition and Applications, in press.\n\n   (b) Previous parts of the data set relate to feature extraction of leaves from: \n\n J. Cope, P. Remagnino, S. Barman, and P. Wilkin.\n Plant texture classification using gabor cooccurrences.\n Advances in Visual Computing,\n pages 669ñ677, 2010.\n\n T. Beghin, J. Cope, P. Remagnino, and S. Barman.\n Shape and texture based plant leaf classification. In\n Advanced Concepts for Intelligent Vision Systems,\n pages 345ñ353. Springer, 2010.\n\n4. Relevant Information Paragraph:\n The data directory contains the binary images (masks) of the leaf samples. The colour images are not included.\n The data set features are organised as the following:\n * [THIS DATASET]\'data_Sha_64.txt\'\n  * \'data_Tex_64.txt\'\n * \'data_Mar_64.txt\'\n\n One file for each 64-element feature vectors. Each row begins with the class label.\n The remaining 64 elements is the feature vector.\n\n5. Number of Instances\n\n 1600 samples each of three features (16 samples per leaf class).\n\n6. Number of Attributes\n\n    Three 64 element feature vectors per sample.\n\n7. Vectors\n There are three features: Shape, Margin and Texture. As discussed in the paper(s) above.\n For Each feature, a 64 element vector is given per sample of leaf.\n These vectors are taken as a contigous descriptors (for shape) or histograms (for texture and margin).\n\n8. Missing Attribute Values: none\n\n9. Class Distribution: 16 instances per class', 'ARFF', NULL, NULL, NULL, '2015-05-25 20:58:37', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1592284/php0FyS2T', 'true', 79, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:21:11'),
(80, 64, NULL, 'one-hundred-plants-texture', '1', NULL, '**Author**: James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.  \r\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/One-hundred+plant+species+leaves+data+set) - 2012  \r\n**Please cite**: Charles Mallah, James Cope, James Orwell. Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. Signal Processing, Pattern Recognition and Applications, in press. 2013.   \r\n\r\n**One-hundred plant species leaves data set (class = texture)**  \r\nThe data directory contains the binary images (masks) of the leaf samples. The colour images are not included. There are three features: Shape, Margin and Texture. As discussed in the paper(s) above. For Each feature, a 64 element vector is given per sample of leaf. These vectors are taken as a contigous descriptors (for shape) or histograms (for texture and margin). The colour images are not included in this submission. The Leaves were collected in the Royal Botanic Gardens, Kew, UK. email: james.cope@kingston.ac.uk\r\n\r\n**Sources**  \r\n   (a) Original owners of colour Leaves Samples:\r\n James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.\r\n   (b) This dataset consists of work carried out by James Cope, Charles Mallah, and James Orwell.\r\n Donor of database Charles Mallah: charles.mallah@kingston.ac.uk; James Cope:  james.cope@kingston.ac.uk\r\n   (c) Date received 03/12/2012\r\n\r\n**Usage**\r\n   (a) This is a new data set, provisional paper: \r\n\r\n Charles Mallah, James Cope, James Orwell. Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. Signal Processing, Pattern Recognition and Applications, in press.\r\n\r\n   (b) Previous parts of the data set relate to feature extraction of leaves from: \r\n\r\n J. Cope, P. Remagnino, S. Barman, and P. Wilkin.\r\n Plant texture classification using gabor cooccurrences.\r\n Advances in Visual Computing,\r\n pages 669ñ677, 2010.\r\n\r\n T. Beghin, J. Cope, P. Remagnino, and S. Barman.\r\n Shape and texture based plant leaf classification. In\r\n Advanced Concepts for Intelligent Vision Systems,\r\n pages 345ñ353. Springer, 2010.', 'ARFF', NULL, NULL, NULL, '2015-05-25 20:59:55', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1592285/phpoOxxNn', 'true', 80, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:20:59'),
(81, 64, NULL, 'qsar-biodeg', '1', NULL, '**Author**:   \n**Source**: UCI  \n**Please cite**: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878 \n\n\nQSAR biodegradation Data Set \n\n* Abstract: \n\nData set containing values for 41 attributes (molecular descriptors) used to classify 1055 chemicals into 2 classes (ready and not ready biodegradable).\n\n\n* Source:\n\nKamel Mansouri, Tine Ringsted, Davide Ballabio (davide.ballabio \'@\' unimib.it), Roberto Todeschini, Viviana Consonni, Milano Chemometrics and QSAR Research Group (http://michem.disat.unimib.it/chm/), UniversitÃ  degli Studi Milano â€“ Bicocca, Milano (Italy)\n\n\n* Data Set Information:\n\nThe QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group (UniversitÃ  degli Studi Milano â€“ Bicocca, Milano, Italy). The research leading to these results has received funding from the European Communityâ€™s Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project. \nThe data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.\n\n\n* Attribute Information:\n\n41 molecular descriptors and 1 experimental class: \n1) SpMax_L: Leading eigenvalue from Laplace matrix \n2) J_Dz(e): Balaban-like index from Barysz matrix weighted by Sanderson electronegativity \n3) nHM: Number of heavy atoms \n4) F01[N-N]: Frequency of N-N at topological distance 1 \n5) F04[C-N]: Frequency of C-N at topological distance 4 \n6) NssssC: Number of atoms of type ssssC \n7) nCb-: Number of substituted benzene C(sp2) \n8) C%: Percentage of C atoms \n9) nCp: Number of terminal primary C(sp3) \n10) nO: Number of oxygen atoms \n11) F03[C-N]: Frequency of C-N at topological distance 3 \n12) SdssC: Sum of dssC E-states \n13) HyWi_B(m): Hyper-Wiener-like index (log function) from Burden matrix weighted by mass \n14) LOC: Lopping centric index \n15) SM6_L: Spectral moment of order 6 from Laplace matrix \n16) F03[C-O]: Frequency of C - O at topological distance 3 \n17) Me: Mean atomic Sanderson electronegativity (scaled on Carbon atom) \n18) Mi: Mean first ionization potential (scaled on Carbon atom) \n19) nN-N: Number of N hydrazines \n20) nArNO2: Number of nitro groups (aromatic) \n21) nCRX3: Number of CRX3 \n22) SpPosA_B(p): Normalized spectral positive sum from Burden matrix weighted by polarizability \n23) nCIR: Number of circuits \n24) B01[C-Br]: Presence/absence of C - Br at topological distance 1 \n25) B03[C-Cl]: Presence/absence of C - Cl at topological distance 3 \n26) N-073: Ar2NH / Ar3N / Ar2N-Al / R..N..R \n27) SpMax_A: Leading eigenvalue from adjacency matrix (Lovasz-Pelikan index) \n28) Psi_i_1d: Intrinsic state pseudoconnectivity index - type 1d \n29) B04[C-Br]: Presence/absence of C - Br at topological distance 4 \n30) SdO: Sum of dO E-states \n31) TI2_L: Second Mohar index from Laplace matrix \n32) nCrt: Number of ring tertiary C(sp3) \n33) C-026: R--CX--R \n34) F02[C-N]: Frequency of C - N at topological distance 2 \n35) nHDon: Number of donor atoms for H-bonds (N and O) \n36) SpMax_B(m): Leading eigenvalue from Burden matrix weighted by mass \n37) Psi_i_A: Intrinsic state pseudoconnectivity index - type S average \n38) nN: Number of Nitrogen atoms \n39) SM6_B(m): Spectral moment of order 6 from Burden matrix weighted by mass \n40) nArCOOR: Number of esters (aromatic) \n41) nX: Number of halogen atoms \n42) experimental class: ready biodegradable (RB) and not ready biodegradable (NRB)\n\n\n* Relevant Papers:\n\nMansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878\n', 'ARFF', NULL, NULL, NULL, '2015-05-25 21:14:53', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1592286/phpGUrE90', 'true', 81, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:20:47'),
(82, 64, NULL, 'wall-robot-navigation', '1', NULL, '**Author**: Ananda Freire, Marcus Veloso and Guilherme Barreto     \n**Source**: UCI   \n**Please cite**:   \n\n* Dataset Title: \n\nWall-Following Robot Navigation Data Data Set \n\n* Abstract:  \n\nThe data were collected as the SCITOS G5 robot navigates through the room following the wall in a clockwise direction, for 4 rounds, using 24 ultrasound sensors arranged circularly around its \'waist\'.\n\n* Source:\n\n(a) Creators: Ananda Freire, Marcus Veloso and Guilherme Barreto \nDepartment of Teleinformatics Engineering \nFederal University of CearÃ¡ \nFortaleza, CearÃ¡, Brazil \n\n(b) Donors of database: Ananda Freire (anandalf \'@\' gmail.com) \nGuilherme Barreto (guilherme \'@\' deti.ufc.br)\n\n* Data Set Information:\n\nThe provided file contain the raw values of the measurements of all 24 ultrasound sensors and the corresponding class label. Sensor readings are sampled at a rate of 9 samples per second. \n\nIt is worth mentioning that the 24 ultrasound readings and the simplified distances were collected at the same time step, so each file has the same number of rows (one for each sampling time step). \n\nThe wall-following task and data gathering were designed to test the hypothesis that this apparently simple navigation task is indeed a non-linearly separable classification task. Thus, linear classifiers, such as the Perceptron network, are not able to learn the task and command the robot around the room without collisions. Nonlinear neural classifiers, such as the MLP network, are able to learn the task and command the robot successfully without collisions. \n\nIf some kind of short-term memory mechanism is provided to the neural classifiers, their performances are improved in general. For example, if past inputs are provided together with current sensor readings, even the Perceptron becomes able to learn the task and command the robot successfully. If a recurrent neural network, such as the Elman network, is used to learn the task, the resulting dynamical classifier is able to learn the task using less hidden neurons than the MLP network. \n\n* Attribute Information:\n\nNumber of Attributes: sensor_readings_24.data: 24 numeric attributes and the class. \n\nFor Each Attribute: \n-- File sensor_readings_24.data: \n1. US1: ultrasound sensor at the front of the robot (reference angle: 180Â°) - (numeric: real)  \n2. US2: ultrasound reading (reference angle: -165Â°) - (numeric: real)   \n3. US3: ultrasound reading (reference angle: -150Â°) - (numeric: real)   \n4. US4: ultrasound reading (reference angle: -135Â°) - (numeric: real)     \n5. US5: ultrasound reading (reference angle: -120Â°) - (numeric: real)   \n6. US6: ultrasound reading (reference angle: -105Â°) - (numeric: real)   \n7. US7: ultrasound reading (reference angle: -90Â°) - (numeric: real)   \n8. US8: ultrasound reading (reference angle: -75Â°) - (numeric: real)   \n9. US9: ultrasound reading (reference angle: -60Â°) - (numeric: real)   \n10. US10: ultrasound reading (reference angle: -45Â°) - (numeric: real)   \n11. US11: ultrasound reading (reference angle: -30Â°) - (numeric: real)   \n12. US12: ultrasound reading (reference angle: -15Â°) - (numeric: real)   \n13. US13: reading of ultrasound sensor situated at the back of the robot (reference angle: 0Â°) - (numeric: real)   \n14. US14: ultrasound reading (reference angle: 15Â°) - (numeric: real)   \n15. US15: ultrasound reading (reference angle: 30Â°) - (numeric: real)   \n16. US16: ultrasound reading (reference angle: 45Â°) - (numeric: real)   \n17. US17: ultrasound reading (reference angle: 60Â°) - (numeric: real)   \n18. US18: ultrasound reading (reference angle: 75Â°) - (numeric: real)   \n19. US19: ultrasound reading (reference angle: 90Â°) - (numeric: real)   \n20. US20: ultrasound reading (reference angle: 105Â°) - (numeric: real)   \n21. US21: ultrasound reading (reference angle: 120Â°) - (numeric: real)   \n22. US22: ultrasound reading (reference angle: 135Â°) - (numeric: real)   \n23. US23: ultrasound reading (reference angle: 150Â°) - (numeric: real)   \n24. US24: ultrasound reading (reference angle: 165Â°) - (numeric: real)   \n25. Class: {Move-Forward, Slight-Right-Turn, Sharp-Right-Turn, Slight-Left-Turn}   \n\n\n* Relevant Papers:\n\nAnanda L. Freire, Guilherme A. Barreto, Marcus Veloso and Antonio T. Varela (2009), \n\'Short-Term Memory Mechanisms in Neural Network Learning of Robot Navigation \nTasks: A Case Study\'. Proceedings of the 6th Latin American Robotics Symposium (LARS\'2009), \nValparaÃ­so-Chile, pages 1-6, DOI: 10.1109/LARS.2009.5418323\n', 'ARFF', NULL, NULL, NULL, '2015-05-25 21:50:28', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1592289/phpVeNa5j', 'true', 82, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:19:18'),
(83, 64, NULL, 'semeion', '1', NULL, '**Author**: Semeion Research Center of Sciences of Communication     \n**Source**: UCI     \n**Please cite**: Semeion Research Center of Sciences of Communication, via Sersale 117, 00128 Rome, Italy \nTattile Via Gaetano Donizetti, 1-3-5,25030 Mairano (Brescia), Italy.    \n\n* Title:   \nSemeion Handwritten Digit Data Set \n\n* Abstract:   \n1593 handwritten digits from around 80 persons were scanned, stretched in a rectangular box 16x16 in a gray scale of 256 values.\n\n\n* Source:\n\nThe dataset was created by Tactile Srl, Brescia, Italy (http://www.tattile.it) and donated in 1994 to Semeion Research Center of Sciences of Communication, Rome, Italy (http://www.semeion.it), for machine learning research. \n\nFor any questions, e-mail Massimo Buscema (m.buscema \'@\' semeion.it) or Stefano Terzi (s.terzi \'@\' semeion.it)\n\n\n* Data Set Information:\n\n1593 handwritten digits from around 80 persons were scanned, stretched in a rectangular box 16x16 in a gray scale of 256 values.Then each pixel of each image was scaled into a bolean (1/0) value using a fixed threshold. \n\nEach person wrote on a paper all the digits from 0 to 9, twice. The commitment was to write the digit the first time in the normal way (trying to write each digit accurately) and the second time in a fast way (with no accuracy). \n\nThe best validation protocol for this dataset seems to be a 5x2CV, 50% Tune (Train +Test) and completly blind 50% Validation\n\n\n* Attribute Information:\n\nThis dataset consists of 1593 records (rows) and 256 attributes (columns). Each record represents a handwritten digit, orginally scanned with a resolution of 256 grays scale (28). Each pixel of the each original scanned image was first stretched, and after scaled between 0 and 1 (setting to 0 every pixel whose value was under tha value 127 of the grey scale (127 included) and setting to 1 each pixel whose orinal value in the grey scale was over 127). Finally, each binary image was scaled again into a 16x16 square box (the final 256 binary attributes).\n\n\n* Relevant Papers:\n\nM Buscema, MetaNet: The Theory of Independent Judges, in Substance Use & Misuse 33(2)1998, pp 439-461.', 'ARFF', NULL, NULL, NULL, '2015-05-25 22:22:34', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1592293/phptd5jYj', 'true', 83, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:18:33'),
(84, 64, NULL, 'steel-plates-fault', '1', NULL, '**Author**: Semeion, Research Center of Sciences of Communication, Rome, Italy.     \n**Source**: UCI     \n**Please cite**: Dataset provided by Semeion, Research Center of Sciences of Communication, Via Sersale 117, 00128, Rome, Italy. \n(www.semeion.it)   \n\n\n* Title: Steel Plates Faults Data Set \n\n* Abstract: \n\nA dataset of steel plates\' faults, classified into 7 different types. The goal was to train machine learning for automatic pattern recognition.\n\n* Source:\n\nSemeion, Research Center of Sciences of Communication, Via Sersale 117, 00128, Rome, Italy. \nwww.semeion.it\n\n\n* Data Set Information:\n\nType of dependent variables (7 Types of Steel Plates Faults): \n1.Pastry \n2.Z_Scratch \n3.K_Scatch \n4.Stains \n5.Dirtiness \n6.Bumps \n7.Other_Faults \n\n\nAttribute Information:\n\n27 independent variables: \nX_Minimum \nX_Maximum \nY_Minimum \nY_Maximum \nPixels_Areas \nX_Perimeter \nY_Perimeter \nSum_of_Luminosity \nMinimum_of_Luminosity \nMaximum_of_Luminosity \nLength_of_Conveyer \nTypeOfSteel_A300 \nTypeOfSteel_A400 \nSteel_Plate_Thickness \nEdges_Index \nEmpty_Index \nSquare_Index \nOutside_X_Index \nEdges_X_Index \nEdges_Y_Index \nOutside_Global_Index \nLogOfAreas \nLog_X_Index \nLog_Y_Index \nOrientation_Index \nLuminosity_Index \nSigmoidOfAreas \n\n\n* Relevant Papers:\n\n1.M Buscema, S Terzi, W Tastle, A New Meta-Classifier,in NAFIPS 2010, Toronto (CANADA),26-28 July 2010, 978-1-4244-7858-6/10 Â©2010 IEEE \n2.M Buscema, MetaNet: The Theory of Independent Judges, in Substance Use & Misuse, 33(2), 439-461,1998\n\n', 'ARFF', NULL, NULL, NULL, '2015-05-25 22:42:40', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1592296/php9xWOpn', 'true', 84, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:17:37'),
(85, 64, NULL, 'tamilnadu-electricity', '1', NULL, '**Author**: K.Kalyani.    \n**Source**: UCI    \n**Please cite**:   \n\n* Title: Tamilnadu Electricity Board Hourly Readings Data Set \n\n* Abstract: \n\nThis data can be effectively produced the result to fewer parameter of the Load profile can be reduced in the Database\n\n* Source:\n\nK.Kalyani ,kkalyanims \'@\' gmail.com,T.U.K Arts College,Karanthai,Thanjavur.\n\n\n* Data Set Information:\n\nCollect the real time readings for residential,commercial,industrial,agriculure,to find the accuracy consumption in Tamil Nadu Around Thanajvur.\n\n\n* Attribute Information:\n\nforkva,forkw,type,sector,service\n\n\n* Relevant Papers:\n\nEfficient Electricity Utilization By IHBMO\n', 'ARFF', NULL, NULL, NULL, '2015-05-25 22:52:37', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1592297/phpvFYBg2', 'true', 85, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:17:26'),
(86, 64, NULL, 'wdbc', '1', NULL, '**Author**: William H. Wolberg, W. Nick Street, Olvi L. Mangasarian    \n**Source**: UCI   \n**Please cite**:   \n\n* Title: \n\nBreast Cancer Wisconsin (Diagnostic) Data Set (WDBC)\n\n* Abstract: \n\nDiagnostic Wisconsin Breast Cancer Database\n\n* Source:\n\nCreators: \n\n1. Dr. William H. Wolberg, General Surgery Dept. \nUniversity of Wisconsin, Clinical Sciences Center \nMadison, WI 53792 \nwolberg \'@\' eagle.surgery.wisc.edu \n\n2. W. Nick Street, Computer Sciences Dept. \nUniversity of Wisconsin, 1210 West Dayton St., Madison, WI 53706 \nstreet \'@\' cs.wisc.edu 608-262-6619 \n\n3. Olvi L. Mangasarian, Computer Sciences Dept. \nUniversity of Wisconsin, 1210 West Dayton St., Madison, WI 53706 \nolvi \'@\' cs.wisc.edu \n\nDonor: Nick Street\n\n* Data Set Information:\n\nFeatures are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. A few of the images can be found at [Web Link] \n\nSeparating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes. \n\nThe actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34]. \n\nThis database is also available through the UW CS ftp server: \nftp ftp.cs.wisc.edu \ncd math-prog/cpo-dataset/machine-learn/WDBC/\n\n\n* Attribute Information:\n\n1) ID number \n2) Diagnosis (M = malignant, B = benign) \n3-32) \n\nTen real-valued features are computed for each cell nucleus: \n\na) radius (mean of distances from center to points on the perimeter) \nb) texture (standard deviation of gray-scale values) \nc) perimeter \nd) area \ne) smoothness (local variation in radius lengths) \nf) compactness (perimeter^2 / area - 1.0) \ng) concavity (severity of concave portions of the contour) \nh) concave points (number of concave portions of the contour) \ni) symmetry \nj) fractal dimension (\"coastline approximation\" - 1)\n\n\n* Relevant Papers:\n\nW.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993. \n[Web Link] \n\nO.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995. \n[Web Link] \n\nW.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 163-171. \n\nW.H. Wolberg, W.N. Street, and O.L. Mangasarian. Image analysis and machine learning applied to breast cancer diagnosis and prognosis. Analytical and Quantitative Cytology and Histology, Vol. 17 No. 2, pages 77-87, April 1995. \n\nW.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. Computerized breast cancer diagnosis and prognosis from fine needle aspirates. Archives of Surgery 1995;130:511-516. \n\nW.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. Computer-derived nuclear features distinguish malignant from benign breast cytology. Human Pathology, 26:792--796, 1995. \n\n', 'ARFF', NULL, NULL, NULL, '2015-05-26 16:24:07', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1592318/phpAmSP4g', 'true', 86, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-09 20:15:56'),
(87, 64, NULL, 'micro-mass', '2', '2', '**Author**: Pierre Mahé, Jean-Baptiste Veyrieras  \n**Source**: [original](http://www.openml.org/d/1514) - UCI   \n**Please cite**:   \n\n* Dataset Title: MicroMass - Pure (pure spectra version)   \n\n* Abstract:   \nA dataset to explore machine learning approaches for the identification of microorganisms from mass-spectrometry data.  \n\n* Source:\n\nPierre Mahé, pierre.mahe \'@\' biomerieux.com, bioMérieux\nJean-Baptiste Veyrieras, jean-baptiste.veyrieras \'@\' biomerieux.com, bioMérieux\n\n* Data Set Information:\n\nThis MALDI-TOF dataset consists in:\nA) A reference panel of 20 Gram positive and negative bacterial species covering 9 genera among which several species are known to be hard to discriminate by mass spectrometry (MALDI-TOF). Each species was represented by 11 to 60 mass spectra obtained from 7 to 20 bacterial strains, constituting altogether a dataset of 571 spectra obtained from 213 strains. The spectra were obtained according to the standard culture-based workflow used in clinical routine in which the microorganism was first grown on an agar plate for 24 to 48 hours, before a portion of colony was picked, spotted on a MALDI slide and a mass spectrum was acquired. \nB) Based on this reference panel, a dedicated in vitro mock-up mixture dataset was constituted. For that purpose we considered 10 pairs of species of various taxonomic proximity:\n* 4 mixtures, labelled A, B, C and D, involved species that belong to the same genus,  \n* 2 mixtures, labelled E and F, involved species that belong to distinct genera, but to the same Gram type,  \n* 4 mixtures, labelled G, H, I and J, involved species that belong to distinct Gram types.  \nEach mixture was represented by 2 pairs of strains, which were mixed according to the following 9 concentration ratios : 1:0, 10:1, 5:1, 2:1, 1:1, 1:2, 1:5, 1:10, 0:1. Two replicate spectra were acquired for each concentration ratio and each couple of strains, leading altogether to a dataset of 360 spectra, among which 80 are actually pure sample spectra.\n\n* Relevant Papers:\n\nMahé et al. (2014). Automatic identification of mixed bacterial species fingerprints in a MALDI-TOF mass-spectrum. Bioinformatics.\n\nVervier et al., A benchmark of support vector machines strategies for microbial identification by mass-spectrometry data, submitted\n\n\n\n\n\n', 'ARFF', '\"Pierre Mahé\",\"Jean-Baptiste Veyrieras\"', NULL, NULL, '2015-06-01 16:57:25', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1593707/phpHyLSNF', 'true', 87, 'Class', NULL, NULL, NULL, 'public', NULL, 'http://www.openml.org/d/1514', NULL, '2015-06-01 16:57:25'),
(88, 64, NULL, 'wilt', '1', NULL, '**Author**: Brian Johnson     \n**Source**: [UCI] (https://archive.ics.uci.edu/ml/datasets/Wilt)  \n**Please cite**: Johnson, B., Tateishi, R., Hoan, N., 2013. A hybrid pansharpening approach and multiscale object-based image analysis for mapping diseased pine and oak trees. International Journal of Remote Sensing, 34 (20), 6969-6982.   \n\n\n* Dataset:  \nWilt Data Set \n\n* Abstract:    \nHigh-resolution Remote Sensing data set (Quickbird). Small number of training samples of diseased trees, large number for other land cover. Testing data set from stratified random sample of image.\n\n* Source:\n  \nBrian Johnson; \nInstitute for Global Environmental Strategies; \n2108-11 Kamiyamaguchi, Hayama, Kanagawa,240-0115 Japan; \nEmail: Johnson \'@\' iges.or.jp \n\n\n* Data Set Information:  \n\nThis data set contains some training and testing data from a remote sensing study by Johnson et al. (2013) that involved detecting diseased trees in Quickbird imagery. There are few training samples for the \'diseased trees\' class (74) and many for \'other land cover\' class (4265). \n\nThe data set consists of image segments, generated by segmenting the pansharpened image. The segments contain spectral information from the Quickbird multispectral image bands and texture information from the panchromatic (Pan) image band. The testing data set is for the row with â€œSegmentation scale 15â€ segments and â€œoriginal multi-spectral imageâ€ Spectral information in Table 2 of the reference (i.e. row 5). Please see the reference below for more information on the data set, and please cite the reference if you use this data set. Enjoy! \n\n* Attribute Information:\n\nclass: \'w\' (diseased trees), \'n\' (all other land cover)   \nGLCM_Pan: GLCM mean texture (Pan band)   \nMean_G: Mean green value   \nMean_R: Mean red value   \nMean_NIR: Mean NIR value   \nSD_Pan: Standard deviation (Pan band)   \n\n\n* Relevant Papers:\n\nJohnson, B., Tateishi, R., Hoan, N., 2013. A hybrid pansharpening approach and multiscale object-based image analysis for mapping diseased pine and oak trees. International Journal of Remote Sensing, 34 (20), 6969-6982.\n', 'ARFF', NULL, NULL, NULL, '2015-06-01 23:34:28', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1675983/phpnThNfi', 'true', 88, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-10-08 14:43:09'),
(89, 2, NULL, 'adult', '2', '2', '**Author**: Ronny Kohavi and Barry Becker  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Adult) - 1996-05-01  \n**Please cite**: Ron Kohavi, \"Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid\", Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, 1996  \n\n**Note: this is the original version from the UCI repository, with training and test sets merged.**\n\nPrediction task is to determine whether a person makes over 50K a year. Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n\nRonny Kohavi and Barry Becker. Data Mining and Visualization, Silicon Graphics.  \ne-mail: ronnyk \'@\' live.com for questions. \n', 'ARFF', NULL, NULL, NULL, '2015-06-09 16:39:06', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1595261/phpMawTba', 'true', 89, 'class', NULL, NULL, NULL, 'public', NULL, NULL, 'added target attribute', '2015-06-09 16:56:26'),
(90, 2, NULL, 'Bioresponse', '1', NULL, 'Data from the Kaggle Bioresponse challenge:\nhttps://www.kaggle.com/c/bioresponse\n\nThe objective of the competition is to help us build as good a model as possible so that we can, as optimally as this data allows, relate molecular information, to an actual biological response.\n\nWe have shared the data in the comma separated values (CSV) format. Each row in this data set represents a molecule. The first column contains experimental data describing an actual biological response; the molecule was seen to elicit this response (1), or not (0). The remaining columns represent molecular descriptors (d1 through d1776), these are calculated properties that can capture some of the characteristics of the molecule - for example size, shape, or elemental constitution. The descriptor matrix has been normalized.\n\nThe original training and test set were merged.', 'ARFF', NULL, NULL, NULL, '2015-11-04 23:59:56', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1681097/phpSSK7iA', 'true', 90, 'target', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-04 23:59:56'),
(91, 2, NULL, 'Amazon_employee_access', '1', NULL, 'Data from the Kaggle Amazon Employee Access Challenge:\nhttps://www.kaggle.com/c/amazon-employee-access-challenge\n\nWhen an employee at any company starts work, they first need to obtain the computer access necessary to fulfill their role. This access may allow an employee to read/manipulate resources through various applications or web portals. It is assumed that employees fulfilling the functions of a given role will access the same or similar resources. It is often the case that employees figure out the access they need as they encounter roadblocks during their daily work (e.g. not able to log into a reporting portal). A knowledgeable supervisor then takes time to manually grant the needed access in order to overcome access obstacles. As employees move throughout a company, this access discovery/recovery cycle wastes a nontrivial amount of time and money.\n\nThere is a considerable amount of data regarding an employee&rsquo;s role within an organization and the resources to which they have access. Given the data related to current employees and their provisioned access, models can be built that automatically determine access privileges as employees enter and leave roles within a company. These auto-access models seek to minimize the human involvement required to grant or revoke employee access.\n\nThe original training and test set were merged.', 'ARFF', NULL, NULL, NULL, '2015-11-05 00:06:06', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1681098/phpmPOD5A', 'true', 91, 'target', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2015-11-05 00:06:06'),
(92, 874, NULL, 'PhishingWebsites', '1', NULL, '**Author**: Rami Mustafa A Mohammad ( University of Huddersfield\",\"rami.mohammad \'@\' hud.ac.uk\",\"rami.mustafa.a \'@\' gmail.com) Lee McCluskey (University of Huddersfield\",\"t.l.mccluskey \'@\' hud.ac.uk )  Fadi Thabtah (Canadian University of Dubai\",\"fadi \'@\' cud.ac.ae)  \n**Source**: UCI \n**Please cite**: Please refer to the Machine Learning Repository\'s citation policy  \n\nSource:\n\nRami Mustafa A Mohammad ( University of Huddersfield, rami.mohammad \'@\' hud.ac.uk, rami.mustafa.a \'@\' gmail.com)\nLee McCluskey (University of Huddersfield,t.l.mccluskey \'@\' hud.ac.uk )\n\nFadi Thabtah (Canadian University of Dubai,fadi \'@\' cud.ac.ae)\n\n\nData Set Information:\n\nOne of the challenges faced by our research was the unavailability of reliable training datasets. In fact this challenge faces any researcher in the field. However, although plenty of articles about predicting phishing websites have been disseminated these days, no reliable training dataset has been published publically, may be because there is no agreement in literature on the definitive features that characterize phishing webpages, hence it is difficult to shape a dataset that covers all possible features. \nIn this dataset, we shed light on the important features that have proved to be sound and effective in predicting phishing websites. In addition, we propose some new features.\n\n\nAttribute Information:\n\nFor Further information about the features see the features file in the data folder.\n\n\nRelevant Papers:\n\nMohammad, Rami, McCluskey, T.L. and Thabtah, Fadi (2012) An Assessment of Features Related to Phishing Websites using an Automated Technique. In: International Conferece For Internet Technology And Secured Transactions. ICITST 2012 . IEEE, London, UK, pp. 492-497. ISBN 978-1-4673-5325-0\n\nMohammad, Rami, Thabtah, Fadi Abdeljaber and McCluskey, T.L. (2014) Predicting phishing websites based on self-structuring neural network. Neural Computing and Applications, 25 (2). pp. 443-458. ISSN 0941-0643\n\nMohammad, Rami, McCluskey, T.L. and Thabtah, Fadi Abdeljaber (2014) Intelligent Rule based Phishing Websites Classification. IET Information Security, 8 (3). pp. 153-160. ISSN 1751-8709\n\n \n\nCitation Request:\n\nPlease refer to the Machine Learning Repository\'s citation policy', 'ARFF', '\"Rami Mustafa A Mohammad ( University of Huddersfield\",\"rami.mohammad \'@\' hud.ac.uk\",\"rami.mustafa.a \'@\' gmail.com) Lee McCluskey (University of Huddersfield\",\"t.l.mccluskey \'@\' hud.ac.uk )  Fadi Thabtah (Canadian University of Dubai\",\"fadi \'@\' cud.ac.ae)\"', NULL, NULL, '2016-02-16 15:30:33', NULL, 'Public', 'Please refer to the Machine Learning Repository\'s citation policy', NULL, 'https://www.openml.org/data/download/1798106/phpV5QYya', 'true', 92, 'Result', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2016-02-16 15:30:33'),
(93, 874, NULL, 'GesturePhaseSegmentationProcessed', '1', NULL, '**Author**: enata Cristina Barros Madeo (Madeo\",\"R. C. B.)  Priscilla Koch Wagner (Wagner\",\"P. K.)  Sarajane Marques Peres (Peres\",\"S. M.)  {renata.si\",\"priscilla.wagner\",\"sarajane} at usp.br  http://each.uspnet.usp.br/sarajane/  \n**Source**: UCI \n**Please cite**: Please refer to the Machine Learning Repository\'s citation policy. \nAdditionally, the authors require a citation to one or more publications from those cited as relevant papers.  \n\nSource:\n\nCreators: \nRenata Cristina Barros Madeo (Madeo, R. C. B.) \nPriscilla Koch Wagner (Wagner, P. K.) \nSarajane Marques Peres (Peres, S. M.) \n{renata.si, priscilla.wagner, sarajane} at usp.br \nhttp://each.uspnet.usp.br/sarajane/ \n\nDonor: \nUniversity of Sao Paulo - Brazil\n\n\nData Set Information:\n\nThe dataset is composed by features extracted from 7 videos with people gesticulating, aiming at studying Gesture Phase Segmentation. \nEach video is represented by two files: a raw file, which contains the position of hands, wrists, head and spine of the user in each frame; and a processed file, which contains velocity and acceleration of hands and wrists. See the data set description for more information on the dataset.\n\n\nAttribute Information:\n\nRaw files: 18 numeric attributes (double), a timestamp and a class attribute (nominal). \nProcessed files: 32 numeric attributes (double) and a class attribute (nominal). \nA feature vector with up to 50 numeric attributes can be generated with the two files mentioned above.\n\n\nRelevant Papers:\n\n1. Madeo, R. C. B. ; Lima, C. A. M. ; PERES, S. M. . Gesture Unit Segmentation using Support Vector Machines: Segmenting \nGestures from Rest Positions. In: Symposium on Applied Computing (SAC), 2013, Coimbra. Proceedings of the 28th Annual \nACM Symposium on Applied Computing (SAC), 2013. p. 46-52. \n* In this paper, the videos A1 and A2 were studied. \n\n2. Wagner, P. K. ; PERES, S. M. ; Madeo, R. C. B. ; Lima, C. A. M. ; Freitas, F. A. . Gesture Unit Segmentation Using \nSpatial-Temporal Information and Machine Learning. In: 27th Florida Artificial Intelligence Research Society Conference \n(FLAIRS), 2014, Pensacola Beach. Proceedings of the 27th Florida Artificial Intelligence Research Society Conference \n(FLAIRS). Palo Alto : The AAAI Press, 2014. p. 101-106. \n* In this paper, the videos A1, A2, A3, B1, B3, C1 and C3 were studied. \n\n3. Madeo, R. C. B.. Support Vector Machines and Gesture Analysis: incorporating temporal aspects (in Portuguese). Master \nThesis - Universidade de Sao Paulo, Sao Paulo Researcher Foundation. 2013. \n* In this document, the videos named B1 and B3 in the document correspond to videos C1 and C3 in this dataset. Only \nfive videos were explored in this document: A1, A2, A3, C1 and C3. \n\n4. Wagner, P. K. ; Madeo, R. C. B. ; PERES, S. M. ; Lima, C. A. M. . Segmenta&Atilde;&sect;ao de Unidades Gestuais com Multilayer \nPerceptrons (in Portuguese). In: Encontro Nacional de Inteligencia Artificial e Computacional (ENIAC), 2013, Fortaleza. \nAnais do X Encontro Nacional de Inteligencia Artificial e Computacional (ENIAC), 2013. \n* In this paper, the videos A1, A2 and A3 were studied.\n\n\n\nCitation Request:\n\nPlease refer to the Machine Learning Repository\'s citation policy. \nAdditionally, the authors require a citation to one or more publications from those cited as relevant papers.', 'ARFF', '\"enata Cristina Barros Madeo (Madeo\",\"R. C. B.)  Priscilla Koch Wagner (Wagner\",\"P. K.)  Sarajane Marques Peres (Peres\",\"S. M.)  {renata.si\",\"priscilla.wagner\",\"sarajane} at usp.br  http://each.uspnet.usp.br/sarajane/\"', NULL, NULL, '2016-02-17 11:42:33', NULL, 'Public', 'Please refer to the Machine Learning Repository\'s citation policy. \nAdditionally, the authors require a citation to one or more publications from those cited as relevant papers.', NULL, 'https://www.openml.org/data/download/1798765/phpYLeydd', 'true', 93, 'Phase', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2016-02-20 13:08:52'),
(94, 874, NULL, 'MiceProtein', '1', NULL, '**Author**: lara Higuera Department of Software Engineering and Artificial Intelligence\",\"Faculty of Informatics and the Department of Biochemistry and Molecular Biology\",\"Faculty of Chemistry\",\"University Complutense\",\"Madrid\",\"Spain.  Email: clarahiguera \'@\' ucm.es   Katheleen J. Gardiner\",\"creator and owner of the protein expression data\",\"is currently with the Linda Crnic Institute for Down Syndrome\",\"Department of Pediatrics\",\"Department of Biochemistry and Molecular Genetics\",\"Human Medical Genetics and Genomics\",\"and Neuroscience Programs\",\"University of Colorado\",\"School of Medicine\",\"Aurora\",\"Colorado\",\"USA.  Email: katheleen.gardiner \'@\' ucdenver.edu   Krzysztof J. Cios is currently with the Department of Computer Science\",\"Virginia Commonwealth University\",\"Richmond\",\"Virginia\",\"USA\",\"and IITiS Polish Academy of Sciences\",\"Poland.  Email: kcios \'@\' vcu.edu  \n**Source**: UCI  \n**Please cite**: Higuera C, Gardiner KJ, Cios KJ (2015) Self-Organizing Feature Maps Identify Proteins Critical to Learning in a Mouse Model of Down Syndrome. PLoS ONE 10(6): e0129126. [Web Link] journal.pone.0129126  \n\nAbstract: Expression levels of 77 proteins measured in the cerebral cortex of 8 classes of control and Down syndrome mice exposed to context fear conditioning, a task used to assess associative learning.\nSource:\n\nClara Higuera Department of Software Engineering and Artificial Intelligence, Faculty of Informatics and the Department of Biochemistry and Molecular Biology, Faculty of Chemistry, University Complutense, Madrid, Spain. \nEmail: clarahiguera \'@\' ucm.es \n\nKatheleen J. Gardiner, creator and owner of the protein expression data, is currently with the Linda Crnic Institute for Down Syndrome, Department of Pediatrics, Department of Biochemistry and Molecular Genetics, Human Medical Genetics and Genomics, and Neuroscience Programs, University of Colorado, School of Medicine, Aurora, Colorado, USA. \nEmail: katheleen.gardiner \'@\' ucdenver.edu \n\nKrzysztof J. Cios is currently with the Department of Computer Science, Virginia Commonwealth University, Richmond, Virginia, USA, and IITiS Polish Academy of Sciences, Poland. \nEmail: kcios \'@\' vcu.edu \n\n\nData Set Information:\n\nThe data set consists of the expression levels of 77 proteins/protein modifications that produced detectable signals in the nuclear fraction of cortex. There are 38 control mice and 34 trisomic mice (Down syndrome), for a total of 72 mice. In the experiments, 15 measurements were registered of each protein per sample/mouse. Therefore, for control mice, there are 38x15, or 570 measurements, and for trisomic mice, there are 34x15, or 510 measurements. The dataset contains a total of 1080 measurements per protein. Each measurement can be considered as an independent sample/mouse. \n\nThe eight classes of mice are described based on features such as genotype, behavior and treatment. According to genotype, mice can be control or trisomic. According to behavior, some mice have been stimulated to learn (context-shock) and others have not (shock-context) and in order to assess the effect of the drug memantine in recovering the ability to learn in trisomic mice, some mice have been injected with the drug and others have not. \n\nClasses: \nc-CS-s: control mice, stimulated to learn, injected with saline (9 mice) \nc-CS-m: control mice, stimulated to learn, injected with memantine (10 mice) \nc-SC-s: control mice, not stimulated to learn, injected with saline (9 mice) \nc-SC-m: control mice, not stimulated to learn, injected with memantine (10 mice) \n\nt-CS-s: trisomy mice, stimulated to learn, injected with saline (7 mice) \nt-CS-m: trisomy mice, stimulated to learn, injected with memantine (9 mice) \nt-SC-s: trisomy mice, not stimulated to learn, injected with saline (9 mice) \nt-SC-m: trisomy mice, not stimulated to learn, injected with memantine (9 mice) \n\nThe aim is to identify subsets of proteins that are discriminant between the classes. \n\n\nAttribute Information:\n\n1 Mouse ID \n2..78 Values of expression levels of 77 proteins; the names of proteins are followed by &acirc;&euro;&oelig;_n&acirc;&euro; indicating that they were measured in the nuclear fraction. For example: DYRK1A_n \n79 Genotype: control (c) or trisomy (t) \n80 Treatment type: memantine (m) or saline (s) \n81 Behavior: context-shock (CS) or shock-context (SC) \n82 Class: c-CS-s, c-CS-m, c-SC-s, c-SC-m, t-CS-s, t-CS-m, t-SC-s, t-SC-m \n\n\nRelevant Papers:\n\nThe posted data were analyzed by: \nHiguera C, Gardiner KJ, Cios KJ (2015) Self-Organizing Feature Maps Identify Proteins Critical to Learning in a Mouse Model of Down Syndrome. PLoS ONE 10(6): e0129126. [Web Link] journal.pone.0129126 \n\nThe data are a subset of the data analyzed by: \nAhmed MM, Dhanasekaran AR, Block A, Tong S, Costa ACS, Stasko M, et al. (2015) Protein Dynamics Associated with Failed and Rescued Learning in the Ts65Dn Mouse Model of Down Syndrome. PLoS ONE 10(3): e0119491. [Web Link] \n\n\n\n\nCitation Request:\n\nHiguera C, Gardiner KJ, Cios KJ (2015) Self-Organizing Feature Maps Identify Proteins Critical to Learning in a Mouse Model of Down Syndrome. PLoS ONE 10(6): e0129126. [Web Link] journal.pone.0129126', 'ARFF', '\"lara Higuera Department of Software Engineering and Artificial Intelligence\",\"Faculty of Informatics and the Department of Biochemistry and Molecular Biology\",\"Faculty of Chemistry\",\"University Complutense\",\"Madrid\",\"Spain.  Email: clarahiguera \'@\' ucm.es   Katheleen J. Gardiner\",\"creator and owner of the protein expression data\",\"is currently with the Linda Crnic Institute for Down Syndrome\",\"Department of Pediatrics\",\"Department of Biochemistry and Molecular Genetics\",\"Human Medical Genetics and Genomics\",\"and Neuroscience Programs\",\"University of Colorado\",\"School of Medicine\",\"Aurora\",\"Colorado\",\"USA.  Email: katheleen.gardiner \'@\' ucdenver.edu   Krzysztof J. Cios is currently with the Department of Computer Science\",\"Virginia Commonwealth University\",\"Richmond\",\"Virginia\",\"USA\",\"and IITiS Polish Academy of Sciences\",\"Poland.  Email: kcios \'@\' vcu.edu\"', NULL, NULL, '2016-02-17 14:32:49', NULL, 'Public', 'Higuera C, Gardiner KJ, Cios KJ (2015) Self-Organizing Feature Maps Identify Proteins Critical to Learning in a Mouse Model of Down Syndrome. PLoS ONE 10(6): e0129126. [Web Link] journal.pone.0129126', NULL, 'https://www.openml.org/data/download/1804243/phpO6CpB2', 'true', 94, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2016-02-21 21:09:16'),
(95, 2, NULL, 'cylinder-bands', '2', '2', '**Author**: Bob Evans, RR Donnelley & Sons Co.  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Cylinder+Bands) - August, 1995  \n**Please cite**:   \n\n**Cylinder bands**  \nProcess delays known as cylinder banding in rotogravure printing were substantially mitigated using control rules discovered by decision tree induction.\n \nAttribute Information:\n>  \n   1. timestamp: numeric;19500101 - 21001231  \n   2. cylinder number: nominal  \n   3. customer: nominal;  \n   4. job number: nominal;   \n   5. grain screened: nominal; yes, no  \n   6. ink color: nominal;  key, type  \n   7. proof on ctd ink:  nominal;  yes, no   \n   8. blade mfg: nominal;  benton, daetwyler, uddeholm  \n   9. cylinder division: nominal;  gallatin, warsaw, mattoon  \n  10. paper type: nominal;  uncoated, coated, super  \n  11. ink type: nominal;  uncoated, coated, cover  \n  12. direct steam: nominal; use; yes, no *  \n  13. solvent type: nominal;  xylol, lactol, naptha, line, other  \n  14. type on cylinder:  nominal;  yes, no   \n  15. press type: nominal; use; 70 wood hoe, 70 motter, 70 albert, 94 motter  \n  16. press: nominal;  821, 802, 813, 824, 815, 816, 827, 828  \n  17. unit number: nominal;  1, 2, 3, 4, 5, 6, 7, 8, 9, 10  \n  18. cylinder size: nominal;  catalog, spiegel, tabloid  \n  19. paper mill location: nominal; north us, south us, canadian, \n      scandanavian, mid european  \n  20. plating tank: nominal; 1910, 1911, other  \n  21. proof cut: numeric;  0-100  \n  22. viscosity: numeric;  0-100  \n  23. caliper: numeric;  0-1.0  \n  24. ink temperature: numeric;  5-30  \n  25. humifity: numeric;  5-120  \n  26. roughness: numeric;  0-2  \n  27. blade pressure: numeric;  10-75  \n  28. varnish pct: numeric;  0-100  \n  29. press speed: numeric;  0-4000  \n  30. ink pct: numeric;  0-100  \n  31. solvent pct: numeric;  0-100  \n  32. ESA Voltage: numeric;  0-16  \n  33. ESA Amperage: numeric;  0-10  \n  34. wax: numeric ;  0-4.0  \n  35. hardener:  numeric; 0-3.0  \n  36. roller durometer:  numeric;  15-120  \n  37. current density:  numeric;  20-50  \n  38. anode space ratio:  numeric;  70-130  \n  39. chrome content: numeric; 80-120  \n  40. band type: nominal; class; band, no band  \n\nNotes:  \n* cylinder number is an identifier and should be ignored when modelling the data', 'ARFF', NULL, NULL, NULL, '2016-03-30 22:09:17', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1854224/phpAz9Len', 'true', 95, 'band_type', NULL, '\"timestamp\",\"cylinder_number\"', NULL, 'public', NULL, NULL, NULL, '2016-03-30 22:09:17'),
(96, 2, NULL, 'cjs', '3', NULL, '**Author**: Dr. Fernando Camacho  \n**Source**: Unknown - 1995  \n**Please cite**: Camacho, F. and Arron, G. (1995)  Effects of the regulators paclobutrazol and flurprimidol on the growth of terminal sprouts formed on trimmed silver maple trees. Canadian Journal of Statistics 3(23).\n\nData on tree growth used in the Case Study published in the September, 1995 issue of the Canadian Journal of Statistics. This data set was been provided by Dr. Fernando Camacho, Ontario Hydro Technologies, 800 Kipling Ave, Toronto Canada M3Z 5S4. It forms the basis of the Case Study in Data Analysis published in the Canadian Journal of Statistics, September 1995. It can be freely used for noncommercial purposes, as long as proper acknowledgement to the source and to the Canadian Journal of Statistics is made.\n\n\nDescription\n\n\nThe effects of the Growth Regulators Paclobutrazol (PP 333)\nand Flurprimidol (EL-500) on the Number and Length of Internodes\nin Terminal Sprouts Formed on Trimmed Silver Maple Trees.\n \nIntroduction:\n \nThe trimming of trees under distribution lines on city streets and\nin rural areas is a major problem and expense for electrical\nutilities.  Such operations are routinely performed at intervals of\none to eight years depending upon the individual species growth rate\nand the amount of clearance required.  Ontario Hydro trims about\n500,000 trees per year at a cost of about $25 per tree.\n \nMuch effort has been spent in developing chemicals for the horticultural\nindustry to retard the growth of woody and herbaceous plants.  Recently,\na group of new growth regulators was introduced which was shown to be\neffective in controlling the growth of trees without producing\nnoticeable injury symptoms.  In this group are PP 333 ( common name\npaclobutrazol) (2RS, 3RS - 1 -(4-chlorophenyl) - 4,4 - dimethyl - 2 -\n(1,2,4-triazol-l-yl) pentan - 3- ol and EL-500 (common name flurprimidol\nand composition alpha - (1-methylethyl) - alpha - [4-(trifluromethoxyl)\nphenyl] - 5- pyrimidine - methanol).  Both EL-500 and PP-333 have been\nreported to control excessive sprout growth in a number of species\nwhen applied as a foliar spray, as a soil drench, or by trunk injection.\nSprout length is a function of both the number of internodes and\nthe length of the individual internodes in the sprout.  While there\nhave been many reports that both PP 333 and EL-500 cause a reduction\nin the length of internodes formed in sprouts on woody plants treated\nwith the growth regulators, there has been but one report that EL-500\napplication to apple trees resulted in a reduction of the number\nof internodes formed per sprout.\n \nThe purpose of the present study was to investigate the length of the\nterminal sprouts, the length of the individual internodes in those\nsprouts, and the number of internodes in trimmed silver maple trees\nfollowing trunk injection with the growth regulators PP 333 and EL-500.\n \nExperimental Details.\n \nMultistemmed 12-year-old silver maple trees growing at Wesleyville,\nOntario were trunk injected with methanolic solutions of EL-500\nand PP-333 in May of 1985 using a third generation Asplundh\ntree injector.\n \nTwo different application rates (20 g/L and 4 g/L) were used for each\nchemical.  The volume of solution (and hence the amount of active\ningredient) injected into each tree was determined from the diameter\nof the tree, using the formula: vol(mL) = (dbh)*(dbh)*.492 where dbh\nis the diameter at breast height.  Two sets of control trees were\nincluded in the experiment.  In one set, tree received no injection\n(control) and in a second set, the trees were injected with\nmethanol, the carrier in the growth regulator solutions.  Ten trees,\nchosen at random, were used in each of the control and experimental\nsets.  Prior to injection, all the trees were trimmed by a forestry\ncrew, with their heights being reduced by about one third.\n \nIn January 1987, twenty months after the trees were injected, between\nsix and eight limbs were removed at random from the bottom two-thirds\nof the canopy of each of the ten trees in each experimental and control\nset.  The limbs were returned to the laboratory and the length of all\nthe terminal sprouts, the lengths of the individual internodes, and\nthe number of internodes recorded.  Between one and 25 terminal\nsprouts were found on each limb collected.  Sprouts which had a\nlength of 1 cm or less were recorded as being 1 cm in length.\nIn such spouts, the internode lengths were not measured, but were\ncalculated from the total length of the sprout and the number\nof internodes counted.  Internode lengths were then expressed to one\ndecimal place.  In two instances, one of the ten trees in a set\ncould not be sampled because limb removal would have jeopardized the\nhealth of the tree over the long-term.\n \nData set:\n \nEach of the records represents a terminal sprout and contains the\nfollowing information:\n   N   the sprout number\n   TR  treatment 1  control\n                  2  methanol control\n                  3  PP 333 20g/L\n                  4  PP 333  4g/L\n                  5  EL 500 20g/L\n                  6  EL 500  4g/L\n   TREE  tree id\n   BR    branch id\n   TL    total sprout length (cm)\n   IN    number of internodes on the sprout\n   INTER a list of the lengths of the internodes in the sprout,\n          starting from the base of the sprout (129 entries)\n \nSprouts 1868 to 1879 do not have branch identification data.', 'ARFF', NULL, NULL, NULL, '2016-04-11 18:32:46', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1910442/phpDAC5gS', 'true', 96, 'TR', 'N', NULL, NULL, 'public', NULL, NULL, NULL, '2016-04-11 18:32:46'),
(97, 64, NULL, 'dresses-sales', '2', NULL, '**Author**: Muhammad Usman & Adeel Ahmed   \r\n**Source**: origin source at [UCI](https://archive.ics.uci.edu/ml/datasets/Dresses_Attribute_Sales)  \r\n**Please cite**:   \r\n\r\n####1. Summary\r\n\r\nThis dataset contain attributes of dresses and their recommendations according to their sales.Sales are monitor on the basis of alternate days. \r\n\r\nThe attributes present analyzed are: Style, Price, Rating, Size, Season, NeckLine, SleeveLength, waiseline, Material, FabricType, Decoration, Pattern, Type, Recommendation.\r\n\r\nContact:\r\n```\r\nMuhammad Usman & Adeel Ahmed, usman.madspot \'@\' gmail.com adeel.ahmed92 \'@\' gmail.com, Air University, Students at Air University.\r\n```\r\n\r\n####2: Attribute Information:\r\n\r\n```\r\nStyle: Bohemia,brief,casual,cute,fashion,flare,novelty,OL,party,sexy,vintage,work. \r\nPrice:Low,Average,Medium,High,Very-High \r\nRating:1-5 \r\nSize:S,M,L,XL,Free \r\nSeason:Autumn,winter,Spring,Summer \r\nNeckLine:O-neck,backless,board-neck,Bowneck,halter,mandarin-collor,open,peterpan-collor,ruffled,scoop,slash-neck,square-collar,sweetheart,turndowncollar,V-neck. \r\nSleeveLength:full,half,halfsleeves,butterfly,sleveless,short,threequarter,turndown,null \r\nwaiseline:dropped,empire,natural,princess,null. \r\nMaterial:wool,cotton,mix etc \r\nFabricType:shafoon,dobby,popline,satin,knitted,jersey,flannel,corduroy etc \r\nDecoration:applique,beading,bow,button,cascading,crystal,draped,embroridary,feathers,flowers etc \r\nPattern type: solid,animal,dot,leapard etc \r\nRecommendation:0,1 \r\n```\r\n', 'ARFF', NULL, NULL, NULL, '2016-04-11 19:57:27', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1910507/phpcFPMhq', 'true', 97, 'Class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2016-04-11 19:57:27'),
(98, 64, NULL, 'LED-display-domain-7digit', '1', '1', '1. Title of Database: LED display domain\n\n2. Sources:\n   (a) Breiman,L., Friedman,J.H., Olshen,R.A., &amp; Stone,C.J. (1984). \n       Classification and Regression Trees.  Wadsworth International\n       Group: Belmont, California.  (see pages 43-49).\n   (b) Donor: David Aha \n   (c) Date: 11/10/1988\n\n3. Past Usage: (many)\n     1. CART book (above):\n        -- Optimal Bayes classification rate: 74%\n        -- CART decision tree algorithm: 71% (resubstitution estimate)\n        -- Nearest Neighbor Algorithm: 71%\n           -- 200 training and 5000 test instances\n     \n     2. Quinlan,J.R. (1987). Simplifying Decision Trees.  In International\n        Journal of Man-Machine Studies (to appear).\n        -- C4 decision tree algorithm: 72.6% (using pessimistic pruning)\n           -- 2000 training and 500 test instances\n     3. Tan,M. &amp; Eshelman,L. (1988). Using Weighted Networks to Represent\n        Classification Knowledge in Noisy Domains.  In Proceedings of the\n        5th International Conference on Machine Learning, 121-134, Ann\n        Arbor, Michigan: Morgan Kaufmann.  \n        -- IWN system: 73.3% (using the And-OR classification algorithm)\n           -- 400 training and 500 test cases\n\n4. Relevant Information Paragraph:\n     This simple domain contains 7 Boolean attributes and 10 concepts,\n     the set of decimal digits.  Recall that LED displays contain 7\n     light-emitting diodes -- hence the reason for 7 attributes.  The\n     problem would be easy if not for the introduction of noise.  In\n     this case, each attribute value has the 10% probability of having\n     its value inverted.  \n\n     It\'s valuable to know the optimal Bayes rate for these databases.\n     In this case, the misclassification rate is 26% (74% classification\n     accuracy).\n        \n5. Number of Instances: 500. But in the original URL you can find a C script and run it choosing the number of instances to be generated.\n\n6. Number of Attributes: 7 (all Boolean-valued)\n\n7. Attribute Information:\n   -- All attribute values are either 0 or 1, according to whether\n      the corresponding light is on or not for the decimal digit.\n   -- Each attribute (excluding the class attribute, which is an\n      integer ranging between 0 and 9 inclusive) has a 10% percent\n      chance of being inverted.\n\n8. Missing Attribute Values: None\n\n9. Class Distribution: 10% (Theoretical)\n   -- Each concept (digit) has the same theoretical probability\n      distribution.  The program randomly selects the attribute.', 'ARFF', NULL, NULL, NULL, '2016-07-29 20:36:10', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/4535757/phpSj3fWL', 'true', 98, 'Class', NULL, NULL, NULL, 'public', NULL, 'http://sci2s.ugr.es/keel/dataset.php?cod=63, https://archive.ics.uci.edu/ml/datasets/LED+Display+Domain', NULL, '2016-07-29 20:36:10'),
(99, 64, NULL, 'texture', '1', '1', '**Author**: Laboratory of Image Processing and Pattern Recognition (INPG-LTIRF), Grenoble - France.  \r\n**Source**: [original](https://www.elen.ucl.ac.be/neural-nets/Research/Projects/ELENA/databases/REAL/texture/) - ELENA project   \r\n**Please cite**:   \r\n\r\n####1. Summary\r\n\r\nThis database was generated by the Laboratory of Image Processing and Pattern Recognition (INPG-LTIRF) in the development of the Esprit project ELENA No. 6891 and the Esprit working group ATHOS No. 6620.\r\n```\r\n (a) Original source:\r\n\r\n   P. Brodatz \"Textures: A Photographic Album for Artists and Designers\",\r\n   Dover Publications,Inc.,New York, 1966.\r\n\r\n (b) Creation: Laboratory of Image Processing and Pattern Recognition\r\n\r\n   Institut National Polytechnique de Grenoble INPG\r\n   Laboratoire de Traitement d\'Image et de Reconnaissance de Formes LTIRF\r\n   Av. Felix Viallet, 46\r\n   F-38031 Grenoble Cedex\r\n   France\r\n\r\n (c) Contact: Dr. A. Guerin-Dugue, INPG-LTIRF, guerin@tirf.inpg.fr\r\n```\r\n\r\n####2. Past Usage:\r\n\r\nThis database has a private usage at the TIRF laboratory. It has been created in order to study the textures discrimination with high order statistics.\r\n\r\n```\r\nA.Guerin-Dugue, C. Aviles-Cruz, \"High Order Statistics from Natural Textured Images\",\r\nIn ATHOS workshop on System Identification and High Order Statistics, Sophia-Antipolis, France, September 1993.\r\n\r\nGuerin-Dugue, A. and others, Deliverable R3-B4-P - Task B4: Benchmarks, Technical report,\r\nElena-NervesII \"Enhanced Learning for Evolutive Neural Architecture\", ESPRIT-Basic Research Project  Number 6891,\r\nJune 1995.\r\n```\r\n\r\n####3. Relevant Information:\r\n\r\nThe aim is to distinguish between 11 different textures (Grass lawn, Pressed calf leather, Handmade paper, Raffia looped to a high pile, Cotton canvas, ...), each pattern (pixel) being characterised by 40 attributes built by the estimation of fourth order modified moments in four orientations: 0, 45, 90 and 135 degrees.\r\n\r\nA statistical method based on the extraction of fourth order moments for the characterization of natural micro-textures was developed called \"fourth order modified moments\" (mm4) [Guerin93], this method measures the deviation from first-order Gauss-Markov process, for each texture. The features were estimated in four directions to take into account the possible orientations of the textures (0, 45, 90 and 135 degrees). Only correlation between the current pixel, the first neighbourhood and the second neighbourhood are taken into account. This small neighbourhood is adapted to the fine grain property of the textures.\r\n\r\nThe data set contains 11 classes of 500 instances and each class refers to a type of texture in the Brodatz album.\r\n\r\nThe database dimension is 40 plus one for the class label. The 40 attributes were build respectively by the estimation of the following fourth order modified moments in four orientations: 0, 45, 90 and 135 degrees: mm4(000), mm4(001), mm4(002), mm4(011), mm4(012), mm4(022), mm4(111), mm4(112), mm4(122) and mm4(222).\r\n\r\n!! Patterns are always sorted by class and are presented in the increasing order of their class label in each dataset relative to the texture database (texture.dat, texture_CR.dat, texture_PCA.dat, texture_DFA.dat)\r\n\r\n####4. Class:\r\n\r\nThe class label is a code for the following classes:\r\n```\r\n                Class         Class label\r\n  2   Grass lawn                      (D09)  \r\n  3   Pressed calf leather            (D24) \r\n  4   Handmade paper                  (D57) \r\n  6   Raffia looped to a high pile:   (D84) \r\n  7   Cotton canvas                   (D77) \r\n  8   Pigskin                         (D92) \r\n  9   Beach sand:                     (D28) \r\n  10  Beach sand                      (D29) \r\n  12  Oriental straw cloth            (D53) \r\n  13  Oriental straw cloth            (D78) \r\n  14  Oriental grass fiber cloth      (D79) \r\n```\r\n\r\n####5. Summary Statistics:\r\n\r\nTable here below provides for each attribute of the database the dynamic (Min and Max values), the mean value and the standard deviation.\r\n\r\n```\r\nAttribute  Min      Max       Mean     Standard    \r\n                                       deviation   \r\n\r\n    1   -1.4495    0.7741   -1.0983    0.2034\r\n    2   -1.2004    0.3297   -0.5867    0.2055\r\n    3   -1.3099    0.3441   -0.5838    0.3135\r\n    4   -1.1104    0.5878   -0.4046    0.2302\r\n    5   -1.0534    0.4387   -0.3307    0.2360\r\n    6   -1.0029    0.4515   -0.2422    0.2225\r\n    7   -1.2076    0.5246   -0.6026    0.2003\r\n    8   -1.0799    0.3980   -0.4322    0.2210\r\n    9   -1.0570    0.4369   -0.3317    0.2361\r\n   10   -1.2580    0.3546   -0.5978    0.3268\r\n   11   -1.4495    0.7741   -1.0983    0.2034\r\n   12   -1.0831    0.3715   -0.5929    0.2056\r\n   13   -1.1194    0.6347   -0.4019    0.3368\r\n   14   -1.0182    0.1573   -0.6270    0.1390\r\n   15   -0.9435    0.1642   -0.4482    0.1952\r\n   16   -0.9944    0.0357   -0.5763    0.1587\r\n   17   -1.1722    0.0201   -0.7331    0.1955\r\n   18   -1.0174    0.1155   -0.4919    0.2335\r\n   19   -1.0044    0.0833   -0.4727    0.2257\r\n   20   -1.1800    0.4392   -0.4831    0.3484\r\n   21   -1.4495    0.7741   -1.0983    0.2034\r\n   22   -1.2275    0.5963   -0.7363    0.2220\r\n   23   -1.3412    0.4464   -0.7771    0.3290\r\n   24   -1.1774    0.6882   -0.5770    0.2646\r\n   25   -1.1369    0.4098   -0.5085    0.2538\r\n   26   -1.1099    0.3725   -0.4038    0.2515\r\n   27   -1.2393    0.6120   -0.7279    0.2278\r\n   28   -1.1540    0.4221   -0.5863    0.2446\r\n   29   -1.1323    0.3916   -0.5090    0.2526\r\n   30   -1.4224    0.4718   -0.7708    0.3264\r\n   31   -1.4495    0.7741   -1.0983    0.2034\r\n   32   -1.1789    0.5647   -0.6463    0.1890\r\n   33   -1.1473    0.6755   -0.4919    0.3304\r\n   34   -1.1228    0.3132   -0.6435    0.1441\r\n   35   -1.0145    0.3396   -0.4918    0.1922\r\n   36   -1.0298    0.1560   -0.5934    0.1704\r\n   37   -1.2534    0.0899   -0.7795    0.1641\r\n   38   -1.0966    0.1944   -0.5541    0.2111\r\n   39   -1.0765    0.2019   -0.5230    0.2015\r\n   40   -1.2155    0.4647   -0.5677    0.3091\r\n```\r\n\r\nThe dynamic of the attributes is in [-1.45 - 0.775]. The database resulting from the centering and reduction by attribute of the Texture database is on the ftp server in the `REAL/texture/texture_CR.dat.Z\' file.\r\n\r\n####6. Confusion matrix.\r\n\r\nThe following confusion matrix of the k_NN classifier was obtained with a Leave_One_Out error counting method on the texture_CR.dat database. k was set to 1 in order to reach the minimum mean error rate : 1.0 +/- 0.8%.\r\n\r\n```\r\n Class    2      3      4      6      7      8      9      10     12     13     14 \r\n 2      97.0    1.0    0.4    0.0    0.0    0.0    1.6    0.0    0.0    0.0    0.0   \r\n 3       0.2   99.0    0.0    0.0    0.0    0.0    0.4    0.0    0.0    0.0    0.4   \r\n 4       1.0    0.0   98.8    0.0    0.0    0.0    0.2    0.0    0.0    0.0    0.0   \r\n 6       0.0    0.0    0.0   99.4    0.0    0.0    0.0    0.6    0.0    0.0    0.0   \r\n 7       0.0    0.0    0.0    0.0  100.0    0.0    0.0    0.0    0.0    0.0    0.0   \r\n 8       0.0    0.0    0.0    0.0    0.0   98.6    0.0    1.4    0.0    0.0    0.0   \r\n 9       0.4    0.0    0.2    0.0    0.0    0.2   98.8    0.4    0.0    0.0    0.0   \r\n 10      0.0    0.0    0.0    0.0    0.0    1.4    0.0   98.6    0.0    0.0    0.0   \r\n 12      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  100.0    0.0    0.0   \r\n 13      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   99.8    0.2   \r\n 14      0.0    0.4    0.0    0.0    0.0    0.4    0.0    0.0    0.2    0.0   99.0   \r\n```\r\n\r\n7. Result of the Principal Component Analysis:\r\n\r\nThe Principal Components Analysis is a very classical method in pattern recognition [Duda73]. PCA reduces the sample dimension in a linear way for the best representation in lower dimensions keeping the maximum of inertia. The best axe for the representation is however not necessary the best axe for the discrimination. After PCA, features are selected according to the percentage of initial inertia which is covered by the different axes and the number of features is determined according to the percentage of initial inertia to keep for the classification process.\r\n\r\nThis selection method has been applied on the texture_CR database. When quasi-linear correlations exists between some initial features, these redundant dimensions are removed by PCA and this preprocessing is then recommended. In this case, before a PCA, the determinant of the data covariance matrix is near zero; this database is thus badly conditioned for all process which use this information (the quadratic classifier for example).\r\n\r\nThe following file is available for the texture database: \'\'texture_PCA.dat.Z\'\', it is the projection of the \'\'texture_CR\'\' database on its principal components (sorted in a decreasing order of the related inertia percentage; so, if you desire to work on the database projected on its x first principal components you only have to keep the x first attributes of the texture_PCA.dat database and the class labels (last attribute)).\r\n\r\nTable here below provides the inertia percentages associated to the eigenvalues corresponding to the principal component axis sorted in the decreasing order of the associated inertia percentage. 99.85 percent of the total database inertia will remain if the 20 first principal components are kept.\r\n\r\n```\r\n       Eigen Value   Inertia      Cumulated\r\n         value      percentage      inertia\r\n\r\n  1   30.267500000 75.6687000000  75.6687000000 \r\n  2   3.6512500000  9.1281300000  84.7969000000 \r\n  3   2.2937000000  5.7342400000  90.5311000000 \r\n  4   1.7039700000  4.2599300000  94.7910000000 \r\n  5   0.6716540000  1.6791300000  96.4702000000 \r\n  6   0.5015290000  1.2538200000  97.7240000000 \r\n  7   0.1922830000  0.4807070000  98.2047000000 \r\n  8   0.1561070000  0.3902670000  98.5950000000 \r\n  9   0.1099570000  0.2748920000  98.8699000000 \r\n  10  0.0890891000  0.2227230000  99.0926000000 \r\n  11  0.0656016000  0.1640040000  99.2566000000 \r\n  12  0.0489988000  0.1224970000  99.3791000000 \r\n  13  0.0433819000  0.1084550000  99.4875000000 \r\n  14  0.0345022000  0.0862554000  99.5738000000 \r\n  15  0.0299203000  0.0748007000  99.6486000000 \r\n  16  0.0248857000  0.0622141000  99.7108000000 \r\n  17  0.0167901000  0.0419752000  99.7528000000 \r\n  18  0.0161633000  0.0404083000  99.7932000000 \r\n  19  0.0128898000  0.0322246000  99.8254000000 \r\n  20  0.0113884000  0.0284710000  99.8539000000 \r\n  21  0.0078481400  0.0196204000  99.8735000000 \r\n  22  0.0071527800  0.0178820000  99.8914000000 \r\n  23  0.0067661400  0.0169153000  99.9083000000 \r\n  24  0.0053149500  0.0132874000  99.9216000000 \r\n  25  0.0051102600  0.0127757000  99.9344000000 \r\n  26  0.0047116600  0.0117792000  99.9461000000 \r\n  27  0.0036193700  0.0090484300  99.9552000000 \r\n  28  0.0033222000  0.0083054900  99.9635000000 \r\n  29  0.0030722400  0.0076806100  99.9712000000 \r\n  30  0.0026373300  0.0065933300  99.9778000000 \r\n  31  0.0020996800  0.0052492000  99.9830000000 \r\n  32  0.0019376500  0.0048441200  99.9879000000 \r\n  33  0.0015642300  0.0039105700  99.9918000000 \r\n  34  0.0009679080  0.0024197700  99.9942000000 \r\n  35  0.0009578000  0.0023945000  99.9966000000 \r\n  36  0.0007379780  0.0018449400  99.9984000000 \r\n  37  0.0006280250  0.0015700600  100.000000000\r\n  38  0.0000000040  0.0000000099  100.000000000 \r\n  39  0.0000000001  0.0000000003  100.000000000 \r\n  40  0.0000000008  0.0000000019  100.000000000 \r\n\r\n```\r\n\r\nThis matrix can be found in the texture_EV.dat file.\r\n\r\nThe Discriminant Factorial Analysis (DFA) can be applied to a learning database where each learning sample belongs to a particular class [Duda73]. The number of discriminant features selected by DFA is fixed in function of the number of classes (c) and of the number of input dimensions (d); this number is equal to the minimum between d and c-1. In the usual case where d is greater than c, the output dimension is fixed equal to the number of classes minus one and the discriminant axes are selected in order to maximize the between-variance and to minimize the within-variance of the classes.\r\n\r\nThe discrimination power (ratio of the projected between-variance over the projected within-variance) is not the same for each discriminant axis: this ratio decreases for each axis. So for a problem with many classes, this preprocessing will not be always efficient as the last output features will not be so discriminant. This analysis uses the information of the inverse of the global covariance matrix, so the covariance matrix must be well conditioned (for example, a preliminary PCA must be applied to remove the linearly correlated dimensions).\r\n\r\nThe Discriminant Factorial Analysis (DFA) has been applied on the 18 first principal components of the texture_PCA database (thus by keeping only the 18 first attributes of these databases before to apply the DFA preprocessing) in order to build the texture_DFA.dat.Z database file, having 10 dimensions (the texture database having 11 classes). In the case of the texture database, experiments shown that a DFA preprocessing is very useful and most of the time improved the classifiers performances.\r\n\r\n[Duda73] Duda, R.O. and Hart, P.E.,Pattern Classification and Scene Analysis, John Wiley & Sons, 1973.\r\n', 'ARFF', NULL, NULL, NULL, '2016-07-29 21:03:14', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/4535764/phpBDgUyY', 'true', 99, 'Class', NULL, NULL, NULL, 'public', NULL, 'http://sci2s.ugr.es/keel/dataset.php?cod=72', NULL, '2016-07-29 21:03:14'),
(100, 2, NULL, 'Australian', '3', '2', '**Author**: Confidential. Donated by Ross Quinlan  \r\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Statlog+(Australian+Credit+Approval))/LibSVM - 2014-11-14  \r\n**Please cite**:   \r\n\r\nThis is the famous Australian dataset, retrieved 2014-11-14 from the libSVM site.\r\nIt was normalized.\r\n\r\nThe original version is from [UCI](https://archive.ics.uci.edu/ml/datasets/Statlog+(Australian+Credit+Approval)).\r\n\r\nThis file concerns credit card applications. All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data. \r\n\r\nThis dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values. There are also a few missing values. \r\n\r\n\r\nSource: Statlog / Australian\r\n# of classes: 2\r\n# of data: 690\r\n# of features: 14', 'ARFF', NULL, NULL, NULL, '2016-09-21 15:43:02', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/4599631/phpjP8PU3', 'true', 100, 'Y', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2016-09-21 15:43:02'),
(101, 2, NULL, 'UNIX_user_data', '1', NULL, '**Author**: Terran Lane (terran@ecn.purdue.edu)   \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/UNIX+User+Data) - Date unknown  \n**Please cite**:   \n\nThis file contains 9 sets of sanitized user data drawn from the command histories of 8 UNIX computer users at Purdue over the course of up to 2 years (USER0 and USER1 were generated by the same person, working on different platforms and different projects).  The data is drawn from tcsh(1) history files and has been parsed and sanitized to remove filenames, user names, directory structures, web addresses, host names, and other possibly identifying items.  Command names, flags, and shell metacharacters have been preserved.  Additionally, **SOF** and **EOF** tokens have been inserted at the start and end of\nshell sessions, respectively.  Sessions are concatenated by date order and tokens appear in the order issued within the shell session, but no timestamps are included in this data.  For example, the two sessions:\n\ncd ~/private/docs  \nls -laF | more  \ncat foo.txt bar.txt zorch.txt > somewhere  \nexit  \n\ncd ~/games/  \nxquake &  \nfg  \nvi scores.txt  \nmailx john_doe@somewhere.com  \nexit  \n\nwould be represented by the token stream  \n\n**SOF**  \ncd  \n\\<1\\>                  (one \"file name\" argument)  \nls  \n-laF  \n|  \nmore  \ncat  \n\\<3\\>                     (three \"file\" arguments)\n\\>  \n\\<1\\>  \nexit  \n**EOF**  \n**SOF**  \ncd  \n\\<1\\>  \nxquake  \n&  \nfg  \nvi  \n\\<1\\>  \nmailx  \n\\<1\\>  \nexit  \n**EOF**\n\nThis data is made available under conditions of anonymity for the contributing users and may be used for research purposes only. Summaries and research results employing this data may be published, but literal tokens or token sequences from the data may not be published except with express consent of the originators of the data. No portion of this data may be released with or included in a commercial product, nor may any portion of this data be sold or redistributed for profit or as part of of a profit-making endeavor.', 'ARFF', NULL, NULL, NULL, '2014-09-27 10:55:59', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/52413/UNIX_user_data.arff', 'true', 101, 'user', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-09-27 10:55:59'),
(102, 402, NULL, 'fourclass_scale', '1', NULL, '**Author**: Tin Kam Ho and Eugene M. Kleinberg.  \nlibSVM\",\"AAD group  \n**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  \n**Please cite**:   \n\n#Dataset from the LIBSVM data repository.\n\nPreprocessing: transform to two-class', 'Sparse_ARFF', '\"Tin Kam Ho and Eugene M. Kleinberg.\"', '\"libSVM\",\"AAD group\"', NULL, '2015-06-02 11:17:44', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/1594035/phpeLklTK', 'true', 102, 'class', NULL, NULL, NULL, 'public', NULL, 'http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html', NULL, '2015-06-02 11:17:44'),
(103, 1, 0, 'kin8nm', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThis is data set is concerned with the forward kinematics of an 8 link\n robot arm. Among the existing variants of this data set we have used\n the variant 8nm, which is known to be highly non-linear and medium\n noisy.\n\n Original source: DELVE repository of data. \n Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\n http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\n Characteristics: 8192 cases, 9 attributes (0 nominal, 9 continuous).', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:16:04', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3626/dataset_2175_kin8nm.arff', 'true', 103, 'y', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:16:04'),
(104, 1, 0, 'mbagrade', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nDataset from Smoothing Methods in Statistics \n (ftp stat.cmu.edu/datasets)\n\n Simonoff, J.S. (1996). Smoothing Methods in Statistics. New York: Springer-Verlag.', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:16:07', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3627/dataset_2176_mbagrade.arff', 'true', 104, 'grade_point_average', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:16:07'),
(105, 1, 0, 'wisconsin', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Wisconsin Prognostic Breast Cancer (WPBC)\n \n 2. Source Information\n \n a) Creators: \n \n 	Dr. William H. Wolberg, General Surgery Dept., University of\n 	Wisconsin,  Clinical Sciences Center, Madison, WI 53792\n 	wolberg@eagle.surgery.wisc.edu\n \n 	W. Nick Street, Computer Sciences Dept., University of\n 	Wisconsin, 1210 West Dayton St., Madison, WI 53706\n 	street@cs.wisc.edu  608-262-6619\n \n 	Olvi L. Mangasarian, Computer Sciences Dept., University of\n 	Wisconsin, 1210 West Dayton St., Madison, WI 53706\n 	olvi@cs.wisc.edu \n \n b) Donor: Nick Street\n \n c) Date: December 1995\n \n 3. Past Usage:\n \n 	Various versions of this data have been used in the following\n 	publications: \n \n 	(i) W. N. Street, O. L. Mangasarian, and W.H. Wolberg. \n 	An inductive learning approach to prognostic prediction. \n 	In A. Prieditis and S. Russell, editors, Proceedings of the\n 	Twelfth International Conference on Machine Learning, pages\n 	522--530, San Francisco, 1995. Morgan Kaufmann.\n \n 	(ii) O.L. Mangasarian, W.N. Street and W.H. Wolberg. \n 	Breast cancer diagnosis and prognosis via linear programming. \n 	Operations Research, 43(4), pages 570-577, July-August 1995. \n \n 	(iii) W.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. \n 	Computerized breast cancer diagnosis and prognosis from fine\n 	needle aspirates.  Archives of Surgery 1995;130:511-516. \n \n 	(iv) W.H. Wolberg, W.N. Street, and O.L. Mangasarian. \n 	Image analysis and machine learning applied to breast cancer\n 	diagnosis and prognosis. Analytical and Quantitative Cytology\n 	and Histology, Vol. 17 No. 2, pages 77-87, April 1995.\n \n 	(v) W.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. \n 	Computer-derived nuclear ``grade\'\' and breast cancer prognosis. \n 	Analytical and Quantitative Cytology and Histology, Vol. 17,\n 	pages 257-264, 1995. \n \n See also:\n 	http://www.cs.wisc.edu/~olvi/uwmp/mpml.html\n 	http://www.cs.wisc.edu/~olvi/uwmp/cancer.html\n \n Results:\n \n 	Two possible learning problems:\n \n 	1) Predicting field 2, outcome: R = recurrent, N = nonrecurrent\n 	- Dataset should first be filtered to reflect a particular\n 	endpoint; e.g., recurrences before 24 months = positive,\n 	nonrecurrence beyond 24 months = negative.\n 	- 86.3% accuracy estimated accuracy on 2-year recurrence using\n 	previous version of this data.  Learning method: MSM-T (see\n 	below) in the 4-dimensional space of Mean Texture, Worst Area,\n 	Worst Concavity, Worst Fractal Dimension.\n \n 	2) Predicting Time To Recur (field 3 in recurrent records)\n 	- Estimated mean error 13.9 months using Recurrence Surface\n 	Approximation. (See references (i) and (ii) above)\n \n 4. Relevant information\n \n 	Each record represents follow-up data for one breast cancer\n 	case.  These are consecutive patients seen by Dr. Wolberg\n 	since 1984, and include only those cases exhibiting invasive\n 	breast cancer and no evidence of distant metastases at the\n 	time of diagnosis. \n \n 	The first 30 features are computed from a digitized image of a\n 	fine needle aspirate (FNA) of a breast mass.  They describe\n 	characteristics of the cell nuclei present in the image.\n 	A few of the images can be found at\n 	http://www.cs.wisc.edu/~street/images/\n \n 	The separation described above was obtained using\n 	Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n 	Construction Via Linear Programming.\" Proceedings of the 4th\n 	Midwest Artificial Intelligence and Cognitive Science Society,\n 	pp. 97-101, 1992], a classification method which uses linear\n 	programming to construct a decision tree.  Relevant features\n 	were selected using an exhaustive search in the space of 1-4\n 	features and 1-3 separating planes.\n \n 	The actual linear program used to obtain the separating plane\n 	in the 3-dimensional space is that described in:\n 	[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n 	Programming Discrimination of Two Linearly Inseparable Sets\",\n 	Optimization Methods and Software 1, 1992, 23-34].\n \n 	The Recurrence Surface Approximation (RSA) method is a linear\n 	programming model which predicts Time To Recur using both\n 	recurrent and nonrecurrent cases.  See references (i) and (ii)\n 	above for details of the RSA method. \n \n 	This database is also available through the UW CS ftp server:\n \n 	ftp ftp.cs.wisc.edu\n 	cd math-prog/cpo-dataset/machine-learn/WPBC/\n \n 5. Number of instances: 198\n \n 6. Number of attributes: 34 (ID, outcome, 32 real-valued input features)\n \n 7. Attribute information\n \n 1) ID number\n 2) Outcome (R = recur, N = nonrecur)\n 3) Time (recurrence time if field 2 = R, disease-free time if \n 	field 2	= N)\n 4-33) Ten real-valued features are computed for each cell nucleus:\n \n 	a) radius (mean of distances from center to points on the perimeter)\n 	b) texture (standard deviation of gray-scale values)\n 	c) perimeter\n 	d) area\n 	e) smoothness (local variation in radius lengths)\n 	f) compactness (perimeter^2 / area - 1.0)\n 	g) concavity (severity of concave portions of the contour)\n 	h) concave points (number of concave portions of the contour)\n 	i) symmetry \n 	j) fractal dimension (\"coastline approximation\" - 1)\n \n Several of the papers listed above contain detailed descriptions of\n how these features are computed. \n \n The mean, standard error, and \"worst\" or largest (mean of the three\n largest values) of these features were computed for each image,\n resulting in 30 features.  For instance, field 4 is Mean Radius, field\n 14 is Radius SE, field 24 is Worst Radius.\n \n Values for features 4-33 are recoded with four significant digits.\n \n 34) Tumor size - diameter of the excised tumor in centimeters\n 35) Lymph node status - number of positive axillary lymph nodes\n observed at time of surgery\n \n 8. Missing attribute values: \n 	Lymph node status is missing in 4 cases.\n \n 9. Class distribution: 151 nonrecur, 47 recur\n\n-----------------------------------------------------------------------------------------------------------\n Luis Torgo\'s version: (reconstructed)\n - removed the four instances with unknown values of the last attribute\n - exchanged the attribute position of attributes n.3 (Time) and n.35\n   (Lymph node).\n - removed the attribute outcome as it is the class attribute if the\n   problem is treated as a classification one\n-----------------------------------------------------------------------------------------------------------', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:16:10', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3628/dataset_2177_wisconsin.arff', 'true', 105, 'time', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:16:10'),
(106, 1, 0, 'vineyard', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nDataset from Smoothing Methods in Statistics \n (ftp stat.cmu.edu/datasets)\n\n Simonoff, J.S. (1996). Smoothing Methods in Statistics. New York: Springer-Verlag.', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:16:12', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3629/dataset_2178_vineyard.arff', 'true', 106, 'lugs_1991', 'row_number', NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:16:12'),
(107, 1, 0, 'bolts', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nData from StatLib (ftp stat.cmu.edu/datasets)\n \n SUMMARY:\n \n Data from an experiment on the affects of machine adjustments on\n the time to count bolts.  Data appear as the STATS (Issue 10) Challenge.\n \n DATA:\n \n Submitted by W. Robert Stephenson, Iowa State University\n                             email: wrstephe@iastate.edu\n \n A manufacturer of automotive accessories provides hardware, e.g. nuts,\n bolts, washers and screws, to fasten the accessory to the car or truck.\n Hardware is counted and packaged automatically.  Specifically, bolts\n are dumped into a large metal dish.  A plate that forms the bottom of\n the dish rotates counterclockwise.  This rotation forces bolts to the\n outside of the dish and up along a narrow ledge.  Due to the vibration\n of the dish caused by the spinning bottom plate, some bolts fall off \n the ledge and back into the dish.  The ledge spirals up to a point \n where the bolts are allowed to drop into a pan on a conveyor belt.  \n As a bolt drops, it passes by an electronic eye that counts it.  When \n the electronic counter reaches the preset number of bolts, the\n rotation is stopped and the conveyor belt is moved forward.  \n \n There are several adjustments on the machine that affect its operation.  \n These include; a speed setting that controls the speed of rotation\n (SPEED1) of the plate at the bottom of the dish, a total number of \n bolts (TOTAL) to be counted, a second speed setting (SPEED2) that is \n used to change the speed of rotation (usually slowing it down) for the\n last few bolts, the number of bolts to be counted at this second speed\n (NUMBER2), and the sensitivity of the electronic eye (SENS).  The \n sensitivity setting is to insure that the correct number of bolts are \n counted.  Too few bolts packaged causes customer complaints.  Too many\n bolts packaged increases costs.  For each run conducted in this \n experiment the correct number of bolts was counted.  From an\n engineering standpoint if the correct number of bolts is counted, the \n sensitivity should not affect the time to count bolts.  The measured \n response is the time (TIME), in seconds, it takes to count the desired\n number of bolts.  In order to put times on a equal footing the\n response to be analyzed is the time to count 20 bolts (T20BOLT).\n Below are the data for 40 combinations of settings.  RUN is the order \n in which the data were collected.\n \n Analyze the data.  What adjustments have the greatest effect on the \n time to count 20 bolts?  How would you adjust the machine to get\n the shortest time to count 20 bolts?  Are there any unusual features\n to the data?\n \n The data description and data may be freely used for non-commercial\n purposes and can be freely distributed.  Copyright remains with the\n author and STATS Magazine.', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:16:14', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3630/dataset_2179_bolts.arff', 'true', 107, 'T20BOLT', 'RUN', NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:16:14'),
(108, 1, 0, 'cleveland', '1', '1', '**Author**: Andras Janosi, M.D.  \nDonor: David W. Aha (aha@ics.uci.edu)  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Heart+Disease) - July 1988  \n**Please cite**: The author request that any publications resulting from the use of the data include the name of the author.\n\n**Heart Disease Databases: Cleveland**  \nThis database contains 76 attributes, but all published experiments refer to using a subset of 14 of them.  In particular, the Cleveland database is the only one that has been used by ML researchers to this date.  The \"goal\" field refers to the presence of heart disease in the patient.  It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).  \n    \nThe names and social security numbers of the patients were recently removed from the database, replaced with dummy values.\nOne file has been \"processed\", that one containing the Cleveland database. \n     \nAttribute documentation:  \n>\n       1 id: patient identification number\n       2 ccf: social security number (I replaced this with a dummy value of 0)\n       3 age: age in years\n       4 sex: sex (1 = male; 0 = female)\n       5 painloc: chest pain location (1 = substernal; 0 = otherwise)\n       6 painexer (1 = provoked by exertion; 0 = otherwise)\n       7 relrest (1 = relieved after rest; 0 = otherwise)\n       8 pncaden (sum of 5, 6, and 7)\n       9 cp: chest pain type\n         -- Value 1: typical angina\n         -- Value 2: atypical angina\n         -- Value 3: non-anginal pain\n         -- Value 4: asymptomatic\n      10 trestbps: resting blood pressure (in mm Hg on admission to the \n         hospital)\n      11 htn\n      12 chol: serum cholestoral in mg/dl\n      13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)\n      14 cigs (cigarettes per day)\n      15 years (number of years as a smoker)\n      16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n      17 dm (1 = history of diabetes; 0 = no such history)\n      18 famhist: family history of coronary artery disease (1 = yes; 0 = no)\n      19 restecg: resting electrocardiographic results\n         -- Value 0: normal\n         -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST \n                     elevation or depression of > 0.05 mV)\n         -- Value 2: showing probable or definite left ventricular hypertrophy\n                     by Estes\' criteria\n      20 ekgmo (month of exercise ECG reading)\n      21 ekgday(day of exercise ECG reading)\n      22 ekgyr (year of exercise ECG reading)\n      23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)\n      24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)\n      25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)\n      26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)\n      27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)\n      28 proto: exercise protocol\n           1 = Bruce     \n           2 = Kottus\n           3 = McHenry\n           4 = fast Balke\n           5 = Balke\n           6 = Noughton \n           7 = bike 150 kpa min/min  (Not sure if \"kpa min/min\" is what was \n               written!)\n           8 = bike 125 kpa min/min  \n           9 = bike 100 kpa min/min\n          10 = bike 75 kpa min/min\n          11 = bike 50 kpa min/min\n          12 = arm ergometer\n      29 thaldur: duration of exercise test in minutes\n      30 thaltime: time when ST measure depression was noted\n      31 met: mets achieved\n      32 thalach: maximum heart rate achieved\n      33 thalrest: resting heart rate\n      34 tpeakbps: peak exercise blood pressure (first of 2 parts)\n      35 tpeakbpd: peak exercise blood pressure (second of 2 parts)\n      36 dummy\n      37 trestbpd: resting blood pressure\n      38 exang: exercise induced angina (1 = yes; 0 = no)\n      39 xhypo: (1 = yes; 0 = no)\n      40 oldpeak = ST depression induced by exercise relative to rest\n      41 slope: the slope of the peak exercise ST segment\n         -- Value 1: upsloping\n         -- Value 2: flat\n         -- Value 3: downsloping\n      42 rldv5: height at rest\n      43 rldv5e: height at peak exercise\n      44 ca: number of major vessels (0-3) colored by flourosopy\n      45 restckm: irrelevant\n      46 exerckm: irrelevant\n      47 restef: rest raidonuclid (sp?) ejection fraction\n      48 restwm: rest wall (sp?) motion abnormality\n         0 = none\n         1 = mild or moderate\n         2 = moderate or severe\n         3 = akinesis or dyskmem (sp?)\n      49 exeref: exercise radinalid (sp?) ejection fraction\n      50 exerwm: exercise wall (sp?) motion \n      51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n      52 thalsev: not used\n      53 thalpul: not used\n      54 earlobe: not used\n      55 cmo: month of cardiac cath (sp?)  (perhaps \"call\")\n      56 cday: day of cardiac cath (sp?)\n      57 cyr: year of cardiac cath (sp?)\n      58 num: diagnosis of heart disease (angiographic disease status)\n         -- Value 0: < 50% diameter narrowing\n         -- Value 1: > 50% diameter narrowing\n         (in any major vessel: attributes 59 through 68 are vessels)\n      59 lmt\n      60 ladprox\n      61 laddist\n      62 diag\n      63 cxmain\n      64 ramus\n      65 om1\n      66 om2\n      67 rcaprox\n      68 rcadist\n      69 lvx1: not used\n      70 lvx2: not used\n      71 lvx3: not used\n      72 lvx4: not used\n      73 lvf: not used\n      74 cathef: not used\n      75 junk: not used\n      76 name: last name of patient \n         (I replaced this with the dummy string \"name\")', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:16:17', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3631/dataset_2180_cleveland.arff', 'true', 108, 'num', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:16:17'),
(109, 1, 0, 'auto_price', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThis data set consists of three types of entities:\n (a) the specification of an auto in terms of various characteristics;\n (b) its assigned insurance risk rating,;\n (c) its normalized losses in use as compared to other cars. \n The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially\n assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by\n moving it up (or down) the scale. Actuarians call this process \"symboling\". A value of +3 indicates that the auto is\n risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year.\n This value is normalized for all autos within a particular size classification (two-door small, station wagons,\n sports/speciality, etc...), and represents the average loss per car per year.\n - Note: Several of the attributes in the database could be used as a \"class\" attribute.\n The original data (from the UCI repository) (http://www.ics.uci.edu/~mlearn/MLSummary.html) has 205 instances\n described by 26 attributes :\n - 15 continuous\n - 1 integer\n - 10 nominal\n The following provides more information on these attributes:\n \n   1. symboling:                 -3, -2, -1, 0, 1, 2, 3.\n   2. normalized-losses:        continuous from 65 to 256.\n   3. make:                     alfa-romero, audi, bmw, chevrolet, dodge, honda,\n                                isuzu, jaguar, mazda, mercedes-benz, mercury,\n                                mitsubishi, nissan, peugot, plymouth, porsche,\n                                renault, saab, subaru, toyota, volkswagen, volvo\n   4. fuel-type:                diesel, gas.\n   5. aspiration:               std, turbo.\n   6. num-of-doors:             four, two.\n   7. body-style:               hardtop, wagon, sedan, hatchback,convertible.\n   8. drive-wheels:             4wd, fwd, rwd.\n   9. engine-location:          front, rear.\n  10. wheel-base:               continuous from 86.6 120.9.\n  11. length:                   continuous from 141.1 to 208.1.\n  12. width:                    continuous from 60.3 to 72.3.\n  13. height:                   continuous from 47.8 to 59.8.\n  14. curb-weight:              continuous from 1488 to 4066.\n  15. engine-type:              dohc, dohcv, l, ohc, ohcf, ohcv, rotor.\n  16. num-of-cylinders:         eight, five, four, six, three, twelve, two.\n  17. engine-size:              continuous from 61 to 326.\n  18. fuel-system:              1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.\n  19. bore:                     continuous from 2.54 to 3.94.\n  20. stroke:                   continuous from 2.07 to 4.17.\n  21. compression-ratio:        continuous from 7 to 23.\n  22. horsepower:               continuous from 48 to 288.\n  23. peak-rpm:                 continuous from 4150 to 6600.\n  24. city-mpg:                 continuous from 13 to 49.\n  25. highway-mpg:              continuous from 16 to 54.\n  26. price:                    continuous from 5118 to 45400.\n \n The original data also has some missing attribute values denoted by \"?\" : \n \n    Attribute #:   Number of instances missing a value:\n    2.             41\n    6.             2\n    19.            4\n    20.            4\n    22.            2\n    23.            2\n    26.            4\n \n I\'ve changed the original data in the following way :\n - All instances with unknowns were removed giving 159 instances.\n - The goal variable is \"price\"\n - All nominal attributes (10) were removed.\n \n Original source: UCI machine learning repository. (http://www.ics.uci.edu/~mlearn/MLSummary.html). \n Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\n http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\n Characteristics: 159 cases; 14 continuous variables; 1 nominal vars..', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:16:20', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3632/dataset_2181_auto_price.arff', 'true', 109, 'price', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:16:20'),
(110, 1, 0, 'autoMpg', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n Identifier attribute deleted.\n\n As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction\n using instance-based learning with encoding length selection. In Progress\n in Connectionist-Based Information Systems. Singapore: Springer-Verlag.\n\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n\n 1. Title: Auto-Mpg Data\n \n 2. Sources:\n    (a) Origin:  This dataset was taken from the StatLib library which is\n                 maintained at Carnegie Mellon University. The dataset was \n                 used in the 1983 American Statistical Association Exposition.\n    (c) Date: July 7, 1993\n \n 3. Past Usage:\n     -  See 2b (above)\n     -  Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning.\n        In Proceedings on the Tenth International Conference of Machine \n        Learning, 236-243, University of Massachusetts, Amherst. Morgan\n        Kaufmann.\n \n 4. Relevant Information:\n \n    This dataset is a slightly modified version of the dataset provided in\n    the StatLib library.  In line with the use by Ross Quinlan (1993) in\n    predicting the attribute \"mpg\", 8 of the original instances were removed \n    because they had unknown values for the \"mpg\" attribute.  The original \n    dataset is available in the file \"auto-mpg.data-original\".\n \n    \"The data concerns city-cycle fuel consumption in miles per gallon,\n     to be predicted in terms of 3 multivalued discrete and 5 continuous\n     attributes.\" (Quinlan, 1993)\n \n 5. Number of Instances: 398\n \n 6. Number of Attributes: 9 including the class attribute\n \n 7. Attribute Information:\n \n     1. mpg:           continuous\n     2. cylinders:     multi-valued discrete\n     3. displacement:  continuous\n     4. horsepower:    continuous\n     5. weight:        continuous\n     6. acceleration:  continuous\n     7. model year:    multi-valued discrete\n     8. origin:        multi-valued discrete\n     9. car name:      string (unique for each instance)\n \n 8. Missing Attribute Values:  horsepower has 6 missing values', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:16:22', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3633/dataset_2182_autoMpg.arff', 'true', 110, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:16:22'),
(111, 1, 0, 'cpu_act', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThe Computer Activity databases are a collection of computer systems\n activity measures. The data was collected from a Sun Sparcstation\n 20/712 with 128 Mbytes of memory running in a multi-user university\n department. Users would typically be doing a large variety of tasks\n ranging from accessing the internet, editing files or running very\n cpu-bound programs.  The data was collected continuously on two\n separate occasions. On both occassions, system activity was gathered\n every 5 seconds. The final dataset is taken from both occasions with\n equal numbers of observations coming from each collection epoch.\n \n System measures used:\n 1. lread - Reads (transfers per second ) between system memory and user memory.\n 2. lwrite - writes (transfers per second) between system memory and user memory.\n 3. scall - Number of system calls of all types per second.\n 4. sread - Number of system read calls per second.\n 5. swrite - Number of system write calls per second . \n 6. fork - Number of system fork calls per second. \n 7. exec - Number of system exec calls per second. \n 8. rchar - Number of characters transferred per second by system read calls.\n 9. wchar - Number of characters transfreed per second by system write calls. \n 10. pgout - Number of page out requests per second.\n 11. ppgout - Number of pages, paged out per second. \n 12. pgfree - Number of pages per second placed on the free list. \n 13. pgscan - Number of pages checked if they can be freed per second.\n 14. atch - Number of page attaches (satisfying a page fault by reclaiming a page in memory) per second.\n 15. pgin - Number of page-in requests per second.\n 16. ppgin - Number of pages paged in per second.\n 17. pflt - Number of page faults caused by protection errors (copy-on-writes). \n 18. vflt - Number of page faults caused by address translation. \n 19. runqsz - Process run queue size.\n 20. freemem - Number of memory pages available to user processes.\n 21. freeswap - Number of disk blocks available for page swapping. \n 22. usr - Portion of time (%) that cpus run in user mode.\n 23. sys - Portion of time (%) that cpus run in system mode.\n 24. wio - Portion of time (%) that cpus are idle waiting for block IO.\n 25. idle - Portion of time (%) that cpus are otherwise idle.\n \n The two different regression tasks obtained from these databases are:\n \n CompAct \n Predict usr, the portion of time that cpus run in user mode from all attributes 1-21.\n \n CompAct(s) \n Predict usr using a restricted number (excluding the paging information (10-18)\n \n Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\n http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\n Original source: DELVE repository of data. \n Characteristics: 8192 cases, 22 continuous attributes', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:16:32', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3634/dataset_2183_cpu_act.arff', 'true', 111, 'usr', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:16:32'),
(112, 1, 0, 'delta_elevators', '1', '1', '**Author**: Rui Camacho (rcamacho@garfield.fe.up.pt)  \n**Source**: [Regression datasets collection Luis Torgo](http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html)  \n**Please cite**:   \n\nThis data set is also obtained from the task of controlling the ailerons of a F16 aircraft, although the target variable and attributes are different from the ailerons domain. The target variable here is a variation instead of an absolute value, and there was some pre-selection of the attributes.', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:16:39', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/52348/openml_phpmlDSTj', 'true', 112, 'Se', NULL, NULL, NULL, 'public', NULL, NULL, 'set target feature', '2014-09-22 16:13:44'),
(113, 1, 0, 'fruitfly', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n Identifier attribute deleted.\n\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n NAME:  Sexual activity and the lifespan of male fruitflies\n TYPE:  Designed (almost factorial) experiment\n SIZE:  125 observations, 5 variables\n \n DESCRIPTIVE ABSTRACT:\n A cost of increased reproduction in terms of reduced longevity has been\n shown for female fruitflies, but not for males.  The flies used were an\n outbred stock.  Sexual activity was manipulated by supplying individual\n males with one or eight receptive virgin females per day.  The\n longevity of these males was compared with that of two control types.\n The first control consisted of two sets of individual males kept with\n one or eight newly inseminated females.  Newly inseminated females will\n not usually remate for at least two days, and thus served as a control\n for any effect of competition with the male for food or space.  The\n second control was a set of individual males kept with no females.\n There were 25 males in each of the five groups, which were treated\n identically in number of anaesthetizations (using CO2) and provision of\n fresh food medium.\n \n SOURCE:\n Figure 2 in the article \"Sexual Activity and the Lifespan of Male\n Fruitflies\" by Linda Partridge and Marion Farquhar.  _Nature_, 294,\n 580-581, 1981.\n \n VARIABLE DESCRIPTIONS:\n Columns  Variable    Description\n -------  --------    -----------\n  1- 2    ID          Serial No. (1-25) within each group of 25\n                      (the order in which data points were abstracted)\n \n  4       PARTNERS    Number of companions (0, 1 or 8)\n \n  6       TYPE        Type of companion\n                        0: newly pregnant female\n                        1: virgin female\n                        9: not applicable (when PARTNERS=0)\n \n  8- 9    LONGEVITY   Lifespan, in days\n \n 11-14    THORAX      Length of thorax, in mm (x.xx)\n \n 16-17    SLEEP       Percentage of each day spent sleeping\n \n \n SPECIAL NOTES:\n `Compliance\' of the males in the two experimental groups was documented\n as follows:  On two days per week throughout the life of each\n experimental male, the females that had been supplied as virgins to\n that male were kept and examined for fertile eggs.  The insemination\n rate declined from approximately 7 females/day at age one week to just\n under 2/day at age eight weeks in the males supplied with eight virgin\n females per day, and from just under 1/day at age one week to\n approximately 0.6/day at age eight weeks in the males supplied with one\n virgin female per day.  These `compliance\' data were not supplied for\n individual males, but the authors say that \"There were no significant\n differences between the individual males within each experimental\n group.\"\n \n STORY BEHIND THE DATA:\n James Hanley found this dataset in _Nature_ and was attracted by the\n way the raw data were presented in classical analysis of covariance\n style in Figure 2.  He read the data points from the graphs and brought\n them to the attention of a colleague with whom he was teaching the\n applied statistics course.  Dr. Liddell thought that with only three\n explanatory variables (THORAX, plus PARTNERS and TYPE to describe the\n five groups), it would not be challenging enough as a data-analysis\n project.  He suggested adding another variable.  James Hanley added\n SLEEP, a variable not mentioned in the published article.  Teachers can\n contact us about the construction of this variable.  (We prefer to\n divulge the details at the end of the data-analysis project.)\n \n Further discussion of the background and pedagogical use of this\n dataset can be found in Hanley (1983) and in Hanley and Shapiro\n (1994).  To obtain the Hanley and Shapiro article, send the one-line\n e-mail message:\n send jse/v2n1/datasets.hanley\n to the address archive@jse.stat.ncsu.edu\n \n PEDAGOGICAL NOTES:\n This has been the most successful and the most memorable dataset we\n have used in an \"applications of statistics\" course, which we have\n taught for ten years.  The most common analysis techniques have been\n analysis of variance, classical analysis of covariance, and multiple\n regression.  Because the variable THORAX is so strong (it explains\n about 1/3 of the variance in LONGEVITY), it is important to consider it\n to increase the precision of between-group contrasts.  When students\n first check and find that the distributions of thorax length, and in\n particular, the mean thorax length, are very similar in the different\n groups, many of them are willing to say (in epidemiological\n terminology) that THORAX is not a confounding variable, and that it can\n be omitted from the analysis.\n \n There is usually lively discussion about the primary contrast.  The\n five groups and their special structure allow opportunities for\n students to understand and verbalize what we mean by the term\n \"statistical interaction.\"\n \n There is also much debate as to whether one should take the SLEEP\n variable into account.  Some students say that it is an `intermediate\'\n variable.  Some students formally test the mean level of SLEEP across\n groups, find one pair where there is a statistically significant\n difference, and want to treat it as a confounding variable.  A few\n students muse about how it was measured.\n \n There is heteroscedasticity in the LONGEVITY variable.\n \n One very observant student (now a professor) argued that THORAX cannot\n be used as a predictor or explanatory variable for the LONGEVITY\n outcome since fruitflies who die young may not be fully grown, i.e., it\n is also an intermediate variable.  One Ph.D. student who had studied\n entomology assured us that fruitflies do not grow longer after birth;\n therefore, the THORAX length is not time-dependent!\n \n Curiously, the dataset has seldom been analyzed using techniques from\n survival analysis.  The fact that there are no censored observations is\n not really an excuse, and one could easily devise a way to introduce\n censoring of LONGEVITY.\n \n REFERENCES:\n Hanley, J. A. (1983), \"Appropriate Uses of Multivariate Analysis,\"\n _Annual Review of Public Health_, 4, 155-180.\n \n Hanley, J. A., and Shapiro, S. H. (1994), \"Sexual Activity and the\n Lifespan of Male Fruitflies:  A Dataset That Gets Attention,\" _Journal\n of Statistics Education_, Volume 2, Number 1.\n \n SUBMITTED BY:\n James A. Hanley and Stanley H. Shapiro\n Department of Epidemiology and Biostatistics\n McGill University\n 1020 Pine Avenue West\n Montreal, Quebec, H3A 1A2\n Canada\n tel: +1 (514) 398-6270 (JH) \n      +1 (514) 398-6272 (SS)\n fax: +1 (514) 398-4503\n INJH@musicb.mcgill.ca, StanS@epid.lan.mcgill.ca', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:16:42', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3636/dataset_2185_fruitfly.arff', 'true', 113, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:16:42'),
(114, 1, 0, 'pbc', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n Case number deleted. X treated as the class attribute.\n\n As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction\n using instance-based learning with encoding length selection. In Progress\n in Connectionist-Based Information Systems. Singapore: Springer-Verlag.\n\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n NAME:  PBC Data\n SIZE:  418 observations, 20 variables\n \n \n \n DESCRIPTIVE ABSTRACT:\n \n Below is a description of the variables recorded from the Mayo Clinic trial \n in primary biliary cirrhosis (PBC) of the liver conducted between 1974 and \n 1984.  A total of 424 PBC patients, referred to Mayo Clinic during\n that ten-year interval, met eligibility criteria for the randomized placebo \n controlled trial of the drug D-penicillamine. The first 312 cases in the data \n set participated in the randomized trial, and contain largely complete data. \n The additional 112 cases did not participate in the clinical trial, but \n consented to have basic measurements recorded and to be followed for survival.\n Six of those cases were lost to follow-up shortly after diagnosis, so there \n are data here on an additional 106 cases as well as the 312 randomized \n participants. Missing data items are denoted by \".\".  At least one space \n separates each variable in the .DAT file.  Censoring was due to liver \n transplantation for twenty-five subjects with the following case numbers: \n 5, 105, 111, 120, 125, 158, 183, 241, 246, 247, 254, 263, 264, 265, 274, \n 288, 291, 295, 297, 345, 361, 362, 375, 380, 383.\n \n \n \n SOURCE:  Counting Processes and Survival Analysis by T. Fleming & \n          D. Harrington, (1991),  published by John Wiley & Sons.\n \n \n \n VARIABLE DESCRIPTIONS:\n \n The data are in free format.  That is, at least one blank space separates\n each variable.  The variables contained in the .DAT are:\n \n \n N:   Case number.\n X:   The number of days between registration and the earlier of\n      death, liver transplantation, or study analysis time in July, 1986.\n D:   1 if X is time to death, 0 if time to censoring\n Z1:  Treatment Code, 1 = D-penicillamine, 2 = placebo.\n Z2:  Age in years. For the first 312 cases, age was calculated by\n      dividing the number of days between birth and study registration by 365.\n Z3:  Sex, 0 = male, 1 = female.\n Z4:  Presence of ascites, 0 = no, 1 = yes.\n Z5:  Presence of hepatomegaly, 0 = no, 1 = yes.\n Z6:  Presence of spiders 0 = no, 1 = Yes.\n Z7:  Presence of edema, 0 = no edema and no diuretic therapy for\n      edema; 0.5 = edema present for which no diuretic therapy was given, or \n      edema resolved with diuretic therapy; 1 = edema despite diuretic therapy\n Z8:  Serum bilirubin, in mg/dl.\n Z9:  Serum cholesterol, in mg/dl.\n Z10: Albumin, in gm/dl.\n Z11: Urine copper, in mg/day.\n Z12: Alkaline phosphatase, in U/liter.\n Z13: SGOT, in U/ml.\n Z14: Triglycerides, in mg/dl.\n Z15: Platelet count; coded value is number of platelets\n      per-cubic-milliliter of blood divided by 1000.\n Z16: Prothrombin time, in seconds.\n Z17: Histologic stage of disease, graded 1, 2, 3, or 4.\n \n \n \n \n STORY BEHIND THE DATA:\n \n Between January, 1974 and May, 1984, the Mayo Clinic conducted a\n double-blinded randomized trial in primary biliary cirrhosis of the liver\n (PBC), comparing the drug D-penicillamine (DPCA) with a placebo. There\n were 424 patients who met the eligibility criteria seen at the Clinic while\n the trial was open for patient registration. Both the treating physician and\n the patient agreed to participate in the randomized trial in 312 of the 424\n cases. The date of randomization and a large number of clinical, biochemical,\n serologic, and histologic parameters were recorded for each of the 312\n clinical trial patients. The data from the trial were analyzed in 1986 for\n presentation in the clinical literature. For that analysis, disease and \n survival status as of July, 1986, were recorded for as many patients as \n possible.  By that date, 125 of the 312 patients had died, with only 11 \n not attributable to PBC.  Eight patients had been lost to follow up, and 19 \n had undergone liver transplantation. \n \n PBC is a rare but fatal chronic liver disease of unknown cause,\n with a prevalence of about 50-cases-per-million population. The primary\n pathologic event appears to be the destruction of interlobular bile ducts,\n which may be mediated by immunologic mechanisms. The data discussed here are\n important in two respects. First, controlled clinical trials are difficult to\n complete in rare diseases, and this case series of patients uniformly\n diagnosed, treated, and followed is the largest existing for PBC. The\n treatment comparison in this trial is more precise than in similar trials\n having fewer participants and avoids the bias that may arise in comparing\n a case series to historical controls. Second, the data present an\n opportunity to study the natural history of the disease. We will see that, \n despite the immunosuppressive properties of DPCA, there are no detectable\n differences between the distributions of survival times for the DPCA and\n placebo treatment groups. This suggests that these groups can be combined\n in studying the association between survival time from randomization and\n clinical and other measurements. In the early to mid 1980s, the rate of \n successful liver transplant increased substantially, and transplant has \n become an effective therapy for PBC. The Mayo Clinic data set is therefore \n one of the last allowing a study of the natural history of PBC in patients \n who were treated with only supportive care or its equivalent. The PBC data \n can be used to: estimate a survival distribution; test for differences \n between two groups; and estimate covariate effects via a regression\n model.', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:16:46', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3637/dataset_2186_pbc.arff', 'true', 114, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:16:46'),
(115, 1, 0, 'pol', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThis is a commercial application described in Weiss & Indurkhya (1995). \n The data describes a telecommunication problem. No further information\n is available.\n \n Characteristics: (10000+5000) cases, 49 continuous attributes \n Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\n http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\n Original Source: The data in the original format can be obtained \n from http://www.cs.su.oz.au/~nitin', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:17:01', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3638/dataset_2187_pol.arff', 'true', 115, 'foo', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:17:01'),
(116, 1, 0, 'autoHorse', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n Horsepower treated as the class attribute.\n\n As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction\n using instance-based learning with encoding length selection. In Progress\n in Connectionist-Based Information Systems. Singapore: Springer-Verlag.\n\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n 1. Title: 1985 Auto Imports Database\n \n 2. Source Information:\n    -- Creator/Donor: Jeffrey C. Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)\n    -- Date: 19 May 1987\n    -- Sources:\n      1) 1985 Model Import Car and Truck Specifications, 1985 Ward\'s\n         Automotive Yearbook.\n      2) Personal Auto Manuals, Insurance Services Office, 160 Water\n         Street, New York, NY 10038 \n      3) Insurance Collision Report, Insurance Institute for Highway\n         Safety, Watergate 600, Washington, DC 20037\n\n 3. Past Usage:\n    -- Kibler,~D., Aha,~D.~W., & Albert,~M. (1989).  Instance-based prediction\n       of real-valued attributes.  {it Computational Intelligence}, {it 5},\n       51--57.\n          -- Predicted price of car using all numeric and Boolean attributes\n          -- Method: an instance-based learning (IBL) algorithm derived from a\n             localized k-nearest neighbor algorithm.  Compared with a\n             linear regression prediction...so all instances\n             with missing attribute values were discarded.  This resulted with\n             a training set of 159 instances, which was also used as a test\n             set (minus the actual instance during testing).\n          -- Results: Percent Average Deviation Error of Prediction from Actual\n             -- 11.84% for the IBL algorithm\n             -- 14.12% for the resulting linear regression equation\n \n 4. Relevant Information:\n    -- Description\n       This data set consists of three types of entities: (a) the\n       specification of an auto in terms of various characteristics, (b)\n       its assigned insurance risk rating, (c) its normalized losses in use\n       as compared to other cars.  The second rating corresponds to the\n       degree to which the auto is more risky than its price indicates.\n       Cars are initially assigned a risk factor symbol associated with its\n       price.   Then, if it is more risky (or less), this symbol is\n       adjusted by moving it up (or down) the scale.  Actuarians call this\n       process \"symboling\".  A value of +3 indicates that the auto is\n       risky, -3 that it is probably pretty safe.\n \n       The third factor is the relative average loss payment per insured\n       vehicle year.  This value is normalized for all autos within a\n       particular size classification (two-door small, station wagons,\n       sports/speciality, etc...), and represents the average loss per car\n       per year.\n \n    -- Note: Several of the attributes in the database could be used as a\n             \"class\" attribute.\n \n 5. Number of Instances: 205\n \n 6. Number of Attributes: 26 total\n    -- 15 continuous\n    -- 1 integer\n    -- 10 nominal\n \n 7. Attribute Information:     \n      Attribute:                Attribute Range:\n      ------------------        -----------------------------------------------\n   1. symboling:                -3, -2, -1, 0, 1, 2, 3.\n   2. normalized-losses:        continuous from 65 to 256.\n   3. make:                     alfa-romero, audi, bmw, chevrolet, dodge, honda,\n                                isuzu, jaguar, mazda, mercedes-benz, mercury,\n                                mitsubishi, nissan, peugot, plymouth, porsche,\n                                renault, saab, subaru, toyota, volkswagen, volvo\n   4. fuel-type:                diesel, gas.\n   5. aspiration:               std, turbo.\n   6. num-of-doors:             four, two.\n   7. body-style:               hardtop, wagon, sedan, hatchback, convertible.\n   8. drive-wheels:             4wd, fwd, rwd.\n   9. engine-location:          front, rear.\n  10. wheel-base:               continuous from 86.6 120.9.\n  11. length:                   continuous from 141.1 to 208.1.\n  12. width:                    continuous from 60.3 to 72.3.\n  13. height:                   continuous from 47.8 to 59.8.\n  14. curb-weight:              continuous from 1488 to 4066.\n  15. engine-type:              dohc, dohcv, l, ohc, ohcf, ohcv, rotor.\n  16. num-of-cylinders:         eight, five, four, six, three, twelve, two.\n  17. engine-size:              continuous from 61 to 326.\n  18. fuel-system:              1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.\n  19. bore:                     continuous from 2.54 to 3.94.\n  20. stroke:                   continuous from 2.07 to 4.17.\n  21. compression-ratio:        continuous from 7 to 23.\n  22. horsepower:               continuous from 48 to 288.\n  23. peak-rpm:                 continuous from 4150 to 6600.\n  24. city-mpg:                 continuous from 13 to 49.\n  25. highway-mpg:              continuous from 16 to 54.\n  26. price:                    continuous from 5118 to 45400.\n \n 8. Missing Attribute Values: (denoted by \"?\")\n    Attribute #:   Number of instances missing a value:\n    2.             41\n    6.             2\n    19.            4\n    20.            4\n    22.            2\n    23.            2\n    26.            4%', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:17:04', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3639/dataset_2188_autoHorse.arff', 'true', 116, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:17:04'),
(117, 1, 0, 'lowbwt', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n Identification code deleted. \n\n As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction\n using instance-based learning with encoding length selection. In Progress\n in Connectionist-Based Information Systems. Singapore: Springer-Verlag.\n\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n NAME:  LOW BIRTH WEIGHT DATA\n KEYWORDS:  Logistic Regression\n SIZE:  189 observations, 11 variables\n \n NOTE:\n         These data come from Appendix 1 of Hosmer and Lemeshow (1989).\n These data are copyrighted and must be acknowledged and used accordingly.\n \n DESCRIPTIVE ABSTRACT:\n         The goal of this study was to identify risk factors associated with\n giving birth to a low birth weight baby (weighing less than 2500 grams).\n Data were collected on 189 women, 59 of which had low birth weight babies\n and 130 of which had normal birth weight babies.  Four variables which were\n thought to be of importance were age, weight of the subject at her last\n menstrual period, race, and the number of physician visits during the first\n trimester of pregnancy.\n \n \n SOURCE:\n          Data were collected at Baystate Medical Center, Springfield,\n Massachusetts, during 1986.\n \n \n NOTE:\n           This data set consists of the complete data.  A paired data set\n created from this low birth weight data may be found in plowbwt.dat and\n a 3 to 1 matched data set created from the low birth weight data may be\n found in mlowbwt.dat.\n \n \n \n Table:  Code Sheet for the Variables in the Low Birth Weight Data Set.\n \n Columns   Variable                                              Abbreviation\n -----------------------------------------------------------------------------\n 2-4     Identification Code                                     ID\n    \n 10      Low Birth Weight (0 = Birth Weight ge 2500g,            LOW\n                           l = Birth Weight < 2500g)\n   \n 17-18   Age of the Mother in Years                              AGE\n      \n 23-25   Weight in Pounds at the Last Menstrual Period           LWT\n      \n 32      Race (1 = White, 2 = Black, 3 = Other)                  RACE\n      \n 40      Smoking Status During Pregnancy (1 = Yes, 0 = No)       SMOKE\n      \n 48      History of Premature Labor (0 = None, 1 = One, etc.)    PTL\n      \n 55      History of Hypertension (1 = Yes, 0 = No)               HT\n      \n 61      Presence of Uterine Irritability (1 = Yes, 0 = No)      UI\n      \n 67      Number of Physician Visits During the First Trimester   FTV\n                 (0 = None, 1 = One, 2 = Two, etc.)\n      \n 73-76   Birth Weight in Grams                                   BWT\n -----------------------------------------------------------------------------\n \n PEDAGOGICAL NOTES:\n         These data have been used as an example of fitting a multiple\n logistic regression model.\n \n STORY BEHIND THE DATA:\n         Low birth weight is an outcome that has been of concern to physicians\n for years. This is due to the fact that infant mortality rates and birth\n defect rates are very high for low birth weight babies. A woman\'s behavior\n during pregnancy (including diet, smoking habits, and receiving prenatal care)\n can greatly alter the chances of carrying the baby to term and, consequently,\n of delivering a baby of normal birth weight.\n         The variables identified in the code sheet given in the table have been\n shown to be associated with low birth weight in the obstetrical literature. The\n goal of the current study was to ascertain if these variables were important\n in the population being served by the medical center where the data were\n collected.\n \n \n References:\n \n 1. Hosmer and Lemeshow, Applied Logistic Regression, Wiley, (1989).', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:17:07', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3640/dataset_2189_lowbwt.arff', 'true', 117, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:17:07'),
(118, 1, 0, 'cholesterol', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n Cholesterol treated as the class attribute.\n\n As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction\n using instance-based learning with encoding length selection. In Progress\n in Connectionist-Based Information Systems. Singapore: Springer-Verlag.\n\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n Publication Request: \n    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n    This file describes the contents of the heart-disease directory.\n \n    This directory contains 4 databases concerning heart disease diagnosis.\n    All attributes are numeric-valued.  The data was collected from the\n    four following locations:\n \n      1. Cleveland Clinic Foundation (cleveland.data)\n      2. Hungarian Institute of Cardiology, Budapest (hungarian.data)\n      3. V.A. Medical Center, Long Beach, CA (long-beach-va.data)\n      4. University Hospital, Zurich, Switzerland (switzerland.data)\n \n    Each database has the same instance format.  While the databases have 76\n    raw attributes, only 14 of them are actually used.  Thus I\'ve taken the\n    liberty of making 2 copies of each database: one with all the attributes\n    and 1 with the 14 attributes actually used in past experiments.\n \n    The authors of the databases have requested:\n \n       ...that any publications resulting from the use of the data include the \n       names of the principal investigator responsible for the data collection\n       at each institution.  They would be:\n \n        1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n        2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n        3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n        4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:\n           Robert Detrano, M.D., Ph.D.\n \n    Thanks in advance for abiding by this request.\n \n    David Aha\n    July 22, 1988\n    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n \n 1. Title: Heart Disease Databases\n \n 2. Source Information:\n    (a) Creators: \n        -- 1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n        -- 2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n        -- 3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n        -- 4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:\n              Robert Detrano, M.D., Ph.D.\n    (b) Donor: David W. Aha (aha@ics.uci.edu) (714) 856-8779   \n    (c) Date: July, 1988\n \n 3. Past Usage:\n     1. Detrano,~R., Janosi,~A., Steinbrunn,~W., Pfisterer,~M., Schmid,~J.,\n        Sandhu,~S., Guppy,~K., Lee,~S., & Froelicher,~V. (1989).  {it \n        International application of a new probability algorithm for the \n        diagnosis of coronary artery disease.}  {it American Journal of \n        Cardiology}, {it 64},304--310.\n        -- International Probability Analysis \n        -- Address: Robert Detrano, M.D.\n                    Cardiology 111-C\n                    V.A. Medical Center\n                    5901 E. 7th Street\n                    Long Beach, CA 90028\n        -- Results in percent accuracy: (for 0.5 probability threshold)\n              Data Name:  CDF    CADENZA\n           -- Hungarian   77     74\n              Long beach  79     77\n              Swiss       81     81\n           -- Approximately a 77% correct classification accuracy with a\n              logistic-regression-derived discriminant function\n     2. David W. Aha & Dennis Kibler\n        -- \n           \n           \n           -- Instance-based prediction of heart-disease presence with the \n              Cleveland database\n              -- NTgrowth: 77.0% accuracy\n              --       C4: 74.8% accuracy\n     3. John Gennari\n        -- Gennari, J.~H., Langley, P, & Fisher, D. (1989). Models of\n           incremental concept formation. {it Artificial Intelligence, 40},\n           11--61.\n        -- Results: \n           -- The CLASSIT conceptual clustering system achieved a 78.9% accuracy\n              on the Cleveland database.\n \n 4. Relevant Information:\n      This database contains 76 attributes, but all published experiments\n      refer to using a subset of 14 of them.  In particular, the Cleveland\n      database is the only one that has been used by ML researchers to \n      this date.  The \"goal\" field refers to the presence of heart disease\n      in the patient.  It is integer valued from 0 (no presence) to 4.\n      Experiments with the Cleveland database have concentrated on simply\n      attempting to distinguish presence (values 1,2,3,4) from absence (value\n      0).  \n    \n      The names and social security numbers of the patients were recently \n      removed from the database, replaced with dummy values.\n \n      One file has been \"processed\", that one containing the Cleveland \n      database.  All four unprocessed files also exist in this directory.\n     \n 5. Number of Instances: \n         Database:    # of instances:\n           Cleveland: 303\n           Hungarian: 294\n         Switzerland: 123\n       Long Beach VA: 200\n \n 6. Number of Attributes: 76 (including the predicted attribute)\n \n 7. Attribute Information:\n    -- Only 14 used\n       -- 1. #3  (age)       \n       -- 2. #4  (sex)       \n       -- 3. #9  (cp)        \n       -- 4. #10 (trestbps)  \n       -- 5. #12 (chol)      \n       -- 6. #16 (fbs)       \n       -- 7. #19 (restecg)   \n       -- 8. #32 (thalach)   \n       -- 9. #38 (exang)     \n       -- 10. #40 (oldpeak)   \n       -- 11. #41 (slope)     \n       -- 12. #44 (ca)        \n       -- 13. #51 (thal)      \n       -- 14. #58 (num)       (the predicted attribute)\n \n    -- Complete attribute documentation:\n       1 id: patient identification number\n       2 ccf: social security number (I replaced this with a dummy value of 0)\n       3 age: age in years\n       4 sex: sex (1 = male; 0 = female)\n       5 painloc: chest pain location (1 = substernal; 0 = otherwise)\n       6 painexer (1 = provoked by exertion; 0 = otherwise)\n       7 relrest (1 = relieved after rest; 0 = otherwise)\n       8 pncaden (sum of 5, 6, and 7)\n       9 cp: chest pain type\n         -- Value 1: typical angina\n         -- Value 2: atypical angina\n         -- Value 3: non-anginal pain\n         -- Value 4: asymptomatic\n      10 trestbps: resting blood pressure (in mm Hg on admission to the \n         hospital)\n      11 htn\n      12 chol: serum cholestoral in mg/dl\n      13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)\n      14 cigs (cigarettes per day)\n      15 years (number of years as a smoker)\n      16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n      17 dm (1 = history of diabetes; 0 = no such history)\n      18 famhist: family history of coronary artery disease (1 = yes; 0 = no)\n      19 restecg: resting electrocardiographic results\n         -- Value 0: normal\n         -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST \n                     elevation or depression of > 0.05 mV)\n         -- Value 2: showing probable or definite left ventricular hypertrophy\n                     by Estes\' criteria\n      20 ekgmo (month of exercise ECG reading)\n      21 ekgday(day of exercise ECG reading)\n      22 ekgyr (year of exercise ECG reading)\n      23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)\n      24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)\n      25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)\n      26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)\n      27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)\n      28 proto: exercise protocol\n           1 = Bruce     \n           2 = Kottus\n           3 = McHenry\n           4 = fast Balke\n           5 = Balke\n           6 = Noughton \n           7 = bike 150 kpa min/min  (Not sure if \"kpa min/min\" is what was \n               written!)\n           8 = bike 125 kpa min/min  \n           9 = bike 100 kpa min/min\n          10 = bike 75 kpa min/min\n          11 = bike 50 kpa min/min\n          12 = arm ergometer\n      29 thaldur: duration of exercise test in minutes\n      30 thaltime: time when ST measure depression was noted\n      31 met: mets achieved\n      32 thalach: maximum heart rate achieved\n      33 thalrest: resting heart rate\n      34 tpeakbps: peak exercise blood pressure (first of 2 parts)\n      35 tpeakbpd: peak exercise blood pressure (second of 2 parts)\n      36 dummy\n      37 trestbpd: resting blood pressure\n      38 exang: exercise induced angina (1 = yes; 0 = no)\n      39 xhypo: (1 = yes; 0 = no)\n      40 oldpeak = ST depression induced by exercise relative to rest\n      41 slope: the slope of the peak exercise ST segment\n         -- Value 1: upsloping\n         -- Value 2: flat\n         -- Value 3: downsloping\n      42 rldv5: height at rest\n      43 rldv5e: height at peak exercise\n      44 ca: number of major vessels (0-3) colored by flourosopy\n      45 restckm: irrelevant\n      46 exerckm: irrelevant\n      47 restef: rest raidonuclid (sp?) ejection fraction\n      48 restwm: rest wall (sp?) motion abnormality\n         0 = none\n         1 = mild or moderate\n         2 = moderate or severe\n         3 = akinesis or dyskmem (sp?)\n      49 exeref: exercise radinalid (sp?) ejection fraction\n      50 exerwm: exercise wall (sp?) motion \n      51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n      52 thalsev: not used\n      53 thalpul: not used\n      54 earlobe: not used\n      55 cmo: month of cardiac cath (sp?)  (perhaps \"call\")\n      56 cday: day of cardiac cath (sp?)\n      57 cyr: year of cardiac cath (sp?)\n      58 num: diagnosis of heart disease (angiographic disease status)\n         -- Value 0: < 50% diameter narrowing\n         -- Value 1: > 50% diameter narrowing\n         (in any major vessel: attributes 59 through 68 are vessels)\n      59 lmt\n      60 ladprox\n      61 laddist\n      62 diag\n      63 cxmain\n      64 ramus\n      65 om1\n      66 om2\n      67 rcaprox\n      68 rcadist\n      69 lvx1: not used\n      70 lvx2: not used\n      71 lvx3: not used\n      72 lvx4: not used\n      73 lvf: not used\n      74 cathef: not used\n      75 junk: not used\n      76 name: last name of patient \n         (I replaced this with the dummy string \"name\")\n \n 9. Missing Attribute Values: Several.  Distinguished with value -9.0.\n \n 10. Class Distribution:\n         Database:      0   1   2   3   4 Total\n           Cleveland: 164  55  36  35  13   303\n           Hungarian: 188  37  26  28  15   294\n         Switzerland:   8  48  32  30   5   123\n       Long Beach VA:  51  56  41  42  10   200', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:17:10', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3641/dataset_2190_cholesterol.arff', 'true', 118, 'chol', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:17:10'),
(119, 1, 0, 'sleep', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nData from StatLib (ftp stat.cmu.edu/datasets)\n\n Data from which conclusions  were  drawn  in  the  article  \"Sleep  in \n Mammals: Ecological and Constitutional Correlates\" by Allison, T.  and \n Cicchetti, D. (1976), _Science_, November 12, vol. 194,  pp.  732-734. \n Includes brain and body  weight,  life  span,  gestation  time,  time \n sleeping, and predation and danger indices for 62 mammals.\n \n \n \n Variables below (from left to right) for Mammals Data Set:\n \n species of animal\n \n body weight in kg\n \n brain weight in g\n \n slow wave (\"nondreaming\") sleep (hrs/day)\n \n paradoxical (\"dreaming\") sleep (hrs/day)\n \n total sleep (hrs/day)  (sum of slow wave and paradoxical sleep)\n \n maximum life span (years)\n \n gestation time (days)\n \n predation index (1-5)\n                 1 = minimum (least likely to be preyed upon)\n                 5 = maximum (most likely to be preyed upon)\n \n sleep exposure index (1-5)\n                 1 = least exposed (e.g. animal sleeps in a \n                     well-protected den)\n                 5 = most exposed\n \n overall danger index (1-5)\n                 (based on the above two indices and other information)\n                 1 = least danger (from other animals)\n                 5 = most danger (from other animals)\n \n Note: Missing values denoted by -999.0\n \n \n For more details, see\n \n Allison, Truett and Cicchetti, Domenic V. (1976), \"Sleep  in  Mammals: \n Ecological and Constitutional  Correlates\",  _Science_,  November  12, \n vol. 194, pp. 732-734.\n \n The above data set can be freely used for non-commercial purposes  and \n can be freely distributed (permission in  writing  obtained  from  Dr. \n Truett Allison).\n \n Submitted by Roger Johnson\n rwjohnso@silver.sdsmt.edu\n\n Total sleep treated as the class attribute. Attributes for slow\n wave and paradoxical sleep have been deleted. (The animal\'s\n name has also been deleted.)', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:17:12', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3642/dataset_2191_sleep.arff', 'true', 119, 'danger_index', NULL, NULL, NULL, 'public', NULL, NULL, 'corrected target', '2014-10-06 22:07:54'),
(120, 1, 0, 'triazines', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThe problem is to learn a regression equation/rule/tree to predict the\n activity from the descriptive structural attributes.  The data and\n methodology is described in detail in: - King, Ross .D., Hurst,\n Jonathan. D., and Sternberg, Michael.J.E. A comparison of artificial\n intelligence methods for modelling QSARs Applied Artificial\n Intelligence, 1994 (in press).  - Hurst, Jonathan. D., King, Ross\n .D. and Sternberg, Michael.J.E. Quantitative Structure-Activity\n Relationships by neural networks and inductive logic programming:\n 2. The inhibition of dihydrofolate reductase by triazines. Journal of\n Computer Aided Molecular Design, 1994 (in press).\n \n Original source: ?. \n Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\n http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\n Characteristics: 186 cases; 61 continuous variables', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:17:16', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3643/dataset_2192_triazines.arff', 'true', 120, 'activity', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:17:16'),
(121, 1, 0, 'autoPrice', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n All nominal attributes and instances with missing values are deleted.\n Price treated as the class attribute.\n\n As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction\n using instance-based learning with encoding length selection. In Progress\n in Connectionist-Based Information Systems. Singapore: Springer-Verlag.\n\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n 1. Title: 1985 Auto Imports Database\n \n 2. Source Information:\n    -- Creator/Donor: Jeffrey C. Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)\n    -- Date: 19 May 1987\n    -- Sources:\n      1) 1985 Model Import Car and Truck Specifications, 1985 Ward\'s\n         Automotive Yearbook.\n      2) Personal Auto Manuals, Insurance Services Office, 160 Water\n         Street, New York, NY 10038 \n      3) Insurance Collision Report, Insurance Institute for Highway\n         Safety, Watergate 600, Washington, DC 20037\n\n 3. Past Usage:\n    -- Kibler,~D., Aha,~D.~W., & Albert,~M. (1989).  Instance-based prediction\n       of real-valued attributes.  {it Computational Intelligence}, {it 5},\n       51--57.\n          -- Predicted price of car using all numeric and Boolean attributes\n          -- Method: an instance-based learning (IBL) algorithm derived from a\n             localized k-nearest neighbor algorithm.  Compared with a\n             linear regression prediction...so all instances\n             with missing attribute values were discarded.  This resulted with\n             a training set of 159 instances, which was also used as a test\n             set (minus the actual instance during testing).\n          -- Results: Percent Average Deviation Error of Prediction from Actual\n             -- 11.84% for the IBL algorithm\n             -- 14.12% for the resulting linear regression equation\n \n 4. Relevant Information:\n    -- Description\n       This data set consists of three types of entities: (a) the\n       specification of an auto in terms of various characteristics, (b)\n       its assigned insurance risk rating, (c) its normalized losses in use\n       as compared to other cars.  The second rating corresponds to the\n       degree to which the auto is more risky than its price indicates.\n       Cars are initially assigned a risk factor symbol associated with its\n       price.   Then, if it is more risky (or less), this symbol is\n       adjusted by moving it up (or down) the scale.  Actuarians call this\n       process \"symboling\".  A value of +3 indicates that the auto is\n       risky, -3 that it is probably pretty safe.\n \n       The third factor is the relative average loss payment per insured\n       vehicle year.  This value is normalized for all autos within a\n       particular size classification (two-door small, station wagons,\n       sports/speciality, etc...), and represents the average loss per car\n       per year.\n \n    -- Note: Several of the attributes in the database could be used as a\n             \"class\" attribute.\n \n 5. Number of Instances: 205\n \n 6. Number of Attributes: 26 total\n    -- 15 continuous\n    -- 1 integer\n    -- 10 nominal\n \n 7. Attribute Information:     \n      Attribute:                Attribute Range:\n      ------------------        -----------------------------------------------\n   1. symboling:                -3, -2, -1, 0, 1, 2, 3.\n   2. normalized-losses:        continuous from 65 to 256.\n   3. make:                     alfa-romero, audi, bmw, chevrolet, dodge, honda,\n                                isuzu, jaguar, mazda, mercedes-benz, mercury,\n                                mitsubishi, nissan, peugot, plymouth, porsche,\n                                renault, saab, subaru, toyota, volkswagen, volvo\n   4. fuel-type:                diesel, gas.\n   5. aspiration:               std, turbo.\n   6. num-of-doors:             four, two.\n   7. body-style:               hardtop, wagon, sedan, hatchback, convertible.\n   8. drive-wheels:             4wd, fwd, rwd.\n   9. engine-location:          front, rear.\n  10. wheel-base:               continuous from 86.6 120.9.\n  11. length:                   continuous from 141.1 to 208.1.\n  12. width:                    continuous from 60.3 to 72.3.\n  13. height:                   continuous from 47.8 to 59.8.\n  14. curb-weight:              continuous from 1488 to 4066.\n  15. engine-type:              dohc, dohcv, l, ohc, ohcf, ohcv, rotor.\n  16. num-of-cylinders:         eight, five, four, six, three, twelve, two.\n  17. engine-size:              continuous from 61 to 326.\n  18. fuel-system:              1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.\n  19. bore:                     continuous from 2.54 to 3.94.\n  20. stroke:                   continuous from 2.07 to 4.17.\n  21. compression-ratio:        continuous from 7 to 23.\n  22. horsepower:               continuous from 48 to 288.\n  23. peak-rpm:                 continuous from 4150 to 6600.\n  24. city-mpg:                 continuous from 13 to 49.\n  25. highway-mpg:              continuous from 16 to 54.\n  26. price:                    continuous from 5118 to 45400.\n \n 8. Missing Attribute Values: (denoted by \"?\")\n    Attribute #:   Number of instances missing a value:\n    2.             41\n    6.             2\n    19.            4\n    20.            4\n    22.            2\n    23.            2\n    26.            4%', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:17:18', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3644/dataset_2193_autoPrice.arff', 'true', 121, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:17:18'),
(122, 1, 0, 'detroit', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nData from StatLib (ftp stat.cmu.edu/datasets)\n\n This is the data set called `DETROIT\' in the book `Subset selection in\n regression\' by Alan J. Miller published in the Chapman & Hall series of\n monographs on Statistics & Applied Probability, no. 40.   The data are\n unusual in that a subset of three predictors can be found which gives a\n very much better fit to the data than the subsets found from the Efroymson\n stepwise algorithm, or from forward selection or backward elimination.\n \n The original data were given in appendix A of `Regression analysis and its\n application: A data-oriented approach\' by Gunst & Mason, Statistics\n textbooks and monographs no. 24, Marcel Dekker.   It has caused problems\n because some copies of the Gunst & Mason book do not contain all of the data,\n and because Miller does not say which variables he used as predictors and\n which is the dependent variable.   (HOM was the dependent variable, and the\n predictors were FTP ... WE)\n \n The data were collected by J.C. Fisher and used in his paper: \"Homicide in\n Detroit: The Role of Firearms\", Criminology, vol.14, 387-400 (1976)\n \n \n The data are on the homicide rate in Detroit for the years 1961-1973.\n FTP    - Full-time police per 100,000 population\n UEMP   - %  unemployed in the population\n MAN    - number of manufacturing workers in thousands\n LIC    - Number of handgun licences per 100,000 population\n GR     - Number of handgun registrations per 100,000 population\n CLEAR  - %  homicides cleared by arrests\n WM     - Number of white males in the population\n NMAN   - Number of non-manufacturing workers in thousands\n GOV    - Number of government workers in thousands\n HE     - Average hourly earnings\n WE     - Average weekly earnings\n \n HOM    - Number of homicides per 100,000 of population\n ACC    - Death rate in accidents per 100,000 population\n ASR    - Number of assaults per 100,000 population\n \n N.B. Each case takes two lines.', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:17:21', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3645/dataset_2194_detroit.arff', 'true', 122, 'ASR', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:17:21'),
(123, 1, 0, 'quake', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nDataset from Smoothing Methods in Statistics \n (ftp stat.cmu.edu/datasets)\n\n Simonoff, J.S. (1996). Smoothing Methods in Statistics. New York: Springer-Verlag.', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:17:24', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3646/dataset_2195_quake.arff', 'true', 123, 'richter', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:17:24'),
(124, 1, 0, 'cloud', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nData from StatLib (ftp stat.cmu.edu/datasets)\n\n These data are those collected in a cloud-seeding experiment in Tasmania\n between mid-1964 and January 1971.   Their analysis, using regression\n techniques and permutation tests, is discussed in:\n \n       Miller, A.J., Shaw, D.E., Veitch, L.G. & Smith, E.J. (1979).\n       `Analyzing the results of a cloud-seeding experiment in Tasmania\',\n       Communications in Statistics - Theory & Methods, vol.A8(10),\n       1017-1047.\n \n The rainfalls are period rainfalls in inches.   TE and TW are the east and\n west target areas respectively, while NC, SC and NWC are the corresponding\n rainfalls in the north, south and north-west control areas respectively.\n S = seeded, U = unseeded.\n\n Rain in eastern target region is being treated\n as the class attribute. (Attribute for rain\n in the western target region has been deleted.)', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:17:26', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3647/dataset_2196_cloud.arff', 'true', 124, 'TE', 'period', NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:17:26'),
(125, 1, 0, 'longley', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nData from StatLib (ftp stat.cmu.edu/datasets)\n\n The infamous Longley data, \"An appraisal of least-squares programs from\n  the point of view of the user\", JASA, 62(1967) p819-841.\n\n Variables are: Number of people employed   (usually the y variable)\n                GNP implicit price deflator\n                GNP\n                Unemployed\n                Armed forces\n                Non-institutionalized population >=14 years of age\n                Year\n\n Employment is being treated as the class\n attribute.', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:17:28', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3648/dataset_2197_longley.arff', 'true', 125, 'employed', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:17:28'),
(126, 1, 0, 'diabetes_numeric', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThis data set concerns the study of the factors affecting patterns of\n insulin-dependent diabetes mellitus in children.  The objective is to\n investigate the dependence of the level of serum C-peptide on the\n various other factors in order to understand the patterns of residual\n insulin secretion. The response measurement is the logarithm of\n C-peptide concentration (pmol/ml) at the diagnosis, and the predictor\n measurements age and base deficit, a measure of acidity.\n\n Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\n http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\n Original source: Book Generalized Additive Models (p.304) by Hastie &\n Tibshirani, Chapman & Hall.  \n Characteristics: 43 cases; 3 continuous variables', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:17:30', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3649/dataset_2198_diabetes_numeric.arff', 'true', 126, 'c_peptide', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2014-04-23 13:17:30'),
(127, 1, 0, 'pharynx', '1', '1', '**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n Case number deleted. \n\n As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction\n using instance-based learning with encoding length selection. In Progress\n in Connectionist-Based Information Systems. Singapore: Springer-Verlag.\n\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n Name:  Pharynx (A clinical Trial in the Trt. of Carcinoma of the Oropharynx).\n SIZE:  195 observations, 13 variables.\n \n \n \n DESCRIPTIVE ABSTRACT:\n \n The .dat file gives the data for a part of a large clinical trial\n carried out by the Radiation Therapy Oncology Group in the United States. \n The full study included patients with squamous carcinoma of 15 sites in \n the mouth and throat, with 16 participating institutions, though only data \n on three sites in the oropharynx reported by the six largest institutions \n are considered here. Patients entering the study were randomly assigned to \n one of two treatment groups, radiation therapy alone or radiation therapy \n together with a chemotherapeutic agent.  One objective of the study was to \n compare the two treatment policies with respect to patient survival.\n \n \n \n SOURCE:  The Statistical Analysis of Failure Time Data, by JD Kalbfleisch\n          & RL Prentice, (1980),  Published by John Wiley & Sons \n \n \n \n VARIABLE DESCRIPTIONS:\n \n The data are in free format.  That is, at least one blank space separates \n each variable in the .dat file.  The variables are as follows:\n \n \n Case:         Case Number\n Inst:         Participating Institution\n sex:          1=male, 2=female\n Treatment:    1=standard, 2=test\n Grade:        1=well differentiated, 2=moderately differentiated, \n               3=poorly differentiated,  9=missing\n Age:          In years at time of diagnosis\n Condition:    1=no disability, 2=restricted work, 3=requires assistance with\n               self care, 4=bed confined,  9=missing\n Site:         1=faucial arch, 2=tonsillar fossa, 3=posterior pillar,\n               4=pharyngeal tongue, 5=posterior wall\n T staging:    1=primary tumor measuring 2 cm or less in largest diameter,\n               2=primary tumor measuring 2 cm to 4 cm in largest diameter with\n               minimal infiltration in depth, 3=primary tumor measuring more \n               than 4 cm, 4=massive invasive tumor\n N staging:    0=no clinical evidence of node metastases, 1=single positive\n               node 3 cm or less in diameter, not fixed, 2=single positive\n               node more than 3 cm in diameter, not fixed, 3=multiple\n               positive nodes or fixed positive nodes \n Entry Date:   Date of study entry: Day of year and year\n Status:       0=censored,  1=dead\n Time:         Survival time in days from day of diagnosis \n \n \n \n \n \n \n STORY BEHIND THE DATA:\n \n Approximately 30% of the survival times are censored owing primarily to \n patients surviving to the time of analysis. Some patients were lost\n to follow-up because the patient moved or transferred to an institution not\n participating in the study, though these cases were relatively rare. From \n a statistical point of view, an important feature of these data is the \n considerable lack of homogeneity between individuals being studied. \n Of course, as part of the study design, certain criteria for patient \n eligibility had to be met which eliminated extremes in the extent of disease, \n but still many factors are not controlled.\n \n This study included measurements of many covariates which would be expected \n to relate to survival experience. Six such variables are given in the data \n (sex, T staging, N staging, age, general condition, and grade).   The site \n of the primary tumor and possible differences between participating \n institutions require consideration as well.\n      \n The T,N staging classification gives a measure of the extent of the tumor at \n the primary site and at regional lymph nodes. T=1, refers to a small primary \n tumor, 2 centimeters or less in largest diameter, whereas T=4 is a massive \n tumor with extension to adjoining tissue. T=2 and T=3 refer to intermediate\n cases. N=0 refers to there being no clinical evidence of a lymph node \n metastasis and N=1, N=2, N=3 indicate, in increasing magnitude, the extent of \n existing lymph node involvement. Patients with classifications T=1,N=0; \n T=1,N=1;  T=2,N=0; or T=2,N=1, or with distant metastases were excluded \n from study.\n \n The variable general condition gives a measure of the functional capacity of \n the patient at the time of diagnosis (1 refers to no disability whereas\n 4 denotes bed confinement; 2 and 3 measure intermediate levels). The variable\n grade is a measure of the degree of differentiation of the tumor (the degree\n to which the tumor cell resembles the host cell) from 1 (well differentiated) \n to 3 (poorly differentiated)\n \n In addition to the primary question whether the combined treatment mode is\n preferable to the conventional radiation therapy, it is of considerable \n interest to determine the extent to which the several covariates relate to\n subsequent survival.  It is also imperative in answering the primary question \n to adjust the survivals for possible imbalance that may be present in the \n study with regard to the other covariates. Such problems are similar to those \n encountered in the classical theory of linear regression and the analysis of \n covariance.  Again, the need to accommodate censoring is an important \n distinguishing point. In many situations it is also important to develop \n nonparametric and robust procedures since there is frequently little empirical\n or theoretical work to support a particular family of failure time \n distributions.', 'ARFF', NULL, NULL, NULL, '2014-04-23 13:17:32', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/3650/dataset_2199_pharynx.arff', 'true', 127, 'class', NULL, '\"Entry\"', NULL, 'public', NULL, NULL, 'set ignore feature', '2014-10-05 00:03:24'),
(128, 1, 0, 'iris', '1', '1', '', 'ARFF', 'R.A. Fisher', NULL, '1936', '2014-04-06 23:23:39', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/61/dataset_61_iris.arff', 'true', 128, 'class', NULL, NULL, 'http://digital.library.adelaide.edu.au/dspace/handle/2440/15227', 'public', NULL, 'https://archive.ics.uci.edu/ml/datasets/Iris', NULL, '2014-04-06 23:23:39'),
(129, 1, NULL, 'iris-challenge', '1', '1', '', 'ARFF', NULL, NULL, NULL, '2018-05-29 19:06:15', NULL, 'CC0', NULL, NULL, 'https://www.openml.org/data/download/19330175/iris-challenge.arff', 'true', 129, 'class', NULL, NULL, NULL, 'public', NULL, NULL, NULL, '2018-05-29 19:06:15'),
(130, 16, 0, 'iris', '2', '1', '', 'ARFF', 'R.A. Fisher', NULL, '1936', '2014-04-06 23:23:39', NULL, 'Public', NULL, NULL, 'https://www.openml.org/data/download/61/dataset_61_iris.arff', 'true', 130, 'class', NULL, NULL, 'http://digital.library.adelaide.edu.au/dspace/handle/2440/15227', 'private', NULL, 'https://archive.ics.uci.edu/ml/datasets/Iris', NULL, '2014-04-06 23:23:39');

